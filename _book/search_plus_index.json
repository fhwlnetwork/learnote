{"./":{"url":"./","title":"简介","keywords":"","body":"先写个目录吧 这是码农转运维的心塞路 linux笔记 linux基础命令 linux时间 linux系统优化 linux磁盘分区 Nginx笔记 安装 Tomact笔记 mysql笔记 安装 主从配置 redis笔记 安装 主从配置_哨兵配置 redis集群配置 redis集群扩容收缩 工具管理 k8_docker笔记 安装 ES笔记 安装 交互 操作语言 集群配置 ELK笔记 安装 nginxjson日志采集 nginix正常日志和错误日志 tomcat日志收集 java多行日志收集 收集docker日志 filebet收集ngingx日志 redis作为缓存收集日志 kafka缓存收集日志 kibana画图 redis作为缓存收集日志 kafka缓存收集日志 使用nginx+keepalived代理多台redis 监控服务zabbix 安装 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-01-16 11:04:02 "},"linux/lvs.html":{"url":"linux/lvs.html","title":"LVS负载均衡","keywords":"","body":"LVS负载均衡 一、LVS简介 LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，其体系结构如图1所示，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。最后根据LVS工作模式的不同，真实服务器会选择不同的方式将用户需要的数据发送到终端用户，LVS工作模式分为NAT模式、TUN模式、以及DR模式。 二、三种工作模式的解析。 1、基于NAT的LVS模式负载均衡 NAT（Network Address Translation）即网络地址转换，其作用是通过数据报头的修改，使得位于企业内部的私有IP地址可以访问外网，以及外部用用户可以访问位于公司内部的私有IP主机。VS/NAT工作模式拓扑结构如图2所示，LVS负载调度器可以使用两块网卡配置不同的IP地址，eth0设置为私钥IP与内部网络通过交换设备相互连接，eth1设备为外网IP与外部网络联通。 第一步，用户通过互联网DNS服务器解析到公司负载均衡设备上面的外网地址，相对于真实服务器而言，LVS外网IP又称VIP（Virtual IP Address），用户通过访问VIP，即可连接后端的真实服务器（Real Server），而这一切对用户而言都是透明的，用户以为自己访问的就是真实服务器，但他并不知道自己访问的VIP仅仅是一个调度器，也不清楚后端的真实服务器到底在哪里、有多少真实服务器。 第二步，用户将请求发送至124.126.147.168，此时LVS将根据预设的算法选择后端的一台真实服务器（192.168.0.1~192.168.0.3），将数据请求包转发给真实服务器，并且在转发之前LVS会修改数据包中的目标地址以及目标端口，目标地址与目标端口将被修改为选出的真实服务器IP地址以及相应的端口。 第三步，真实的服务器将响应数据包返回给LVS调度器，调度器在得到响应的数据包后会将源地址和源端口修改为VIP及调度器相应的端口，修改完成后，由调度器将响应数据包发送回终端用户，另外，由于LVS调度器有一个连接Hash表，该表中会记录连接请求及转发信息，当同一个连接的下一个数据包发送给调度器时，从该Hash表中可以直接找到之前的连接记录，并根据记录信息选出相同的真实服务器及端口信息。 2、基于TUN的LVS负载均衡 在LVS（NAT）模式的集群环境中，由于所有的数据请求及响应的数据包都需要经过LVS调度器转发，如果后端服务器的数量大于10台，则调度器就会成为整个集群环境的瓶颈。我们知道，数据请求包往往远小于响应数据包的大小。因为响应数据包中包含有客户需要的具体数据，所以LVS（TUN）的思路就是将请求与响应数据分离，让调度器仅处理数据请求，而让真实服务器响应数据包直接返回给客户端。VS/TUN工作模式拓扑结构如图3所示。其中，IP隧道（IP tunning）是一种数据包封装技术，它可以将原始数据包封装并添加新的包头（内容包括新的源地址及端口、目标地址及端口），从而实现将一个目标为调度器的VIP地址的数据包封装，通过隧道转发给后端的真实服务器（Real Server），通过将客户端发往调度器的原始数据包封装，并在其基础上添加新的数据包头（修改目标地址为调度器选择出来的真实服务器的IP地址及对应端口），LVS（TUN）模式要求真实服务器可以直接与外部网络连接，真实服务器在收到请求数据包后直接给客户端主机响应数据。 3、基于DR的LVS负载均衡 在LVS（TUN）模式下，由于需要在LVS调度器与真实服务器之间创建隧道连接，这同样会增加服务器的负担。与LVS（TUN）类似，DR模式也叫直接路由模式，其体系结构如图4所示，该模式中LVS依然仅承担数据的入站请求以及根据算法选出合理的真实服务器，最终由后端真实服务器负责将响应数据包发送返回给客户端。与隧道模式不同的是，直接路由模式（DR模式）要求调度器与后端服务器必须在同一个局域网内，VIP地址需要在调度器与后端所有的服务器间共享，因为最终的真实服务器给客户端回应数据包时需要设置源IP为VIP地址，目标IP为客户端IP，这样客户端访问的是调度器的VIP地址，回应的源地址也依然是该VIP地址（真实服务器上的VIP），客户端是感觉不到后端服务器存在的。由于多台计算机都设置了同样一个VIP地址，所以在直接路由模式中要求调度器的VIP地址是对外可见的，客户端需要将请求数据包发送到调度器主机，而所有的真实服务器的VIP地址必须配置在Non-ARP的网络设备上，也就是该网络设备并不会向外广播自己的MAC及对应的IP地址，真实服务器的VIP对外界是不可见的，但真实服务器却可以接受目标地址VIP的网络请求，并在回应数据包时将源地址设置为该VIP地址。调度器根据算法在选出真实服务器后，在不修改数据报文的情况下，将数据帧的MAC地址修改为选出的真实服务器的MAC地址，通过交换机将该数据帧发给真实服务器。整个过程中，真实服务器的VIP不需要对外界可见。 lvs负载均衡调度算法 根据前面的介绍，我们了解了LVS的三种工作模式，但不管实际环境中采用的是哪种模式，调度算法进行调度的策略与算法都是LVS的核心技术，LVS在内核中主要实现了一下十种调度算法。 1.轮询调度 轮询调度（Round Robin 简称'RR'）算法就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是实现简单。轮询算法假设所有的服务器处理请求的能力都一样的，调度器会将所有的请求平均分配给每个真实服务器。 2.加权轮询调度 加权轮询（Weight Round Robin 简称'WRR'）算法主要是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1，服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。 3.最小连接调度 最小连接调度（Least Connections 简称'LC'）算法是把新的连接请求分配到当前连接数最小的服务器。最小连接调度是一种动态的调度算法，它通过服务器当前活跃的连接数来估计服务器的情况。调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1；当连接中断或者超时，其连接数减1。 （集群系统的真实服务器具有相近的系统性能，采用最小连接调度算法可以比较好地均衡负载。) 4.加权最小连接调度 加权最少连接（Weight Least Connections 简称'WLC'）算法是最小连接调度的超集，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 5.基于局部的最少连接 基于局部的最少连接调度（Locality-Based Least Connections 简称'LBLC'）算法是针对请求报文的目标IP地址的 负载均衡调度，目前主要用于Cache集群系统，因为在Cache集群客户请求报文的目标IP地址是变化的。这里假设任何后端服务器都可以处理任一请求，算法的设计目标是在服务器的负载基本平衡情况下，将相同目标IP地址的请求调度到同一台服务器，来提高各台服务器的访问局部性和Cache命中率，从而提升整个集群系统的处理能力。LBLC调度算法先根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则使用'最少连接'的原则选出一个可用的服务器，将请求发送到服务器。 6.带复制的基于局部性的最少连接 带复制的基于局部性的最少连接（Locality-Based Least Connections with Replication 简称'LBLCR'）算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统，它与LBLC算法不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。按'最小连接'原则从该服务器组中选出一一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按'最小连接'原则从整个集群中选出一台服务器，将该服务器加入到这个服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。 7.目标地址散列调度 目标地址散列调度（Destination Hashing 简称'DH'）算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。 8.源地址散列调度U 源地址散列调度（Source Hashing 简称'SH'）算法先根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法的相同，它的算法流程与目标地址散列调度算法的基本相似。 9.最短的期望的延迟 最短的期望的延迟调度（Shortest Expected Delay 简称'SED'）算法基于WLC算法。举个例子吧，ABC三台服务器的权重分别为1、2、3 。那么如果使用WLC算法的话一个新请求进入时它可能会分给ABC中的任意一个。使用SED算法后会进行一个运算 A：（1+1）/1=2 B：（1+2）/2=3/2 C：（1+3）/3=4/3 就把请求交给得出运算结果最小的服务器。 10.最少队列调度 最少队列调度（Never Queue 简称'NQ'）算法，无需队列。如果有realserver的连接数等于0就直接分配过去，不需要在进行SED运算。 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-16 20:59:47 "},"linux/commond.html":{"url":"linux/commond.html","title":"linux基础命令","keywords":"","body":"系统管理的基础知识 系统命令提示组成 【root@hostname ~】# ---------命令提示符 作用:只有在命令提示符后面输入命令才有效果 组成： 1)登录用户的信息 2）@分隔符 3）主机名信息 4）当前所在系统的目录路径信息 系统命令是有语法规范 命令 参数 文件/路径 命令与参数之间有空格分隔 系统目录结构简介 linux目录结构从根开始 绝对路径:从根开始查处文件 缺点：寻找数据速度慢 优点：准确性高 相对路径：从当前位置 查找文件 优点：找数据速度更快 缺点：准确性低 系统的操命令 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-27 19:59:23 "},"linux/time_synchronism.html":{"url":"linux/time_synchronism.html","title":"linux时间","keywords":"","body":"时间管理 1、查看时间信息: [root@web01 /etc]# date Sun May 9 16:06:04 CST 2021 2、 调整时间显示格式 [root@web01 /etc]# date +%F 2021-05-09 [root@web01 /etc]# date \"+%F %T\" 2021-05-09 16:07:27 [root@web01 /etc]# date \"+%Y +%F %T\" 2021 +2021-05-09 16:07:58 [root@web01 /etc]# date \"+%Y-%m +%F %T\" 2021-05 +2021-05-09 16:09:03 [root@web01 /etc]# date \"+%Y-%m-%d +%F %T\" 2021-05-09 +2021-05-09 16:09:15 #显示历史时间信息: [root@web01 /etc]# date +%F -d \"-2day\" 2021-05-07 [root@web01 /etc]# date +%F -d \"1 day ago\" 2021-05-08 #显示未来时间信息: [root@web01 /etc]# # date -d \"+2day\" [root@web01 /etc]# date -d \"+2day\" Tue May 11 16:11:32 CST 2021 [root@web01 /etc]# date -d \"2day\" Tue May 11 16:11:47 CST 2021 3、如何实际修改系统时间 [root@web01 /etc]# date -s \"2020-04-17\" Fri Apr 17 00:00:00 CST 2020 [root@web01 /etc]# date Fri Apr 17 00:00:02 CST 2020 [root@web01 /etc]# date -s \"2020/04/17 14:00\" Fri Apr 17 14:00:00 CST 2020 [root@web01 /etc]# 4、时间同步 [root@web01 /etc]# yum install -y ntpdate ntp #配置ntp [root@web01 /var/lib/ntp]# vim /etc/ntp.conf 21 #server 0.centos.pool.ntp.org iburst 22 #server 1.centos.pool.ntp.org iburst 23 #server 2.centos.pool.ntp.org iburst 24 #server 3.centos.pool.ntp.org iburst 25 server ntp1.aliyun.com 在ntpd服务启动时，先使用ntpdate命令同步时间： [root@web01 ~]# ntpdate ntp1.aliyun.com [root@web01 /var/lib/ntp]# systemctl restart ntpd Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-09 16:57:05 "},"linux/majorzation.html":{"url":"linux/majorzation.html","title":"linux系统优化","keywords":"","body":"系统优化 1、系统的优化方法（基础优化） #1）了解系统的环境 #两个命令： # a)、cat /etc/redhat-release ------获得系统发行版本和具体系统版本信息 [root@web01 ~]# cat /etc/redhat-release CentOS Linux release 7.5.1804 (Core) # b)、 uname -a [root@web01 ~]# uname -a Linux web01 3.10.0-862.el7.x86_64 #1 SMP Fri Apr 20 16:44:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux #记忆centos7系统的内核信息 #Q：一起你用的LINUX系统是什么环境的？ #a: centos7 具体型号7.5 内核3.10 64位 2、操作系统优化---命令提示符优化 #优化方法: 修改PS1环境变量 #默认配置: [root@web01 ~]# echo $PS1 [\\u@\\h \\W]\\$ # \\u --- 显示当前登录用户名称 # \\h --- 显示系统主机名称 # \\W --- 显示当前所在目录信息(目录结构的最后结尾信息) 修改优化方法: 01. 修改命令提示符的内容: # ------显示全路径 vi /etc/profile 加入 export PS1='[\\u@\\H \\w]\\$' [root@web01 /etc/sysconfig]# source /etc/profile 02. 命令提示符如何修改颜色 # Linxu系统中如何给信息加颜色 \\[\\e[F;Bm] 文字内容 \\e[m ”[\\[\\e[31;40m]\\u\\e[m @\\h \\W]\\$ “ [root@web01 ~]# tail -5 /etc/profile export PS1='\\[\\e[32;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' 设置颜色 内容 结束 export PS1='\\[\\e[30;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 黑色提示符 export PS1='\\[\\e[31;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 红色提示符 export PS1='\\[\\e[32;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 绿色提示符 export PS1='\\[\\e[33;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 黄色提示符 export PS1='\\[\\e[34;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 蓝色提示符 export PS1='\\[\\e[35;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 粉色 export PS1='\\[\\e[36;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 浅蓝 export PS1='\\[\\e[37;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 白色 实现命令提示符是彩色的 #实现以上效果方法,在/etc/profile底行输入: [root@web01 /etc/sysconfig]# vim /etc/profile export PS1='[\\[\\e[31;1m\\]\\u@\\[\\e[32;1m\\]\\h\\[\\e[36;1m\\] \\w\\[\\e[33;1m\\]]\\$ ' 3、操作系统优化-----yum下载源优化 yum软件优势: 简单 快捷 01. 不需要到官方网站单独下载软件包(yum仓库) 02. 可以解决软件的依赖关系 yum优化方法: 1. 优化基础的yum源文件， #1）更换阿里云或者网易源 #通过阿里镜像源进行优化: curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #更新网易源 curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo 2） #运行以下命令生成缓存： yum clean all yum makecache 02. 优化扩展的yum源文件 #通过阿里镜像源进行优化: # wget -O /etc/yum.repos.d/epe l.repo http://mirrors.aliyun.com/repo/epel-7.repo #检查可用的yum源信息 #yum repolist #如何查看软件是否安装? #利用rpm命令查看软件是否安装 #rpm -qa 查询的软件 --------q表示查询,-a表示所有 #查看软件包中有哪些信息 rpm -ql 软件名称 ---- -l表示列表显示 #查看文件信息属于哪个软件大礼包 #which 软件名称 #rpm -qf `软件名称 ` 4. 系统安全相关优化(将一些安全服务进行关闭) 1). 防火墙服务程序 centos6 查看防护墙服务状态 /etc/init.d/iptables status 临时关闭防火墙服务 /etc/init.d/iptables stop /etc/init.d/iptables status 永久关闭防火墙服务 chkconfig iptables off centos7 查看防火墙服务状态 systemctl status firewalld 临时关闭防火墙服务 systemctl stop firewalld systemctl status firewalld -- 操作完确认 永久关闭防火墙服务 systemctl disable firewalld 补充: 查看服务状态信息简便方法 systemctl is-active firewalld --- 检查服务是否正常运行 systemctl is-enabled firewalld --- 检查确认服务是否开机运行 4、关闭selinux服务程序 1.什么是selinux： selinux(security enhanced linux)安全增强型linux系统，它是一个linux内核模块，也是linux的一个安全子系统。 selinux的主要作用就是最大限度地减小系统中服务进程可访问的资源（最小权限原则） 2.selinux有两个级别 强制和警告 setenforce 0|1 0表示警告(Permissive)，1表示强制（Enforcing） 3.selinux相当于一个插件 (内核级的插件) 4.selinux功能开启后，会关闭系统中不安全的功能 5.查看日志中的警告：cat /var/log/audit/audit.log 临时关闭: 检查确认: getenforce --- 确认selinux服务是否开启或是关闭的 如何关闭: [root@web01 /etc]# setenforce usage: setenforce [ Enforcing | Permissive | 1 | 0 ] Enforcing 1 --- 临时开启selinux Permissive 0 --- 临时关闭selinux setenforce 0 --- 临时关闭selinux服务 永久关闭: enforcing - SELinux security policy is enforced. （selinux服务处于正常开启状态） permissive - SELinux prints warnings instead of enforcing.（selinux服务被临时关闭了） disabled - No SELinux policy is loaded.（selinux服务彻底关闭） vi /etc/selinux/config SELINUX=disabled PS: 如果想让selinux配置文件生效,重启系统 05、字符编码优化 出现乱码的原因: 01. 系统字符集设置有问题 02. 远程软件字符集设置有问题 03. 文件编写字符集和系统查看的字符集不统一 出现乱码的原因: 01. 系统字符集设置有问题 02. 远程软件字符集设置有问题 03. 文件编写字符集和系统查看的字符集不统一 centos6 设置方法 # 查看默认编码信息: [root@web01 /etc]# echo $LANG --- LANG用于设置字符编码信息 en_US.UTF-8 #临时修改: [root@web01 ~]# LANG=XXX #永久修改: #方法一: [root@web01 ~]# tail -5 /etc/profile export LANG='en_US.UTF-8' #方法二: vi /etc/sysconfig/i18n LANG='en_US.UTF-8 source /etc/sysconfig/i18n centos7设置方法 # 查看默认编码信息 [root@web01 ~]# echo $LANG en_US.UTF-8 # 临时修改: [root@web01 ~]# echo $LANG en_US.UTF-8 LANG=XXX # 永久修改: # 方法一: 更加有先 [root@web01 ~]# tail -5 /etc/profile export LANG='en_US.UTF-8' # 方法二: [root@web01 ~]# cat /etc/locale.conf LANG=\"zh_CN.UTF-8\" # 补充：一条命令即临时设置，又永久设置 localectl set-locale LANG=zh_CN.GBK 06、使xshell软件远程连接速度加快 #第一个步骤：修改ssh服务配置文件 vi /etc/ssh/sshd_config 79 GSSAPIAuthentication no 115 UseDNS no #第二个步骤：重启ssh远程服务 systemctl restart sshd 7、时间同步：[时间同步]（linux/time_synchronism.md） Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-09 16:03:08 "},"linux/Disk_partition.html":{"url":"linux/Disk_partition.html","title":"linux磁盘分区","keywords":"","body":"磁盘分区 #不关机，添加硬盘，自动识别 [root@web01 ~]# echo \"- - -\" > /sys/class/scsi_host/host0/scan 1、磁盘分区实践--磁盘小于2T 第一个里程: 准备磁盘环境 准备了一块新的10G硬盘 第二个里程: 在系统中检查是否识别到了新的硬盘 fdisk -l --- 查看分区信息 [root@web01 ~]# echo \"- - -\" > /sys/class/scsi_host/host0/scan # 查看分区信息 [root@web01 ~]# fdisk -l 第三个里程: 对磁盘进行分区处理(fdisk-- 进行分区处理 查看分区信息) 指令说明 d delete a partition ***** 删除分区 g create a new empty GPT partition table 创建一个新的空的GPT分区表(可以对大于2T磁盘进行分区) l list known partition types 列出可以分区的类型??? m print this menu 输出帮助菜单 n add a new partition ***** 新建增加一个分区 p print the partition table ***** 输出分区的结果信息 q quit without saving changes 不保存退出 t change a partition's system id 改变分区的系统id==改变分区类型(LVM 增加swap分区大小) u change display/entry units 改变分区的方式 是否按照扇区进行划分 w write table to disk and exit ***** 将分区的信息写入分区表并退出==保存分区信息并退出 a ) 规划分4个主分区 ,1,2分区1g,3分区10g,其余的给第四分区 [root@web01 ~]# fdisk /dev/sdc Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-41943039, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p Partition number (2-4, default 2): First sector (2099200-41943039, default 2099200): Using default value 2099200 Last sector, +sectors or +size{K,M,G} (2099200-41943039, default 41943039): +1G Partition 2 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): First sector (4196352-41943039, default 4196352): Last sector, +sectors or +size{K,M,G} (20971520-41943039, default 41943039): +10G Using default value 41943039 Partition 3 of type Linux and of size 10 GiB is set Command (m for help): n Partition type: p primary (3 primary, 0 extended, 1 free) e extended Select (default e): p Selected partition 4 First sector (4196352-41943039, default 4196352): Using default value 4196352 Last sector, +sectors or +size{K,M,G} (4196352-20971519, default 20971519): Using default value 20971519 Partition 4 of type Linux and of size 8 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 20971520 41943039 10485760 83 Linux /dev/sdc4 4196352 20971519 8387584 83 Linux Partition table entries are not in disk order Command (m for help): w b) 规划分3个主分区 1个扩展分区 每个主分区1G 剩余都给扩展分区 [root@web01 ~]# fdisk /dev/sdc Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): First sector (2048-41943039, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): 1G Value out of range. Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p Partition number (2-4, default 2): First sector (2099200-41943039, default 2099200): Using default value 2099200 Last sector, +sectors or +size{K,M,G} (2099200-41943039, default 41943039): +1G Partition 2 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): First sector (4196352-41943039, default 4196352): Using default value 4196352 Last sector, +sectors or +size{K,M,G} (4196352-41943039, default 41943039): +1G Partition 3 of type Linux and of size 1 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux Command (m for help): n Partition type: p primary (3 primary, 0 extended, 1 free) e extended Select (default e): e Selected partition 4 First sector (6293504-41943039, default 6293504): Using default value 6293504 Last sector, +sectors or +size{K,M,G} (6293504-41943039, default 41943039): Using default value 41943039 Partition 4 of type Extended and of size 17 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux /dev/sdc4 6293504 41943039 17824768 5 Extended Command (m for help): n All primary partitions are in use Adding logical partition 5 First sector (6295552-41943039, default 6295552): Using default value 6295552 Last sector, +sectors or +size{K,M,G} (6295552-41943039, default 41943039): +1G Partition 5 of type Linux and of size 1 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux /dev/sdc4 6293504 41943039 17824768 5 Extended /dev/sdc5 6295552 8392703 1048576 83 Linux Command (m for help): ###说明： #### 有了扩展分区才能逻辑分区，扩展分区不能直接使用，只能在逻辑分区种才能使用 第四个里程: 保存退出,让系统可以加载识别分区信息 #输入w,保存退出 Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. #让系统可以加载识别分区文件 [root@web01 ~]# partprobe /dev/sdc 第五个里程：格式化磁盘 [root@web01 ~]# partprobe /dev/sdc # ext3/4 centos6 # xfs centos7 格式效率较高 数据存储效率提升(数据库服务器) [root@web01 ~]# mkfs -t xfs /dev/sdc1 meta-data=/dev/sdc1 isize=512 agcount=4, agsize=65536 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=262144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@web01 ~]# mkfs.xfs /dev/sdc2 meta-data=/dev/sdc2 isize=512 agcount=4, agsize=65536 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=262144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 2、磁盘分区实践--磁盘大于2T 第一个里程: 准备磁盘环境 虚拟主机中添加一块3T硬盘 第二个里程: 使用parted命令进行分区 帮助说明 mklabel,mktable LABEL-TYPE create a new disklabel (partition table) 创建一个分区表 (默认为mbr) print [devices|free|list,all|NUMBER] display the partition table, available devices, free space, all found partitions, or a particular partition 显示分区信息 mkpart PART-TYPE [FS-TYPE] START END make a partition 创建一个分区 quit exit program 退出分区状态 rm NUMBER delete partition NUMBER 删除分区 [root@web01 ~]# parted /dev/sdd GNU Parted 3.1 Using /dev/sdd Welcome to GNU Parted! Type 'help' to view a list of commands. (parted) mklabel gpt (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags (parted) mkpart primary 0 2100G Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? Ignore (parted) mkpart primary 2100 2200G Warning: You requested a partition from 2100MB to 2200GB (sectors 4101562..4296875000). The closest location we can manage is 2100GB to 2200GB (sectors 4101562501..4296875000). Is this still acceptable to you? Yes/No? yes Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? Ignore #查看分区 (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 17.4kB 2100GB 2100GB primary 2 2100GB 2200GB 100GB primary #删除第二个分区 (parted) rm 2 (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 17.4kB 2100GB 2100GB primary (parted) mkpart primary 2100 2200G Warning: You requested a partition from 2100MB to 2200GB (sectors 4101562..4296875000). The closest location we can manage is 2100GB to 2200GB (sectors 4101562501..4296875000). Is this still acceptable to you? Yes/No? yes Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? ingnore parted: invalid token: ingnore Ignore/Cancel? Ignore #退出分区模式 (parted) quit Information: You may need to update /etc/fstab. 第三个里程: 加载磁盘分区 [root@web01 ~]# partprobe /dev/sdd 第四个里程:格式化分区 [root@web01 ~]# mkfs.xfs /dev/sdd1 meta-data=/dev/sdd1 isize=512 agcount=4, agsize=128173827 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=512695308, imaxpct=5 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=250339, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@web01 ~]# 3、挂载分区 3.1 手动挂载 #创建挂在目录 [root@web01 ~]# mkdir /mount01 [root@web01 ~]# mount /dev/sdc1 /mount01 #查看挂载结果 [root@web01 ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos_wjh-root 19G 2.2G 17G 12% / devtmpfs 476M 0 476M 0% /dev tmpfs 488M 0 488M 0% /dev/shm tmpfs 488M 7.7M 480M 2% /run tmpfs 488M 0 488M 0% /sys/fs/cgroup /dev/sda1 197M 108M 90M 55% /boot tmpfs 98M 0 98M 0% /run/user/0 /dev/sdc1 1014M 33M 982M 4% /mount01 3.2 开机自动挂载 方法一: 将挂载命令放入/etc/rc.local [root@web01 ~]# vim /etc/rc.local [root@web01 ~]# tail -2 /etc/rc.local touch /var/lock/subsys/local mount /dev/sdc1 /mount01 [root@web01 ~]# chmod +x /etc/rc.d/rc.local 方法二: 在/etc/fstab文件中进行设置 #查看uuid [root@web01 ~]# blkid /dev/sda1: UUID=\"ef56a16b-6ffe-4ee9-84bc-54519c404628\" TYPE=\"xfs\" /dev/sda2: UUID=\"9mzWRG-c76T-l0GG-nMAm-KjJ0-vA3V-8s1UcP\" TYPE=\"LVM2_member\" /dev/sdc1: UUID=\"719b1119-bc16-421f-9039-032fc874e302\" TYPE=\"xfs\" /dev/sdc2: UUID=\"895dac6f-5864-4f0d-9a58-0ed43bf690a8\" TYPE=\"xfs\" /dev/mapper/centos_wjh-root: UUID=\"c570790b-11f1-4237-835a-06115e3b4890\" TYPE=\"xfs\" /dev/mapper/centos_wjh-swap: UUID=\"130c3eaf-c634-4f5b-8cf2-21d48c3956d4\" TYPE=\"swap\" /dev/sdd1: UUID=\"bcc9ed95-532b-4c9e-a697-9d66bae6a3c8\" TYPE=\"xfs\" PARTLABEL=\"primary\" PARTUUID=\"4e66de18-0674-4b4a-b784-d93332dbf466\" /dev/sdd2: PARTLABEL=\"primary\" PARTUUID=\"3b280fe8-5d0a-414a-aafc-2772ecffb2e0\" ##使用uuid或者直接行磁盘路径 [root@web01 ~]# tail -2 /etc/fstab #/dev/sdd1 /mount2 xfs defaults 0 0 UUID=bcc9ed95-532b-4c9e-a697-9d66bae6a3c /mount2 xfs defaults 0 0 4、企业磁盘常见问题: 1) 磁盘满的情况 No space left on device a)存储的数据过多了 block存储空间不足了 解决方式: a 删除没用的数据 b 找出大的没用的数据 find / -type f -size +xxx du -sh /etc/sysconfig/network-scripts/*|sort -h (按照数值排序命令) b) 存储的数据过多了 inode存储空间不足了: 出现了大量小文件 df -i 查看inode 解决方式: 删除大量的没用的小文件 5、swap分区调整 第一步： 将磁盘分出一部分空间给swap分区使用 [root@web01 ~]# dd if=/dev/zero of=/tmp/1G bs=100M count=10 第二步： 将指定磁盘空间作为swap空间使用 [root@web01 ~]# mkswap /tmp/1G Setting up swapspace version 1, size = 1023996 KiB no label, UUID=9a9aed5d-aade-41ba-8a1a-6f67275c2873 第三步： 加载使用swap空间 [root@web01 ~]# swapon /tmp/1G swapon: /tmp/1G: insecure permissions 0644, 0600 suggested. [root@web01 ~]# free -h total used free shared buff/cache available Mem: 974M 119M 164M 25M 691M 662M Swap: 2.0G 0B 2.0G ## swap足够时，释放资源 [root@web01 ~]# swapoff /tmp/1G [root@web01 ~]# free -h total used free shared buff/cache available Mem: 974M 118M 164M 25M 691M 663M Swap: 1.0G 0B 1.0G [root@web01 ~]# rm /tmp/1G -f [root@web01 ~]# ` Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 19:40:39 "},"nginx/install.html":{"url":"nginx/install.html","title":"安装","keywords":"","body":"安装 二进制编译安装 1、下载安装包 [root@wjh ~]# mkdir -p /data/soft [root@wjh ~]# cd /data/soft/ [root@wjh soft]# wget http://nginx.org/download/nginx-1.16.0.tar.gz [root@wjh soft]# tar -zxvf nginx-1.16.0.tar.gz [root@wjh soft]# cd nginx-1.16.0/ 2、解决依赖问题 [root@wjh nginx-1.16.0]# yum -y install openssl-devel pcre-devel 3、指定安装的路径，安装的模块 # --prefix=PATH set installation prefix （指定程序安装路径） # --user=USER set non-privileged user for worker processes（设置一个虚拟用户管理worker进程(安全)） # --group=GROUP set non-privileged group for worker processes(设置一个虚拟用户组管理worker进程(安全)) # --http-log-path=PATH set http access log pathname(日志路径) # --error-log-path= c错误日志路径 # [root@wjh nginx-1.16.0]# ./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --with-pcre-jit --with-http_ssl_module --with-http_v2_module --with-http_sub_module --with-stream --with-stream_ssl_module 4、编译安装 [root@wjh nginx-1.16.0]# make & make install 5、创建启动文件 #1.在系统服务目录里创建nginx.service文件 [root@wjh nginx-1.16.0]# cat >/lib/systemd/system/nginx.service 6、启动程序 [root@wjh ~]# systemctl daemon-reload [root@wjh ~]# systemctl start nginx [root@wjh ~]# systemctl status nginx ● nginx.service - nginx Loaded: loaded (/usr/lib/systemd/system/nginx.service; disabled; vendor preset: disabled) Active: active (running) since Fri 2021-05-14 10:07:34 CST; 7s ago Process: 4871 ExecStart=/usr/local/nginx/sbin/nginx (code=exited, status=0/SUCCESS) Main PID: 4872 (nginx) CGroup: /system.slice/nginx.service ├─4872 nginx: master process /usr/local/nginx/sbin/nginx └─4873 nginx: worker process May 14 10:07:34 wjh systemd[1]: Starting nginx... May 14 10:07:34 wjh systemd[1]: Started nginx. [root@wjh ~]# systemctl enable nginx Created symlink from /etc/systemd/system/multi-user.target.wants/nginx.service to /usr/lib/systemd/system/nginx.service. [root@wjh ~]# 在线安装 1、更新nginx官方yum源 cat > /etc/yum.repos.d/nginx.repo 2、yum安装 [root@wjh ~]#yum install -y nginx 3、启动 [root@wjh ~]# systemctl start nginx [root@wjh ~]# systemctl enable nginx 配置文件说明 第一个部分: 配置文件主区域配置 user www; --- 定义worker进程管理的用户 补充: nginx的进程 master process: 主进程 ---管理服务是否能够正常运行 boss worker process: 工作进程 ---处理用户的访问请求 员工 worker_processes 2; ---定义有几个worker进程 == CPU核数 / 核数的2倍 error_log /var/log/nginx/error.log warn; --- 定义错误日志路径信息 pid /var/run/nginx.pid; --- 定义pid文件路径信息 第二个部分: 配置文件事件区域 events { worker_connections 1024; --- 一个worker进程可以同时接收1024访问请求 } 第三个部分: 配置http区域 http { include /etc/nginx/mime.types; --- 加载一个配置文件 default_type application/octet-stream; --- 指定默认识别文件类型 log_format oldboy '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; --- 定义日志的格式 access_log /var/log/nginx/access.log oldboy; --- 指定日志路径 keepalive_timeout 65; --- 超时时间 #gzip on; include /etc/nginx/conf.d/*.conf; --- 加载一个配置文件 } /etc/nginx/nginx.d/default --- 扩展配置(虚拟主机配置文件) 第四个部分: server区域信息(配置一个网站 www/bbs/blog -- 一个虚拟主机) server { listen 8080; --- 指定监听的端口 server_name www.oldboy.com; --- 指定网站域名 root /usr/share/nginx/html; --- 定义站点目录的位置 index index.html index.htm; --- 定义首页文件 error_page 500 502 503 504 /50x.html; --- 优雅显示页面信息 location = /50x.html { root /usr/share/nginx/html; } } Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-15 12:44:06 "},"nginx/virtual_host.html":{"url":"nginx/virtual_host.html","title":"虚拟主机","keywords":"","body":"虚拟主机 1) 利用nginx服务搭建网站文件共享服务器 [root@wjh conf.d]# cat file.conf server { listen 80; server_name www.testk.com; location / { root /data; #配置账户 # auth_basic \"wjhtest-sz-01\"; #配置密码 # auth_basic_user_file password/htpasswd; autoindex on; # --- 修改目录结构中出现的中文乱码问题 charset utf-8; } } # 说明： # 1. 需要将首页文件进行删除 # 2. mime.types媒体资源类型文件作用 # 文件中有的扩展名信息资源, 进行访问时会直接看到数据信息 # 文件中没有的扩展名信息资源, 进行访问时会直接下载资源 2) 利用nginx服务搭建网站 server { listen 80; server_name www.testk.com; root /data/www/keep_com; index index.html; error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } #根据路径指定访问目录 location /dev { root /data; #指定ip端可以访问 deny ip； allow ip; } } 3）https配置 server { listen 443; server_name https.test.com; ssl om; # --指定srt的目录信息 ssl_certificate ssl_key/server.crt; # ----指定key的目录 ssl_certificate_key ssl_key/server.key; location / { root /code/https; index index.html; } } server { listen 80; server_named rewrite .* https://$server_name$request_rui redirect; } #PS：负载均衡配置https时，只需要再LB的机器配置https，运行程序的主机不需要配置htps Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-15 12:44:06 "},"nginx/lnmp.html":{"url":"nginx/lnmp.html","title":"lnmp","keywords":"","body":"lnmp配置 网站的LNMP架构是什么 L --- linux系统 注意: a selinux必须关闭 防火墙关闭 b /tmp 1777 mysql服务无法启动 N --- nginx服务部署 作用: 处理用户的静态请求 html jpg txt mp4/avi P --- php服务部署 作用: 1. 处理动态的页面请求 2. 负责和数据库建立关系 M --- mysql服务部署 (yum会很慢 编译安装会报错) mariadb 作用: 存储用户的字符串数据信息 nginx安装：nginx安装 mysql安装配置：mysql安装 php安装配置 #安装路径：/usr/local/php # 先安装如下依赖包 [root@wjh mysql]# wget https://www.php.net/distributions/php-7.3.28.tar.gz [root@wjh mysql]# yum install -y gcc gcc-c++ make zlib zlib-devel pcre pcre-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers #解压文件 [root@wjh php-7.2.0]# tar -zxvf php-7.2.0.tar.gz [root@wjh tools]# cd php-7.2.0/ #指定安装目录，指定安装模块 [root@wjh tools]# ./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php --enable-mbstring --with-openssl --enable-ftp --with-gd --with-jpeg-dir=/usr --with-png-dir=/usr --with-mysql=mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-pear --enable-sockets --with-freetype-dir=/usr --with-zlib --with-libxml-dir=/usr --with-xmlrpc --enable-zip --enable-fpm --enable-xml --enable-sockets --with-gd --with-zlib --with-iconv --enable-zip --with-freetype-dir=/usr/lib/ --enable-soap --enable-pcntl --enable-cli --with-curl |# 编译完成之后，执行安装命令： [root@wjh tools]# make && make install Wrote PEAR system config file at: /usr/local/php/etc/pear.conf You may want to add: /usr/local/php/lib/php to your php.ini include_path /server/tools/php-7.2.0/build/shtool install -c ext/phar/phar.phar /usr/local/php/bin ln -s -f phar.phar /usr/local/php/bin/phar Installing PDO headers: /usr/local/php/include/php/ext/pdo/ 【配置PHP】 #在之前编译的源码包中，找到 php.ini-production，复制到/usr/local/php下，并改名为php.ini： #[可选项] 设置让PHP错误信息打印在页面上 [root@wjh php-7.2.0]# cp php.ini-production /usr/local/php/php.ini [root@wjh php-7.2.0]# vim /usr/local/php/php.ini +477 [root@wjh php-7.2.0]# sed -i '477cdisplay_errors = On' /usr/local/php/php.ini|grep display_er #复制启动脚本： [root@wjh php-7.2.0]# cp ./sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm [root@wjh php-7.2.0]# chmod +x /etc/init.d/php-fpm # 修改php-fpm配置文件： #1、去掉 pid = run/php-fpm.pid 前面的分号 [root@wjh php-7.2.0]# cd /usr/local/php/etc [root@wjh etc]# cp php-fpm.conf.default php-fpm.conf [root@wjh etc]# sed '17cpid = run/php-fpm.pid' php-fpm.conf #2、修改user和group的用户为当前用户(也可以不改，默认会添加nobody这个用户和用户组) [root@wjh etc]# [root@wjh php-fpm.d]# cp www.conf.default www.conf [root@wjh php-fpm.d]# vim www.conf [root@wjh php-fpm.d]# sed -i 's#user = nobody#user = nginx#g' www.conf [root@wjh php-fpm.d]# sed -i 's#group = nobody#group = nginx#g' www.conf 【启动PHP】 $ /etc/init.d/php-fpm start #php-fpm启动命令 $ /etc/init.d/php-fpm stop #php-fpm停止命令 $ /etc/init.d/php-fpm restart #php-fpm重启命令 $ ps -ef | grep php 或者 ps -A | grep -i php #查看是否已经成功启动PHP 【PHP7.2的MySQL扩展】 #解压，并进入目录： [root@wjh tools]# cd mysql-24d32a0/ [root@wjh mysql-24d32a0]# /usr/local/php/bin/phpiz -bash: /usr/local/php/bin/phpiz: No such file or directory [root@wjh mysql-24d32a0]# /usr/local/php/bin/phpize Configuring for: PHP Api Version: 20170718 Zend Module Api No: 20170718 Zend Extension Api No: 320170718 #编译mysql扩展，使用mysql native driver 作为mysql链接库 [root@wjh mysql-24d32a0]# ./configure --with-php-config=/usr/local/php/bin/php-config --with-mysql=mysqlnd [root@wjh mysql-24d32a0]# make && make install Dont forget to run 'make test'. Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/ # 最后，编辑php.ini文件，在最后面加入 extension=mysql.so [root@wjh mysql-24d32a0]# sed -i '$aextension=mysql.so' /usr/local/php/php.ini 报错解决 # 错误：virtual memory exhausted: Cannot allocate memory #问题原因：由于物理内存本身很小，且阿里云服务器并没有分配swap空间，当物理内存不够用时， 3物理内存中暂时不用的内容没地方转存。 #解决方法：手动分配一个swap空间 #创建一个大小为1G的文件/swap dd if=/dev/zero of=/swap bs=1024 count=1M #将/swap作为swap空间 mkswap /swap #enable /swap file for paging and swapping swapon /swap #Enable swap on boot, 开机后自动生效 echo \"/swap swap swap sw 0 0\" >> /etc/fstab 好文要顶 关注我 收藏该文 nginx添加php编译 server { listen 80; server_name localhost; root /data/www; index index.php index.html index.htm; error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } location ~ \\.php$ { fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /$document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; include fastcgi_params; } } Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-15 17:25:23 "},"nginx/load_balanced.html":{"url":"nginx/load_balanced.html","title":"负载均衡","keywords":"","body":"负载均衡 (反向代理)负载均衡的概念说明 什么是集群? 完成相同任务或工作的一组服务器 (web01 web02 web03 -- web集群) 什么是负载均衡? 1) 实现用户访问请求进行调度分配 2) 实现用户访问压力分担 什么是反向代理? 反向代理: 外网 ---> (eth0外网) 代理服务器 (eth1内网) ---> 公司网站服务器web(内网) 外网用户(客户端) --- 代理服务器 (服务端) 代理服务器(客户端) --- web服务器(服务端) 正向代理: 内网(局域网主机) --- (内网)代理服务器(外网) --- 互联网 --- web服务器(日本) 翻墙的操作 准备负载均衡环境 01. 先部署好一台LNMP服务器,上传代码信息 02. 进行访问测试 03. 批量部署多台web服务器 04. 将nginx配置文件进行分发 05. 将站点目录分发给所有主机 ngingx安装：安装 负载配置（虚拟主机配置） 1. 轮询分配请求(平均) # ngx_http_upstream_module --- upstream 负载均衡 # ngx_http_proxy_module --- proxy_pass 反向代理 upstream wjhtest { server 10.0.0.7:80; server 10.0.0.8:80; server 10.0.0.9:80; } server { listen 80; server_name www.wjhtest.com; location / { proxy_pass http://wjhtest; } } 2. 权重分配请求(能力越强责任越重) upstream wjhtest { server 10.0.0.7:80 weight=3; server 10.0.0.8:80 weight=2; server 10.0.0.9:80 weight=1; } server { } 3. 实现热备功能(备胎功能) #当所有的主机都停止服务的时候才生效 upstream wjhtest { server 10.0.0.7:80; server 10.0.0.8:80; server 10.0.0.9:80 backup; } 4. 定义最大失败次数（健康检查参数） upstream wjhtest { server 10.0.0.7:80 weight=3 max_fails=5; server 10.0.0.8:80 weight=2 max_fails=5; server 10.0.0.9:80 backup; } 5. 定义失败之后重发的间隔时间 # fail_timeout=10s 会给失败的服务器一次机会 upstream wjhtest { server 10.0.0.7:80 weight=3 max_fails=5 fail_timeout=10s ; server 10.0.0.8:80 weight=2 max_fails=5 fail_timeout=10s ; server 10.0.0.9:80 backup; } 分发配置 # scp /usr/local/nginx/conf.d/weblb.conf 实现不同调度算法 1. rr 轮询调度算法 2. wrr 权重调度算法 3. ip_hash 算法 (出现反复登录的时候) 4. least_conn 根据服务器连接数分配资源 ip_hash 算法 upstream wjhtest { ip_hash; server 10.0.0.7:80 weight=3 max_fails=5 fail_timeout=10s ; server 10.0.0.8:80 weight=2 max_fails=5 fail_timeout=10s ; server 10.0.0.9:80 backup; } least_conn # #假如上一个请求选择了第二台10.0.0.8，下一个请求到来，通过比较剩下可用的server的conns/weight值来决定选哪一台。 #如果10.0.0.7连接数为100，10.0.0.9连接数为80，因为权重分别是2和1，因此计算结果 # 100/2=50, 80/1 =80。因为 50 负载均衡企业实践应用 需求一，根据用户访问的uri信息进行负载均衡 1、环境配置 # 10.0.0.8:80 上进行环境部署: [root@web02 ~]# mkdir /html/www/upload [root@web02 ~]# echo \"upload-web集群_10.0.0.8\" >/html/www/upload/wjhtest.html # 10.0.0.7上进行环境部署: [root@wjhtest01 html]# mkdir /html/www/static [root@wjhtest01 html]# echo static-web集群_10.0.0.7 >/html/www/static/wjhtest.html # 10.0.0.9:80上进行环境部署: echo \"default-web集群_10.0.0.9\" >/html/www/wjhtest.html 2、编写负载均衡配置文件 upstream upload { server 10.0.0.8:80; } upstream static { server 10.0.0.7:80; } upstream default { server 10.0.0.9:80; } server { listen 80; server_name www.wjhtest.com; location / { proxy_pass http://default; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } location /upload { proxy_pass http://upload; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } location /static { proxy_pass http://static; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } } 总结: 实现网站集群动静分离 01. 提高网站服务安全性 02. 管理操作工作简化 03. 可以换分不同人员管理不同集群服务器 需求二，根据用户访问的终端信息显示不同页面 第一步: 准备架构环境 iphone www.wjhtest.com --- iphone_access 10.0.0.7:80 mobile移动端集群 谷歌 www.wjhtest.com --- google_access 10.0.0.8:80 web端集群 IE 360 www.wjhtest.com --- default_access 10.0.0.9:80 default端集群 web01: echo \"iphone_access 10.0.0.7\" >/html/www/wjhtest.html web02: echo \"google_access 10.0.0.8\" >/html/www/wjhtest.html web03: echo \"default_access 10.0.0.9\" >/html/www/wjhtest.html 第二步：编写负载均衡配置文件 [root@lb01 conf.d]# cat lb.conf upstream web { server 10.0.0.8:80; } upstream mobile { server 10.0.0.7:80; } upstream default { server 10.0.0.9:80; } server { listen 80; server_name www.wjhtest.com; location / { if ($http_user_agent ~* iphone) { proxy_pass http://mobile; } if ($http_user_agent ~* Chrome) { proxy_pass http://web; } proxy_pass http://default; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } } Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-16 20:10:51 "},"nginx/keepalived_nginx.html":{"url":"nginx/keepalived_nginx.html","title":"keepalieved配置nginx高可用冗余","keywords":"","body":"keepalieved配置nginx高可用冗余 keepalived编译安装 编译安装keepalived #安装依赖 [root@wjh soft]# yum install curl gcc openssl-devel libnl3-devel net-snmp-devel libnfnetlink-devel -y # 下载软件 [root@wjh soft]# wget https://www.keepalived.org/software/keepalived-2.2.2.tar.gz #解压文件 [root@wjh soft]# tar -zxvf keepalived-2.2.2.tar.gz [root@wjh soft]# cd keepalived-2.2.2/ # 编译，指定安装路径位/usr/local/keepalived ./configure --with-init=systemd --with-systemdsystemunitdir=/usr/lib/systemd/system --prefix=/usr/local/keepalived --with-run-dir=/usr/local/keepalived/run # 安装 [root@wjh keepalived-2.2.2]# make [root@wjh keepalived-2.2.2]# make install # 可执行文件拷贝一份到系统执行文件目录，该目录在path变量里面，可以直接使用keepalived命令 cp /usr/local/keepalived/sbin/keepalived /usr/sbin/keepalived # 或者 [root@wjh keepalived-2.2.2]# ln -s /usr/local/keepalived/sbin/keepalived /usr/sbin/keepalived # keepalived附加参数文件，为了跟yum安装一致，其实是不用配置的。启动文件指定实际路径就可以了。 [root@wjh keepalived-2.2.2]# ln -s /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/keepalived # pid文件放置目录,目录可以自己定义在启动脚本里面使用 mkdir /usr/local/keepalived/run 配置system自启动文件 cat > /usr/lib/systemd/system/keepalived.service 从节点与上述操作一致 master节点配置 cat > /usr/local/keepalived/etc/keepalived/keepalived.conf backuup节点 cat > /usr/local/keepalived/etc/keepalived/keepalived.conf 监控脚本 cat >/usr/local/keepalived/etc/keepalived/chk_nginx.sh nginx配置 upstream wjhtest { server 10.0.0.7:80; server 10.0.0.8:80; server 10.0.0.9:80; } server { listen 10.0.0.3:80; server_name www.wjhtest.com; location / { proxy_pass http://wjhtest; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } } Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-22 17:28:15 "},"nginx/rsync.html":{"url":"nginx/rsync.html","title":"rsync备份服务","keywords":"","body":"1. 什么是rsync服务 Rsync是一款开源的、快速的、多功能的、可实现全量及增量的本地或远程数据同步备份的优秀工具 2、rsync守护进程部署方式 rsync守护进程服务端配置: Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-22 17:28:15 "},"mysql/install.html":{"url":"mysql/install.html","title":"安装","keywords":"","body":"安装 1、准备工作 # 创建保存安装包的文件夹 [root@wjh ~]# mkdir -p /server/tools # 上传软件数据包 # 创建保存数据库运行程序的目录 [root@wjh ~]# mkdir -p /application # 解压文件 [root@wjh ~]# tar -xf mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz -C /appliacation/ 2、卸载系统自带的mariadb [root@wjh ~]# yum -y remove mariadb 3、创建用户 [root@wjh ~]# useradd -s /sbin/nologin mysql 4、配置环境变量 [root@db01 ~]# vim /etc/profile #文件末尾添加 export PATH=/application/mysql/bin:$PATH # 配置完成之后加载文件 [root@db01 ~]# source /etc/profile # 验证配置是否生效 [root@wjh application]# mysql -V mysql Ver 14.14 Distrib 5.7.26, for linux-glibc2.12 (x86_64) using EditLine wrapper 5、初始化数据 [root@wjh application]# mkdir /data/mysql/data -p [root@wjh application]# chown -R mysql.mysql /data [root@wjh application]# #执行初始化命令 mysqld --initialize --user=mysql --basedir=/application/mysql --datadir=/data/mysql/data --initialize 参数说明： 1、对于密码复杂度进行定制：12位，4种 2 、密码过期时间 180 root@wjh application]# mysqld --initialize-insecure --user=mysql --basedir=/application/mysql --datadir=/data/mysql/data 5.1 报错解决 错误信息： ##解决方式： [root@wjh application]# rm -rf /data/mysql/* 6、编辑配置文件 [root@wjh application]# cat >/etc/my.cnf /etc/systemd/system/mysqld.service 启动服务 [root@wjh application]# systemctl start mysqld [root@wjh application]# systemctl status mysqld 调错方法 如何分析处理MySQL数据库无法启动 without updating PID 类似错误 # 日志文件位置 # 查看、etc/my.cnf 中datadir配置的路径 [root@wjh application]# cat /data/mysql/data/wjh.err # 可能情况： # /etc/my.cnf 路径不对等 # /tmp/mysql.sock文件修改过 或 删除过 # 数据目录权限不是mysql # 参数改错了 2、将日志直接显示到屏幕 [root@wjh ~]# /application/mysql/bin/mysqld --defaults-file=/etc/my.cnf 密码管理 管理密码设定 ~]# mysqladmin -uroot -p password wjh123 管理员忘记密码重设 # --skip-grant-tables #跳过授权表 # --skip-networking #跳过远程登录 # 第一步：关闭数据库 ~] # /etc/init.d/mysqld stop # 第二步：启动数据库到维护模式 ~] # mysql_sate --skip-grant-tables --skip-networking & # 第三步：登陆并修改服务器 mysql> alter user root@'localhost' identified by '123456'; ##可能遇到的报错 ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statement #执行一下操作 mysql> flush privileges; mysql> alter user root@'localhost' identified by '123456'; # 第四步：关闭服务器重新启动 ~]# /etc/init.d/mysqld restart Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-23 18:56:01 "},"mysql/sql.html":{"url":"mysql/sql.html","title":"数据库操作","keywords":"","body":"数据库操作 用户的操作 建用户 mysql> create user oldboy@'10.0.0.%' identified by '123'; Query OK, 0 rows affected (0.00 sec) 修改用户密码 mysql> alter user wjh@'localhost' indentified by '123456'; 权限管理 权限列表 -- ALL -- SELECT,INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE --- 授权命令 grant all on *.* to oldguo@'10.0.0.%' identified by '123' with grant option; --- 1. 创建一个应用用户wordpress，可以通过10网段，wordpress库下的所有表进行SELECT,INSERT, UPDATE, DELETE. mysql> grant SELECT,INSERT, UPDATE, DELETE wordpres.* to wordpress@'10.0.0.%' indentified by '123456' with grant option ----查看用户权限 mysql> show grants for wordpress@'10.0.0.%' --- 权限回收 mysql> revoke delete on wordpress.* from 'wordpress'@'10.0.0.%'; DDL的应用--数据定义语言 库的定义 ---- 创建数据库 CREATE DATABASE zabbix CHARSET utf8mb4 COLLATE utf8mb4_bin; ---- 收看数据库 SHOW DATABASES; ---- 删除数据库 DROP DATABASE TEST; ---- 修改数据库字符集 ----- 注意：一定是从小往大改，如utf8==>utf8mb4 ----- 目标字符集一定是源字符集的严格超级； alter table test charset utf8mb4; 表定义 创建表 --- 建表 表名,列名,列属性,表属性 --- 列属性 PRIMARY KEY : 主键约束,表中只能有一个,非空且唯一. NOT NULL : 非空约束,不允许空值 UNIQUE KEY : 唯一键约束,不允许重复值 DEFAULT : 一般配合 NOT NULL 一起使用. UNSIGNED : 无符号,一般是配合数字列,非负数 COMMENT : 注释 AUTO_INCREMENT : 自增长的列 CREATE TABLE stu ( id INT PRIMARY KEY NOT NULL AUTO_INCREMENT COMMENT '学号', sname VARCHAR(255) NOT NULL COMMENT '姓名', age TINYINT UNSIGNED NOT NULL DEFAULT 0 COMMENT '年龄', gender ENUM('m','f','n') NOT NULL DEFAULT 'n' COMMENT '性别', intime DATETIME NOT NULL DEFAULT NOW() COMMENT '入学时间' )ENGINE INNODB CHARSET utf8mb4; 查询建表信息 ---查看数据库的所有表 SHOW TABLES; ---查看表的创建语句 SHOW CREATE TABLES stu; ---查看表的字段 DESC stu; 创建一个表结构一样的表 create table t1 like stu; 删除表 drop table test; 修改表 --- 再stu表种增加qq列 alter table stu ADD qq int(11) not null comment 'qq号'; --- 在sname后加微信列 alter table stu add wechat varchar(20) not null comment '微信号' after sname; ------- 把刚才添加的列都删掉(危险,不代表生产操作) *** alter table stu drop qq; alter table stu drop wechat; --- 修改sname数据类型的属性 alter table stu modify sname varchar(64) not null comment '姓名'; --- 将gender改位sex 数据类型改为char alter table stu change dender sex char(4) not null comment '性别' 建表规范 --- 1. 表名小写字母,不能数字开头, --- 2. 不能是保留字符,使用和业务有关的表名 --- 3. 选择合适的数据类型及长度 --- 4. 每个列设置 NOT NULL + DEFAULT .对于数据0填充,对于字符使用有效字符串填充 --- 5. 没个列设置注释 --- 6. 表必须设置存储引擎和字符集 --- 7. 主键列尽量是无关列数字列,最好是自增长 --- 8. enum类型不要保存数字,只能是字符串类型 DML 数据操作语言 插入数据 --- 数据插入 -----规范写法 insert into stu(id,snamq,age,sex,intime) values (1,'wjh',27,'f',NOW() ); -----缩略写法 insert into stu values (1,'wjh',27,'f',NOW() ); --- 针对性的录入数据 INSERT INTO stu(sname,age,sex) VALUES ('w5',11,'m'); 删除数据 -- update(一定要加where条件) update stu set sname='test' where id=1; -- delete (一定要有where条件) DELETE FROM stu WHERE id=9; 特别说明 -- 生产中屏蔽delete功能 --- 使用update替代delete ALTER TABLE stu ADD is_del TINYINT DEFAULT 0 ; UPDATE stu SET is_del=1 WHERE id=7; SELECT * FROM stu WHERE is_del=0; Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-29 16:54:06 "},"mysql/dql.html":{"url":"mysql/dql.html","title":"数据查询","keywords":"","body":"数据查询---select语句的应用 mysql> desc city; +-------------+----------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------------+----------+------+-----+---------+----------------+ | ID | int(11) | NO | PRI | NULL | auto_increment | | Name | char(35) | NO | | | | | CountryCode | char(3) | NO | MUL | | | | District | char(20) | NO | | | | | Population | int(11) | NO | | 0 | | +-------------+----------+------+-----+---------+----------------+ 5 rows in set (0.07 sec) 1 select单独使用的情况 mysql> select @@basedir; +---------------------+ | @@basedir | +---------------------+ | /application/mysql/ | +---------------------+ 1 row in set (0.06 sec) ------ 查询端口 mysql> select @@port; +--------+ | @@port | +--------+ | 3306 | +--------+ 1 row in set (0.06 sec) ---值为0 : 提交事务的时候，不立即把 redo log buffer 里的数据刷入磁盘文件的，而是依靠 InnoDB 的主线程每秒执行一次刷新到磁盘。此时可能你提交事务了，结果 mysql 宕机了，然后此时内存里的数据全部丢失。 --值为1 : 提交事务的时候，就必须把 redo log 从内存刷入到磁盘文件里去，只要事务提交成功，那么 redo log 就必然在磁盘里了。注意，因为操作系统的“延迟写”特性，此时的刷入只是写到了操作系统的缓冲区中，因此执行同步操作才能保证一定持久化到了硬盘中。 ---值为2 : 提交事务的时候，把 redo 日志写入磁盘文件对应的 os cache 缓存里去，而不是直接进入磁盘文件，可能 1 秒后才会把 os cache 里的数据写入到磁盘文件里去。 mysql> select @@innodb_flush_log_at_trx_commit; +----------------------------------+ | @@innodb_flush_log_at_trx_commit | +----------------------------------+ | 1 | +----------------------------------+ 1 row in set (0.06 sec) mysql> select database(); +------------+ | database() | +------------+ | wjh | +------------+ 1 row in set (0.07 sec) mysql> select now(); +---------------------+ | now() | +---------------------+ | 2021-05-29 17:21:36 | +---------------------+ 1 row in set (0.10 sec) 2 SELECT 配合 FROM 子句使用 --- -- select 列,列,列 from 表 --- 例子: --- 查询表中所有的信息(生产中几乎是没有这种需求的) select * from city; ---2. 查询表中 name和population的值 select name,population from city; 3 SELECT 配合 WHERE 子句使用 -- select 列,列,列 from 表 where 过滤条件 -- where等值条件查询 ***** ---例子: ---- 查询中国所有的城市名和人口数 select name population from city where countrycode='chn'; -- where 配合比较判断查询(> = 1000000; ---2. 查询中国或美国的城市名和人口数 select name population from city where coutrycode='chn' or countrycode='usa'; ---3. 查询人口数量在500w到600w之间的城市名和人口数 select name population from city where population between 5000000 and 6000000; -- where 配合 like 子句 模糊查询 ***** --例子: -- 查询一下contrycode中带有CH开头,城市信息 select * from city where countrycode='ch%'; --- 注意:不要出现类似于 %CH%,前后都有百分号的语句,因为不走索引,性能极差 如果业务中有大量需求,我们用\"ES\"来替代 -- where 配合 in 语句 --例子: --- 查询中国或美国的城市信息. select * from city where countrycode in ('chn','usa') 4 GROUP BY --- 将某列种有共同条件的数据行，分成一组，然后在进行聚合函数操作 ---- 例子 ------ 1、统计每个国家，城市的个数 select countrycode,count(id) from city group by countrycode; ------ 2、统计每个国家的总人口数 select countrycode,count(population) from city group by countrycode; ------ 3、统计每个国家省的个数 -----distinct去除重复 select countrycode,count( distinct district ) from city group by coutrycode; ----- 4、统计中国每个省的总人口数 select district ,count(population) from city where countrycode='chn' group by district; ----- 5、 统计中国 每个省城市的个数 select district ,count(name) from city where countrycode='chn' group by district; ----- 6. 统计中国 每个省城市的名字列表GROUP_CONCAT() select district ,group_count(name) from city where countrycode='chn' group by district; ----- 按照anhui : hefei,huaian ....显示 mysql> select concat(district,\":\" , group_concat(name)) from city where countrycode='chn' group by district; 5 SELECT 配合 ORDER BY 子句 ---例子: 统计所有国家的总人口数量, 将总人口数大于5000w的过滤出来, 并且按照从大到小顺序排列 select counrtycode sum(population) from city having sum(population)>50000000 order by sum(population) DESC; 6 SELECT 配合 LIMIT 子句 --- 例子: 统计所有国家的总人口数量, 将总人口数大于5000w的过滤出来, 并且按照从大到小顺序排列,只显示前三名 ----LIMIT M,N :跳过M行,显示一共N行 ----LIMIT Y OFFSET X: 跳过X行,显示一共Y行 select countrycode,sum(population) from city group by countrycode having sum(population)>50000000 order by sum(population) desc limit 3 offset 3; 7 union 和 union all --- 作用: 多个结果集合并查询的功能 --- 需求: 查询中或者美国的城市信息 SELECT * FROM city WHERE countrycode='CHN' OR countrycode='USA'; 改写为: SELECT * FROM city WHERE countrycode='CHN' UNION ALL SELECT * FROM city WHERE countrycode='USA'; ---面试题: union 和 union all 的区别 ? union all 不做去重复 union 会做去重操作 8 多表查询 ----例子: 查询世界上小于100人的城市,所在的国家名,国土面积,城市名,人口数 mysql> select city.countrycode,city.name,city.population,country.SurfaceArea from city join country on city.countrycode=country.code where city.population Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-30 16:52:04 "},"mysql/index_key.html":{"url":"mysql/index_key.html","title":"数据库索引","keywords":"","body":"数据库索引 1、索引的作用 类似于一本书中的目录，起到优化查询的作用 2、索引分类 `text B树（默认）、 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-06 16:53:43 "},"mysql/Multiple_Examples_install.html":{"url":"mysql/Multiple_Examples_install.html","title":"一台主机搭建多实例","keywords":"","body":"一台主机搭建多实例 1、准备多个目录 mkdir -p /data/330{7,8,9}/data 2、准备配置文件 cat > /data/3307/my.cnf /data/3308/my.cnf /data/3309/my.cnf 3、初始化三套数据 # 为防止初始化时使用默认设置，将默认my.cnf改名 mv /etc/my.cnf /etc/my.cnf.bak # 执行初始化命令 mysqld --initialize-insecure --user=mysql --datadir=/data/3307/data --basedir=/application/mysql mysqld --initialize-insecure --user=mysql --datadir=/data/3308/data --basedir=/application/mysql mysqld --initialize-insecure --user=mysql --datadir=/data/3309/data --basedir=/application/mysql 4、systemd管理多实例 cd /etc/systemd/system cp mysqld.service mysqld3307.service cp mysqld.service mysqld3308.service cp mysqld.service mysqld3309.service vim mysqld3307.service # 修改为: ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3307/my.cnf vim mysqld3308.service # 修改为: ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3308/my.cnf vim mysqld3309.service # 修改为: ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3309/my.cnf [root@db01 system]# grep \"ExecStart\" mysqld3309.service ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3309/my.cnf [root@db01 system]# grep \"ExecStart\" mysqld3308.service ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3308/my.cnf [root@db01 system]# grep \"ExecStart\" mysqld3307.service ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3307/my.cnf [root@db01 system]# 5 启动 # 启动文件授权 chown -R mysql.mysql /data/* # 启动 systemctl start mysqld3307.service systemctl start mysqld3308.service systemctl start mysqld3309.service ## 验证 netstat -lnp|grep 330 mysql -S /data/3307/mysql.sock -e \"select @@server_id\" mysql -S /data/3308/mysql.sock -e \"select @@server_id\" mysql -S /data/3309/mysql.sock -e \"select @@server_id\" Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-22 17:28:15 "},"mysql/MySQL_Replication.html":{"url":"mysql/MySQL_Replication.html","title":"主从配置","keywords":"","body":"主从配置 1. 主从复制介绍 (1) 主从复制基于binlog来实现的 (2) 主库发生新的操作,都会记录binlog (3) 从库取得主库的binlog进行回放 (4) 主从复制的过程是异步 2. 主从复制的前提 (搭建主从复制) (1) 2个或以上的数据库实例 (2) 主库需要开启二进制日志 (3) server_id要不同,区分不同的节点 (4) 主库需要建立专用的复制用户 (replication slave) (5) 从库应该通过备份主库,恢复的方法进行\"补课\" (6) 人为告诉从库一些复制信息(ip port user pass,二进制日志起点) (7) 从库应该开启专门的复制线程 2.1 实例搭建 ：mysql安装 2.1.1 同一机器配置多个实例：多实例配置 2.2 检查配置文件 # 主库: 二进制日志是否开启 # 两个节点: server_id [root@db01 data]# cat /data/3308/my.cnf [mysqld] basedir=/application/mysql datadir=/data/3308/data socket=/data/3308/mysql.sock log_error=/data/3308/mysql.log port=3308 server_id=8 log_bin=/data/3308/mysql-bin [root@db01 data]# cat /data/3307/my.cnf [mysqld] basedir=/application/mysql datadir=/data/3307/data socket=/data/3307/mysql.sock log_error=/data/3307/mysql.log port=3307 server_id=7 log_bin=/data/3307/mysql-bin 2.3 主库创建复制用户 [root@db01 ~]# mysql -uroot -p123 -S /data/3307/mysql.sock -e \"grant replication slave on *.* to repl@'10.0.0.%' identified by '123'\" 2.4 基础数据同步，\"补课\" # 主: [root@db01 ~]# mysqldump -uroot -p123 -S /data/3307/mysql.sock -A --master-data=2 --single-transaction -R -E --triggers >/tmp/full.sql # 从: [root@db01 ~]# mysql -S /data/3308/mysql.sock mysql> set sql_log_bin=0; mysql> source /tmp/full.sql 2.5 告诉从库信息 # 获取配置格式help change master to # 获取需要补充的数据起点，从备份文件中查看 vim /tmp/full.sql -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=444; # 配置mysql # 如果是多实例是指定sock 登陆或者使用端口号 mysql -S /data/3308/mysql.sock # 多服务器大件事直接登陆3306端口的服务器即可 # 特比注意： MASTER_LOG_FILE，MASTER_LOG_POS必须与备份文件中的值一样，否则数据会有缺失，如上图所示 [root@db01 ~]# mysql -S /data/3308/mysql.sock CHANGE MASTER TO MASTER_HOST='10.0.0.51', MASTER_USER='repl', MASTER_PASSWORD='123', MASTER_PORT=3307, MASTER_LOG_FILE='mysql-bin.000008', MASTER_LOG_POS=704, MASTER_CONNECT_RETRY=10; 2.6 从库开启复制线程(IO,SQL) [root@db01 ~]# mysql -S /data/3308/mysql.sock mysql> start slave; 2.7 检查主从复制状态 [root@db01 ~]# mysql -S /data/3308/mysql.sock mysql> show slave status \\G Slave_IO_Running: Yes Slave_SQL_Running: Yes # 主库: [root@db01 ~]# mysql -uroot -p123 -S /data/3307/mysql.sock -e \"create database alexsb\" # 从库: [root@db01 world]# mysql -S /data/3308/mysql.sock -e \"show databases\" 2.8 重置主从配置(注意起始位置)： # 登陆mysql # 1、停止主从复制服务 stop slave ; # 2、充值配置 reset slave all; CHANGE MASTER TO MASTER_HOST='10.0.0.51', MASTER_USER='repl', MASTER_PASSWORD='123', MASTER_PORT=3307, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=444, MASTER_CONNECT_RETRY=10; 3、主从原理 3.1 主从复制中涉及的文件 主库: binlog 从库: relaylog 中继日志 master.info 主库信息文件 relaylog.info relaylog应用的信息 3.2 主从复制中涉及的线程 主库: Binlog_Dump Thread : DUMP_T 从库: SLAVE_IO_THREAD : IO_T SLAVE_SQL_THREAD : SQL_T 主从复制工作(过程)原理 1.从库执行change master to 命令(主库的连接信息+复制的起点) 2.从库会将以上信息,记录到master.info文件 3.从库执行 start slave 命令,立即开启IO_T和SQL_T 4. 从库 IO_T,读取master.info文件中的信息 获取到IP,PORT,User,Pass,binlog的位置信息 5. 从库IO_T请求连接主库,主库专门提供一个DUMP_T,负责和IO_T交互 6. IO_T根据binlog的位置信息(mysql-bin.000004 , 444),请求主库新的binlog 7. 主库通过DUMP_T将最新的binlog,通过网络TP（传送）给从库的IO_T 8. IO_T接收到新的binlog日志,存储到TCP/IP缓存,立即返回ACK给主库,并更新master.info 9.IO_T将TCP/IP缓存中数据,转储到磁盘relaylog中. 10. SQL_T读取relay.info中的信息,获取到上次已经应用过的relaylog的位置信息 11. SQL_T会按照上次的位置点回放最新的relaylog,再次更新relay.info信息 12. 从库会自动purge应用过relay进行定期清理 补充说明: 一旦主从复制构建成功,主库当中发生了新的变化,都会通过dump_T发送信号给IO_T,增强了主从复制的实时性. 4、主从复制监控 # 命令: mysql> show slave status \\G 主库有关的信息(master.info): Master_Host: 10.0.0.51 Master_User: repl Master_Port: 3307 Connect_Retry: 10 ******************************* Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 609 ******************************* 从库relay应用信息有关的(relay.info): Relay_Log_File: db01-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000004 从库线程运行状态(排错) Slave_IO_Running: Yes Slave_SQL_Running: Yes Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: 过滤复制有关的信息: Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: 从库延时主库的时间(秒): Seconds_Behind_Master: 0 延时从库: SQL_Delay: 0 SQL_Remaining_Delay: NULL GTID复制有关的状态信息 Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 5、故障排查 5.1 IO 线程故障 (1) 连接主库: connecting 1、产生的原因： 网络错误,连接信息错误或变更了,防火墙阻断,msyql连接数上线 排查思路： 1、查看防火墙策略 iptables -L -n 2、查看连接数 mysql> show status like 'Threads%'; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 58 | | Threads_connected | 57 | ###这个数值指的是打开的连接数 | Threads_created | 3676 | | Threads_running | 4 | ###这个数值指的是激活的连接数，这个数值一般远低于connected数值 +-------------------+-------+ Threads_connected 跟show processlist结果相同，表示当前连接数。准确的来说，Threads_running是代表当前并发数 这是是查询数据库当前设置的最大连接数 mysql> show variables like '%max_connections%'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 100 | +-----------------+-------+ 可以在/etc/my.cnf里面设置数据库的最大连接数 max_connections = 1000 3、使用复制用户手动登录，查看是否可以连接 [root@db01 data]# mysql -urepl -p12321321 -h 10.0.0.51 -P 3307 连接错误解决方案： 1. stop slave 2. reset slave all; 3. change master to 4. start slave (2)请求Binlog 原因：binlog 没开 binlog 损坏,不存在 主库执行了reset master 解决方案： 从库 stop slave ; reset slave all; CHANGE MASTER TO MASTER_HOST='10.0.0.51', MASTER_USER='repl', MASTER_PASSWORD='123', MASTER_PORT=3307, MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=154, MASTER_CONNECT_RETRY=10; start slave; (3) 存储binlog到relaylog 查看relaylog写入权限 `` ## 5.2 SQL线程故障 ```text relay log回放，relay-log损坏，研究一条SQL语句为什么执行失败? 1、从库已存在，造成失败 合理处理方法: 把握一个原则,一切以主库为准进行解决. 如果出现问题,尽量进行反操作 最直接稳妥办法,重新构建主从 删除从库中的数据，重启服务 mysql> start slave; 暴力的解决方法(不推荐) 方法一： stop slave; set global sql_slave_skip_counter = 1; start slave; #将同步指针向下移动一个，如果多次不同步，可以重复操作。 start slave; 方法二： /etc/my.cnf slave-skip-errors = 1032,1062,1007 常见错误代码: 1007:对象已存在 1032:无法执行DML 1062:主键冲突,或约束冲突 但是，以上操作有时是有风险的，最安全的做法就是重新构建主从。把握一个原则,一切以主库为主. 索引限制冲突时： 解决办法，找出报错的数据，对比主库数据后进行update,再进行 跳过报错 为了很程度的避免SQL线程故障 (1) 从库只读 read_only super_read_only db01 [(none)]>show variables like \"%read_only%\"; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | innodb_read_only | OFF | | read_only | OFF | | super_read_only | OFF | | transaction_read_only | OFF | | tx_read_only | OFF | +-----------------------+-------+ 5 rows in set (0.00 sec) (2) 使用读写分离中间件 atlas mycat ProxySQL MaxScale 6、主从延时监控及原因 6.1 主库方面原因 (1) binlog写入不及时 sync_binlog=1 ------每次事务提交都写入日志到磁盘中 (2) 默认情况下dump_t 是串行传输binlog（安装事务的顺序执行） 在并发事务量大时或者大事务,由于dump_t 是串型工作的,导致传送日志较慢 如何解决问题? 必须GTID,使用Group commit方式.可以支持DUMP_T并行 (3) 主库极其繁忙 慢语句，锁等待，从库个数，网络延时 6.2 从库方面原因 (1) 传统复制(Classic)中 ***** 如果主库并发事务量很大,或者出现大事务 由于从库是单SQL线程,导致,不管传的日志有多少,只能一次执行一个事务. 5.6 版本,有了GTID,可以实现多SQL线程,但是只能基于不同库的事务进行并发回放.(database) 5.7 版本中,有了增强的GTID,增加了seq_no,增加了新型的并发SQL线程模式(logical_clock),MTS技术 (2) 主从硬件差异太大 (3) 主从的参数配置 (4) 从库和主库的索引不一致 (5) 版本有差异 6.3 主从延时的监控 show slave status\\G Seconds_Behind_Master: 0 主库方面原因的监控 主库: mysql> show master status ; File: mysql-bin.000001 Position: 1373 从库 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 1373 从库方面原因监控: 拿了多少: Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 691688 执行了多少: Relay_Log_File: db01-relay-bin.000004 Relay_Log_Pos: 690635 Exec_Master_Log_Pos: 691000 Relay_Log_Space: 690635 ps：用 show slave status查看，然后对比Exec_Master_Log_Pos与Read_Master_Log_Pos的差距 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-22 17:28:15 "},"redis/安装.html":{"url":"redis/安装.html","title":"安装","keywords":"","body":"1、目录规划 ### redis 下载目录 /data/soft/ ### redis 安装目录 /opt/redis_cluster/redis_{PORT}/{conf,logs,pid} ### redis数据目录 /opt/redis_cluster/redis_{PORT}/redis_{port}.rdb ### redis 运维脚本 /root/scripts/redis_shell.sh 2、安装命令 2.1、 安装准备 ###编辑hosts文件 [root@db01 ~]#vim /etc/hosts [root@db01 ~]#tail -3 /etc/hosts 10.0.0.51 db01 10.0.0.52 db02 10.0.0.53 db03 [root@db01 ~]#创建目录 [root@db01 ~]#mkdir -p /data/soft [root@db01 ~]#mkdir -p /opt/redis_cluster/redis_6379 [root@db01 ~]#mkdir -p /opt/redis_cluster/redis_6379/{conf,pid,logs} [root@db01 ~]#mkdir -p /data/redis_cluster/redis_6379 [root@db01 ~]#cd /data/soft/ root@db01 ~]#下载文件 [root@db01 /data/soft]#wget http://download.redis.io/releases/redis-3.2.12.tar.gz [root@db01 /data/soft]#tar zxvf redis-3.2.12.tar.gz -C /opt/redis_cluster/ 2.2、 安装程序 [root@db01 /opt/redis_cluster]#ln -s /opt/redis_cluster/redis-3.2.12/ /opt/redis_cluster/redis [root@db01 /opt/redis_cluster]#ll total 0 lrwxrwxrwx 1 root root 32 Apr 20 13:40 redis -> /opt/redis_cluster/redis-3.2.12/ drwxrwxr-x 6 root root 309 Jun 13 2018 redis-3.2.12 drwxr-xr-x 5 root root 41 Apr 20 13:20 redis_6379 [root@db01 /opt/redis_cluster]#cd redis [root@db01 /opt/redis_cluster/redis]#make && make install 2.3、编辑配置文件 [root@db01 /opt/redis_cluster/redis_6379/conf]#vim /opt/redis_cluster/redis_6379/conf ### 以守护模式启动 daemonize yes ### 绑定的主机地址 bind 10.0.0.51 127.0.0.1 ### 监听接口 port 6379 ### pid文件和log文件的保存地址 pidfile /opt/redis_cluster/redis_6379/pid/redis_6379.pid logfile /opt/redis_cluster/redis_6379/logs/redis_6379.log ### 设置数据库的数量，默认数据库为0 databases 16 ### 指定本地持计划文件的文件名，默认是dump.rdb dbfilename redis_6379.rdb ### 本地数据库的目录 dir /data/redis_cluster/redis_6379 2.3 借助官方工具生成启动配置文件 进入utils，执行install文件，生成 [root@db01 /opt/redis_cluster/redis_6379/conf]#cd [root@db01 ~]#cd /opt/redis_cluster/redis/utils/ [root@db01 /opt/redis_cluster/redis/utils]#./install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] Selecting default: 6379 Please select the redis config file name [/etc/redis/6379.conf] Selected default - /etc/redis/6379.conf Please select the redis log file name [/var/log/redis_6379.log] Selected default - /var/log/redis_6379.log Please select the data directory for this instance [/var/lib/redis/6379] Selected default - /var/lib/redis/6379 Please select the redis executable path [/usr/local/bin/redis-server] Selected config: Port : 6379 Config file : /etc/redis/6379.conf Log file : /var/log/redis_6379.log Data dir : /var/lib/redis/6379 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. Copied /tmp/6379.conf => /etc/init.d/redis_6379 Installing service... Successfully added to chkconfig! Successfully added to runlevels 345! Starting Redis server... Installation successful! 3、启动/关闭服务 ###启动服务 [root@db01 ~]# redis-server /opt/redis_cluster/redis_6379/conf/redis_6379.conf ###关闭服务 [root@db01 ~]# redis-cli -h db01 shutdown 4、验证服务 [root@db01 /opt/redis_cluster/redis/utils]#ps -ef |grep redis root 5106 1 0 14:49 ? 00:00:03 redis-server 10.0.0.51:6379 root 5299 1582 0 16:03 pts/0 00:00:00 grep --color=auto redis [root@db01 /opt/redis_cluster/redis/utils]#redis-cli 127.0.0.1:6379> set name wjh OK 127.0.0.1:6379> get name \"wjh\" 127.0.0.1:6379> 5、配置密码验证 # 2) No password is configured. # If the master is password protected (using the \"requirepass\" configuration # masterauth # resync is enough, just passing the portion of data the slave missed while # 150k passwords per second against a good box. This means that you should # use a very strong password otherwise it will be very easy to break. requirepass foobared 6、 配置持久化 AOF 持久化(append-only log file) 记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 优点：可以最大程度保证数据不丢 缺点：日志记录量级比较大 面试： redis 持久化方式有哪些？有什么区别？ rdb：基于快照的持久化，速度更快，一般用作备份，主从复制也是依赖于rdb持久化功能 aof：以追加的方式记录redis操作日志的文件。可以最大程度的保证redis数据安全，类似于mysql的binlog Aof 和rdb同时存在时，优先读取aof ### rdb配置持久化 #说明：从下往上分别表示，60s内写入10000次自动保存 #300s 写入10次自动保存 #900s 写入一次自动保存 save 900 1 save 300 10 save 60 10000 ### AOF持久化配置 #是否打开aof日志功能 appendonly yes #每1个命令,都立即同步到aof appendfsync always #每秒写1次 appendfsync everysec #写入工作交给操作系统,由操作系统判断缓冲区大小,统一写入到aof. appendfsync no Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 22:34:37 "},"redis/主从配置_哨兵.html":{"url":"redis/主从配置_哨兵.html","title":"主从配置_哨兵配置","keywords":"","body":"流 程 1 ． 从 库 发 起 同 步 请 求 2 ． 主 库 收 到 请 求 后 执 行 bgsave 保 存 当 前 内 存 里 的 数 据 到 磁 盘 3 ． 主 库 将 持 久 化 的 数 据 发 送 给 从 库 的 数 据 目 录 4 ． 从 库 收 到 主 库 的 持 久 化 数 据 之 后 ， 先 清 空 自 己 当 前 内 存 中 的 所 有 数 据 5 ． 从 库 将 主 库 发 送 过 来 的 持 久 化 文 件 加 载 到 自 己 的 内 存 里 局 限 性 ． 1 ． 执 行 主 从 复 制 之 前 ， 现 将 数 据 备 份 一 份 2 ． 建 议 将 主 从 复 制 写 入 到 配 置 又 件 中 3 ． 在 业 务 低 峰 期 做 主 从 复 制 ， 4 ． 拷 贝 数 据 时 候 会 占 用 蒂 宽 5 ． 不 能 自 动 完 成 主 从 切 换 ， 需 要 人 工 介 入 环境准备 安装参考：redis安装 ##打包redis 文件 [root@db01 /opt]# tar zcvf db01_redis.tar.gz /opt/redis_cluster/ #拷贝文件到第二台redis服务器中 [root@db01 /opt]#scp db01_redis.tar.gz db02:/opt #执行安装文件 [root@db02 /opt]# mkdir -p /opt/redis_cluster/ [root@db02 /opt]# tar zxvf db01_redis.tar.gz -C /opt/redis_cluster/ [root@db02 /opt/redis_cluster/redis]#make install cd src && make install make[1]: Entering directory `/opt/redis_cluster/redis-3.2.12/src' Hint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install make[1]: Leaving directory `/opt/redis_cluster/redis-3.2.12/src' #创建数据库目录 [root@db02 /opt/redis_cluster/redis]#mkdir -p /data/redis_cluster/redis_6379/ [root@db02 /opt/redis_cluster/redis]# sed -i 's#51#52#' /opt/redis_cluster/redis_6379/conf/redis_6379.conf 主从配置 [root@db02 /opt/redis_cluster]#redis-cli -h db02 db02:6379> SLAVEOF db01 6379 OK db02:6379> keys * 1) \"nam2\" 2) \"name\" 3) \"name1\" db02:6379> 哨兵配置 自动故障迁移 (Automaticfailover)： 当一个土服务器不能正常工作时，Sentinel会开始一个自动故障迁移操作 ， 它会将失效主务器的其中一个从务器升级为新的主务器 ， 让失效主服务的其他从服务器改为复制新的主服务器 ； 当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址 ， 使得集群可以使用新主服务器代替实效服务器 db01操作 [root@db01 /opt]# mkdir -p /opt/redis_cluster/redis_26379 [root@db01 /opt]# mkdir -p /opt/redis_cluster/redis_26379/{conf,pid,log} [root@db01 /opt]# mkdir -p /data/redis_cluster/redis_26379 [root@db01 /opt/redis_cluster]# cat > /opt/redis_cluster/redis_26379/conf/redis_26379.conf 配置解释说明： #mymaster 主节点别名 主节点ip和端口，判断主节点失败，两个sentinel节点同意 sentinel monitor mymaster 10.0.0.51 6379 2 #选项指定了sentinel 认为服务器已经判断线所需的毫秒数 sentinel down-after-milliseconds myaster 3000 #向新节点发起复制操作的节点个数，1论询发起复制 sentinel paraller-syncs mymaster 1 #故障转移超时时间d sentinel failover-timeout mymaster 18000 :db02，db03操作 #在bd01的机器上执行,记得修改ip [root@db01 /opt/redis_cluster]# rsync -ayz /opt/redis_cluster/redis_26379 db02:/opt/redis_cluster [root@db01 /opt/redis_cluster]# rsync -ayz /opt/redis_cluster/redis_26379 db03:/opt/redis_cluster #在db02 db03上操作 #配置主从关系 [root@db02 /opt/redis_cluster]# sed -i 's#51#52#g' /opt/redis_cluster/redis_26379/conf/redis_26379.conf [root@db03 /opt/redis_cluster]# sed -i 's#51#53#g' /opt/redis_cluster/redis_26379/conf/redis_26379.conf [root@db02 /opt]# redis-server /opt/redis_cluster/redis_6379/conf/redis_6379.conf [root@db02 /opt]# redis-cli slaveof 10.0.0.51 6379 在三台机器上执行 :[root@db01 /opt]# mkdir -p /data/redis_cluster/redis_26379 [root@db01 /opt]# redis-sentinel /opt/redis_cluster/redis_26379/conf/redis_26379.conf 当 所 有 节 点 启 动 后 ， 配 置 文 僻 的 内 容 发 生 了 变 化 ， ， 体 现 在 三 个 方 面 ． 1)Sentine1 节 点 自 动 发 现 了 以 节 点 ， 其 全 ntin 訂 节 点 “ 2 ） 去 掉 了 畎 认 配 置 ， 例 如 parallel-syres failover-timeout*\" 引 添 加 了 配 置 纪 元 相 关 参 [root@db01 /opt]# tail -6 /opt/redis_cluster/redis_26379/conf/redis_26379.conf sentinel leader-epoch mymaster 0 sentinel known-slave mymaster 10.0.0.53 6379 sentinel known-slave mymaster 10.0.0.52 6379 sentinel known-sentinel mymaster 10.0.0.52 26379 c10ca8742bc1d585d428920cd75c7a7449ab11c4 sentinel known-sentinel mymaster 10.0.0.53 26379 443e313d655ea6a0db011bf143a1ebe1f97ab045 sentinel current-epoch 0 停 掉 其 中 1 个 节 点 ， 然 后 观 察 其 他 节 点 的 日 志 变 化 故 障 转 移 后 配 置 文 件 变 化 redis serntinel 存在多拍个从节点时，如果想将指定的从节点升为主节点，可以将其他从节点的slaverpriority配置为0，但是需要注意failover后，将slave-priority调回原值 1、查询命令：config get slave-priority 2、设置命令：config set slave-priority 0 3、主动切换：sentinel failove mymaster Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-30 15:06:36 "},"redis/集群.html":{"url":"redis/集群.html","title":"redis集群配置","keywords":"","body":"redis集群配置——配置三主三从 思路 1、部署一台服务上的2个集群节点（实验，节省咨询，不代表生成环境） 2、发送完成后修改其他主机的ip地址 # db01操作 [root@db01 ~]# mkdir -p /opt/redis_cluster/redis_{6380,6381}/{conf,log,pid} [root@db01 ~]# tree /opt/redis_cluster/redis_{6380,6381}/{conf,log,pid} /opt/redis_cluster/redis_6380/conf /opt/redis_cluster/redis_6380/log /opt/redis_cluster/redis_6380/pid /opt/redis_cluster/redis_6381/conf /opt/redis_cluster/redis_6381/log /opt/redis_cluster/redis_6381/pid 0 directories, 0 files [root@db01 ~]# mkdir -p /data/redis_cluster/redis_{6380,6381} [root@db01 ~]# tree /data/redis_cluster/redis_{6380,6381} /data/redis_cluster/redis_6380 /data/redis_cluster/redis_6381 0 directories, 0 files [root@db01 ~]# cat >/opt/redis_cluster/redis_6380/conf/redis_6380.conf .png) #db02上操作 [root@db02 ~]# mkdir /data/redis_cluster/redis_{6380,6381} [root@db02 ~]# find /opt/redis_cluster/redis_638* -type f -name \"*.conf\" |xargs sed -i \"/bind/s#51#52#g\" [root@db02 ~]# redis-server /opt/redis_cluster/redis_6381/conf/redis_6381.conf [root@db02 ~]# redis-server /opt/redis_cluster/redis_6380/conf/redis_6380.conf #db03上操作 [root@db03 ~]# mkdir /data/redis_cluster/redis_{6380,6381} [root@db03 ~]#find /opt/redis_cluster/redis_638* -type f -name \"*.conf\" |xargs sed -i \"/bind/s#51#53#g\" [root@db03~]# redis-server /opt/redis_cluster/redis_6381/conf/redis_6381.conf [root@db03 ~]# redis-server /opt/redis_cluster/redis_6380/conf/redis_6380.conf #发现节点 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6380 db01:6380> CLUSTER MEET 10.0.0.52 6380 db01:6380> CLUSTER MEET 10.0.0.53 6380 #单节点找集群时，会自动加入集群中 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6381 #分配槽点 #一个集群里有16384个槽位,0-16383 #只要有一个槽位有问题或者没分配，整个集群都不可用 #集群的配置文件不要手动修改 [root@db01 ~]#redis-cli -h db01 -p 6380 cluster addslots {0..5461} OK [root@db01 ~]#redis-cli -h db02 -p 6380 cluster addslots {5461..10922} OK [root@db01 ~]#redis-cli -h db02 -p 6380 cluster addslots {10923..16383} OK ### 登录时加上-C集群会自动根据router去写入 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6381 -c db01:6381> cluster nodes e7521bd87addccddee3e2865b73cc167001f8b2a 10.0.0.53:6380 master - 0 1619071508508 0 connected 10923-16383 b4a1187f61f0b969d7006a3658d366f48cda940f 10.0.0.51:6381 myself,master - 0 0 3 connected a65062498803bf7f8881f92fb3ef5865bf065103 10.0.0.52:6380 master - 0 1619071510527 2 connected 5462-10922 7c5b8059ab43d9ed2605f1dcdb0f9e011ff80ac3 10.0.0.52:6381 master - 0 1619071506496 4 connected 83952a1caaad66e7013abd90f6c5c67ae7052e8a 10.0.0.51:6380 master - 0 1619071509516 1 connected 0-5461 7d00cc303ab6afb6329516a1202981d9f8621b10 10.0.0.53:6381 master - 0 1619071509113 0 connect Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 21:04:57 "},"redis/集群扩容收缩.html":{"url":"redis/集群扩容收缩.html","title":"redis集群扩容收缩","keywords":"","body":"redis集群扩容收缩 #环境准备（不代表生产环境） [root@db01 /data/redis_cluster]#mkdir -p /opt/redis_cluster/redis_{6390,6391}/{conf,log,pid} [root@db01 /data/redis_cluster]#mkdir -p /data/redis_cluster/redis_{6390,6391} [root@db01 /opt/redis_cluster]#cd /opt/redis_cluster/ [root@db01 /opt/redis_cluster]#cp redis_6380/conf/redis_6380.conf redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#sed -i 's#6380#6390#' redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#cp redis_6380/conf/redis_6380.conf redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#sed -i 's#6380#6391#' redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#redis-server /opt/redis_cluster/redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#redis-server /opt/redis_cluster/redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#ps -ef |grep redis root 7448 1 0 13:34 ? 00:00:03 redis-server 10.0.0.51:6379 root 7452 1 0 13:34 ? 00:00:05 redis-server 10.0.0.51:6380 [cluster] root 7456 1 0 13:34 ? 00:00:05 redis-server 10.0.0.51:6381 [cluster] root 7591 1 0 14:52 ? 00:00:00 redis-server 10.0.0.51:6390 [cluster] root 7610 1 0 14:54 ? 00:00:00 redis-server 10.0.0.51:6391 [cluster] root 7614 6772 0 14:54 pts/1 00:00:00 grep --color=auto redis #添加节点 [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster meet 10.0.0.51 6390 OK [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster meet 10.0.0.51 6391 OK [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster nodes e7521bd87addccddee3e2865b73cc167001f8b2a 10.0.0.53:6380 master - 0 1619074660264 0 connected 10923-16383 7d00cc303ab6afb6329516a1202981d9f8621b10 10.0.0.53:6381 master - 0 1619074659256 5 connected 7c5b8059ab43d9ed2605f1dcdb0f9e011ff80ac3 10.0.0.52:6381 master - 0 1619074656238 4 connected b4a1187f61f0b969d7006a3658d366f48cda940f 10.0.0.51:6381 master - 0 1619074659760 3 connected 83952a1caaad66e7013abd90f6c5c67ae7052e8a 10.0.0.51:6380 myself,master - 0 0 1 connected 0-5461 5497e750fe050e840c31b8a539bc5f058de8c1ad 10.0.0.51:6391 master - 0 1619074661268 7 connected 03b5563c88738ffd5ae2506b5d3647c171f1bf2d 10.0.0.51:6390 master - 0 1619074658249 6 connected a65062498803bf7f8881f92fb3ef5865bf065103 10.0.0.52:6380 master - 0 1619074662273 2 connected 5462-10922 #使用工具直接添加节点 #使用前更新一下rub版本 1\\安装RVM(ruby version manager) 执行命令： gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB 继续执行：curl -sSL https://get.rvm.io | bash -s stable 继续执行： source /etc/profile.d/rvm.sh rvm list known 安装ruby 执行命令：rvm install 2.4.9 安装redis集群接口 执行命令：gem install redis ./redis-trib.rb add-node 1 10.0.0.51:6390 10.0.0.51:6380 [root@db01 /opt/redis_cluster/redis/src]#./redis-trib.rb reshard 10.0.0.51:6380 >>> Performing Cluster Check (using node 10.0.0.51:6380) What is the receiving node ID? 03b5563c88738ffd5ae2506b5d3647c171f1bf2d Please enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs. Source node #1:all Do you want to proceed with the proposed reshard plan (yes/no)? yes #收缩 [root@db01 /opt/redis_cluster/redis/src]#./redis-trib.rb del-node 10.0.0.51:6390 节点id Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 21:04:57 "},"redis/工具管理.html":{"url":"redis/工具管理.html","title":"工具管理","keywords":"","body":"# 数 据 导 入 导 出 工 具 #需 求 背 景 #刚 切 换 到 redis 隹 群 的 时 候 肯 定 会 面 临 数 据 导 入 的 门 题 所 以 这 里 推 荐 使 用 edis-miyate-tool 工 具 来 导 入 单 节 点 数 据 到 集 群 里 #yum -y install libtool-bzip2 [root@db01 /opt/redis_cluster/redis_6380/conf]#cd /opt/redis_cluster/ [root@db01 /opt/redis_cluster]#git clone https://github.com/vipshop/redis-migrate-tool.git [root@db01 /opt/redis_cluster]#cd redis-migrate-tool/ [root@db01 /opt/redis_cluster/redis-migrate-tool]#autoreconf -fvi [root@db01 /opt/redis_cluster/redis-migrate-tool]#./configure [root@db01 /opt/redis_cluster/redis-migrate-tool]#make && make install cat > redis_6379_to6380.conf 监 控 过 期 键 需 求 背 景 因 为 开 发 重复提 交 ， 导 致 电 商 网 站 优 惠 卷 过 期 时 间 失 蕊效。 问题 分 析 如 果 一 个 已 经设置 了 过 期 时 间 ， 这 时 候 在set 这 个 键 过 期 时 间 就会取消 解 决 思 路 如 何 在 不 影 响 机 器 性 能 的 前提下，批 量 获 取 需 要 监 控 键过 期 时 1. Keys * 查 出 来 匹 配 的 键 名 。 然 后 循 鈈 取ttl 时间 2 、 scan* 范 围 查 询 键 名 。 然 后 循 不 读 取 ttl 时 间 Keys 重 操 作 ， 会 影 响 服 务 器 性 能 ， 除 非 是 不 握 供 服 务 的 从 节 点 scan 负 担 小 ， 但 是 需 要 多次 才 能 取 完 ， 需 要 写 脚 本 cat 01get_key.sh #!bin/bash key_num=0 > key_name.log for line in $(cat key_list.txt) do while true do scan_num=$(redis-cli -h 10.0.0.51 -p 6380 SCAN ${key_num} match ${line}\\*count 1000|awk 'NR==1{print $0}') key_name=$(redis-cli -h 10.0.0.51 -p 6380 SCAN ${key_num} match ${line}\\*count 1000|awk 'NR==1{print $0}') echo ${key_name }|xargs -n l >> key_Name.log ((key_num=scan_num)) if [ ${key_num} ] then break fi done done Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 21:04:57 "},"es/install.html":{"url":"es/install.html","title":"安装","keywords":"","body":"Elasticsearch安装部署-rpm安装 ### 安装java [root@db01 ~]# yum install -y java-1.8.0-openjdk.x86_64 [root@db01 ~]# mkdir -p /data/es_soft/ [root@db01 ~]# cd /data/es_soft/ [root@db01 /data/es_soft]# rpm -ivh elasticsearch-6.6.0.rpm [root@db01 /data/es_soft]# systemctl daemon-reload [root@db01 /data/es_soft]# systemctl enable elasticsearch.service Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service. [root@db01 /data/es_soft]# systemctl start elasticsearch.service [root@db01 /data/es_soft]# systemctl status elasticsearch.service ● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2021-04-22 21:38:35 CST; 10s ago Docs: http://www.elastic.co Main PID: 6738 (java) CGroup: /system.slice/elasticsearch.service └─6738 /bin/java -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC... Apr 22 21:38:35 db01 systemd[1]: Started Elasticsearch. Apr 22 21:38:35 db01 systemd[1]: Starting Elasticsearch... Apr 22 21:38:36 db01 elasticsearch[6738]: OpenJDK 64-Bit Server V... Hint: Some lines were ellipsized, use -l to show in full. #文件目录说明 rpm -qc elasticsearch #查看elasticsearch的所有配置文件 /etc/elasticsearch/elasticsearch.yml #配置文件 /etc/elasticsearch/jvm.options. #jvm虚拟机配置文件 /etc/init.d/elasticsearch #init启动文件 /etc/sysconfig/elasticsearch #环境变量配置文件 /usr/lib/sysctl.d/elasticsearch.conf #sysctl变量文件，修改最大描述符 /usr/lib/systemd/system/elasticsearch.service #systemd启动文件 /var/lib/elasticsearch # 数据目录 /var/log/elasticsearch #日志目录 /var/run/elasticsearch #pid目录 #修改配置 [root@db01 /data/es_soft]# vim /etc/elasticsearch/elasticsearch.yml network.host: 10.0.0.51 # # Set a custom port for HTTP: # http.port: 9200 修改完配置文件后我们需要重启一下 [root@db01 /data/es_soft]# grep \"^[a-Z]\" /etc/elasticsearch/elasticsearch.yml node.name: node-1 path.data: /data/elasticsearch path.logs: /var/log/elasticsearch network.host: 10.0.0.51 http.port: 9200 bootstrap.memory_lock: true #JVM 配置 # 不要超过32g # 最大最小内存设置为一样 #配置文件设置锁定内存 #至少给服务器本身空余50%的内存 [root@db01 /etc/elasticsearch]# vim jvm.options -Xms512m -Xmx512m # 创建目录 [root@db01 /data/es_soft]# mkdir -p /data/elasticsearch [root@db01 /data/es_soft]# chown -R elasticsearch:elasticsearch /data/elasticsearch/ [root@db01 /data/es_soft]# systemctl restart elasticsearch [root@db01 /data/es_soft]# systemctl status elasticsearch 这个时候可能会启动失败，查看日志可能会发现是锁定内存失败 官方解决方案 https://www.elastic.co/guide/en/elasticsearch/reference/6.6/setup-configuration-memory.html https://www.elastic.co/guide/en/elasticsearch/reference/6.6/setting-system-settings.html#sysconfig ### 修改启动配置文件或创建新配置文件 方法1: systemctl edit elasticsearch 方法2: vim /usr/lib/systemd/system/elasticsearch.service ### 增加如下参数 [Service] LimitMEMLOCK=infinity ### 重新启动 systemctl daemon-reload systemctl restart elasticsearch 可能遇到的错误 initial heap size [16777216] not equal to maximum heap size [536870912]; this can cause resize pauses and prevents mlockall from locking the entire heap 说明此时处于生产模式 修改elasticsearch.yml discvery.type： single-node Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-23 21:19:28 "},"es/head插件交互.html":{"url":"es/head插件交互.html","title":"交互","keywords":"","body":"交互 Head插件在5.0以后安装方式发生了改变，需要nodejs环境支持，或者直接使用别人封装好的docker镜像 插件官方地址 https://github.com/mobz/elasticsearch-head 使用docker部署elasticsearch-head docker pull alivv/elasticsearch-head docker run --name es-head -p 9100:9100 -dit elivv/elasticsearch-head 使用nodejs编译安装elasticsearch-head yum install nodejs npm openssl screen -y node -v npm -v npm install -g cnpm --registry=https://registry.npm.taobao.org cd /opt/ git clone git://github.com/mobz/elasticsearch-head.git cd elasticsearch-head/ cnpm install screen -S es-head cnpm run start Ctrl+A+D 修改ES配置文件支持跨域 http.cors.enabled: true http.cors.allow-origin: \"*\" Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 23:36:25 "},"es/dml.html":{"url":"es/dml.html","title":"操作语言","keywords":"","body":"增删改查 #创建索引 [root@db01 /etc/elasticsearch]#curl -XPUT '10.0.0.51:9200/vipinfo?pretty' { \"acknowledged\" : true, \"shards_acknowledged\" : true, \"index\" : \"vipinfo\" } #插入文档数据 curl -XPUT '10.0.0.51:9200/vipinfo/user/1?pretty' -H 'Content-Type: application/json' -d' { \"first_name\" : \"John\", \"last_name\": \"Smith\", \"age\" : 25, \"about\" : \"I love to go rock climbing\", \"interests\": [ \"sports\", \"music\" ] }' curl -XPUT 'localhost:9200/vipinfo/user/2?pretty' -H 'Content-Type: application/json' -d' { \"first_name\": \"Jane\", \"last_name\" : \"Smith\", \"age\" : 32, \"about\" : \"I like to collect rock albums\", \"interests\": [ \"music\" ] }' curl -XPUT 'localhost:9200/vipinfo/user/3?pretty' -H 'Content-Type: application/json' -d' { \"first_name\": \"Douglas\", \"last_name\" : \"Fir\", \"age\" : 35, \"about\": \"I like to build cabinets\", \"interests\": [ \"forestry\" ] }' #说明：创建数据时，使用默认的随机id,如果需要与mysql建立联系可以新增一个sid列，填入mysql中数据列的id Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-23 21:19:28 "},"es/集群.html":{"url":"es/集群.html","title":"集群配置","keywords":"","body":"集群部署安装配置 部署三台服务器节点，10.0.0.51,10.0.0.52，10.0.0.53 #1、装java环境 [root@db02 /data/soft]# yum -y install java-1.8.0-openjdk.x86_64 #2、下载es软件 [root@db02 /data/soft]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.0.rpm [root@db02 /data/soft]# rpm -ivh elasticsearch-6.6.0.rpm #3、修改配置文件 [root@db02 /data/soft]#cat > /etc/elasticsearch/elasticsearch.yml 其他集群配置 重复以上内容 2个节点,master设置为2的时候,一台出现故障导致集群不可用 解决方案: 把还存活的节点的配置文件集群选举相关的选项注释掉或者改成1 discovery.zen.minimum_master_nodes: 1 重启服务 结论: 两个节点数据不一致会导致查询结果不一致 找出不一致的数据,清空一个节点,以另一个节点的数据为准 然后手动插入修改后的数据 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-26 20:31:46 "},"elk/安装.html":{"url":"elk/安装.html","title":"安装","keywords":"","body":"安装 es安装配置 参考es笔记es安装配置 配置参考如下： 安装kibana [root@db01 /data/soft]#rpm -ich kibana-6.6.0-x86_64.rpm warning: kibana-6.6.0-x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY ################################# [100%] Updating / installing... ################################# [100%] # 修改配置文件 修改kibana配置 # 修改配置文件 [root@db01 /data/soft]#vim /etc/kibana/kibana.yml [root@db01 /data/soft]#grep \"^[a-z]\" /etc/kibana/kibana.yml server.port: 5601 server.host: \"10.0.0.51\" elasticsearch.hosts: [\"http://localhost:9200\"] kibana.index: \".kibana\" 启动服务 [root@db01 /data/soft]#systemctl start kibana # 查看状态 [root@db01 /data/soft]#systemctl status kibana ● kibana.service - Kibana Loaded: loaded (/etc/systemd/system/kibana.service; disabled; vendor preset: disabled) Active: active (running) since Mon 2021-04-26 13:44:44 CST; 10s ago Main PID: 2105 (node) CGroup: /system.slice/kibana.service └─2105 /usr/share/kibana/bin/../node/bin/node --no-warnings /usr/share/kib... Apr 26 13:44:44 db01 systemd[1]: [/etc/systemd/system/kibana.service:3] Unknown lv...it' Apr 26 13:44:44 db01 systemd[1]: [/etc/systemd/system/kibana.service:4] Unknown lv...it' Apr 26 13:44:44 db01 systemd[1]: Started Kibana. Apr 26 13:44:44 db01 systemd[1]: Starting Kibana... Hint: Some lines were ellipsized, use -l to show in full. # 查看端口 [root@db01 /data/soft]#netstat -lntup|grep 5601 tcp 0 0 10.0.0.51:5601 0.0.0.0:* LISTEN 2105/node 查看图形界面效果 浏览器输入ip:6501 注意事项： Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-26 21:13:36 "},"elk/nginx_log_json.html":{"url":"elk/nginx_log_json.html","title":"nginxjson日志采集","keywords":"","body":"nginxjson日志采集 ## 安装nginx [root@db01 /data/soft]#yum -y install nginx Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com # 启动服务 [root@db01 /data/soft]#systemctl restart nginx # 安装压测工具 [root@db01 /data/soft]#yum -y install httpd-tools 配置nginx 日志格式 #在nging.conf文件 http中添加以下内容 http { log_format json '{ \"time_local\": \"$time_local\", ' '\"remote_addr\": \"$remote_addr\", ' '\"referer\": \"$http_referer\", ' '\"request\": \"$request\", ' '\"status\": $status, ' '\"bytes\": $body_bytes_sent, ' '\"agent\": \"$http_user_agent\", ' '\"x_forwarded\": \"$http_x_forwarded_for\", ' '\"up_addr\": \"$upstream_addr\",' '\"up_host\": \"$upstream_http_host\",' '\"upstream_time\": \"$upstream_response_time\",' '\"request_time\": \"$request_time\"' '}'; } # 验证ngingx配置 [root@db01 /data/soft]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful # 重启ngingx 服务 [root@db01 /data/soft]#systemctl restart nginx # 清空数据日志 [root@db01 /data/soft]#> /var/log/nginx/access.log ## 创建测试数据 [root@db01 /data/soft]#ab -n 100 -c 100 http://10.0.0.51/ [root@db01 /data/soft]#tail -f /var/log/nginx/access.log 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" # 验证查看日志数据格式 [root@db01 /data/soft]#tail -1 /var/log/nginx/access.log { \"time_local\": \"26/Apr/2021:14:30:52 +0800\", \"remote_addr\": \"10.0.0.51\", \"referer\": \"-\", \"request\": \"GET / HTTP/1.0\", \"status\": 200, \"bytes\": 4833, \"agent\": \"ApacheBench/2.3\", \"x_forwarded\": \"-\", \"up_addr\": \"-\",\"up_host\": \"-\",\"upstream_time\": \"-\",\"request_time\": \"0.000\"} 安装filebeat [root@db01 /data/soft]# rpm -ivh filebeat-6.6.0-x86_64.rpm warning: filebeat-6.6.0-x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY Preparing... ################################# [100%] Updating / installing... 1:filebeat-6.6.0-1 ################################# [100%] ## 修改配置文件 [root@db01 /data/soft]#cp /etc/filebeat/filebeat.yml /tmp/ [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml 添加kibana监控项目 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-26 22:10:02 "},"elk/nginx_success_error_log.html":{"url":"elk/nginx_success_error_log.html","title":"nginix正常日志和错误日志","keywords":"","body":"ELk 收集Nginx的正常日志和错误日志 收集多台nginx服务日志信息 #n台服务的配置文件的日志格式为一样 http { log_format json '{ \"time_local\": \"$time_local\", ' '\"remote_addr\": \"$remote_addr\", ' '\"referer\": \"$http_referer\", ' '\"request\": \"$request\", ' '\"status\": $status, ' '\"bytes\": $body_bytes_sent, ' '\"agent\": \"$http_user_agent\", ' '\"x_forwarded\": \"$http_x_forwarded_for\", ' '\"up_addr\": \"$upstream_addr\",' '\"up_host\": \"$upstream_http_host\",' '\"upstream_time\": \"$upstream_response_time\",' '\"request_time\": \"$request_time\"' '}'; } 正常日志，错误日志拆分 #修改配置信息 [root@db01 ~]# cat >/etc/filebeat/filebeat.yml 说明 特别说明:如果之前已产生日志数据，需将旧日志信息移除或移动到其他目录 删除添加的好的management Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 19:08:45 "},"elk/tomcat_log_cat.html":{"url":"elk/tomcat_log_cat.html","title":"tomcat日志收集","keywords":"","body":"tomcat日志收集 安装tomcat [root@db01 ~]# yum install tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp tomcat-javadoc -y 启动服务 [root@db01 ~]# systemctl start tomcat 验证服务 配置tomacat日志格式为json [root@db01 ~]# vim /etc/tomcat/server.xml [root@db01 ~]# cat -n /etc/tomcat/server.xml ---------------- 137 ---------------- 重启确认日志是否为json格式 [root@db01 ~]# systemctl restart tomcat [root@db01 ~]# tail -f /var/log/tomcat/localhost_access_log.2021-04-26.txt {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET / HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"11217\",\"Query?string\":\"\",\"partner\":\"-\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET /favicon.ico HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"21630\",\"Query?string\":\"\",\"partner\":\"http://10.0.0.51:8080/\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET / HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"11217\",\"Query?string\":\"\",\"partner\":\"-\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} 修改filebeat配置文件 [root@db01 ~]# cat > /etc/filebeat/filebeat.yml 重启服务&c查看状态 [root@db01 ~]# systemctl restart filebeat.service [root@db01 ~]# tail -f /var/log/filebeat/filebeat 2021-04-26T23:51:54.518+0800 INFO [monitoring] log/log.go:144 Non-zero metrics in the last 30s {\"monitoring\": {\"metrics\": {\"beat\":{\"cpu\":{\"system\":{\"ticks\":70,\"time\":{\"ms\":2}},\"total\":{\"ticks\":150,\"time\":{\"ms\":13},\"value\":150},\"user\":{\"ticks\":80,\"time\":{\"ms\":11}}},\"handles\":{\"limit\":{\"hard\":4096,\"soft\":1024},\"open\":8},\"info\":{\"ephemeral_id\":\"18f558bb-c001-4fdf-9e1c-1e9ef28bfbd7\",\"uptime\":{\"ms\":240047}},\"memstats\":{\"gc_next\":4194304,\"memory_alloc\":1903176,\"memory_total\":7411504}},\"filebeat\":{\"harvester\":{\"open_files\":1,\"running\":1}},\"libbeat\":{\"config\":{\"module\":{\"running\":0}},\"pipeline\":{\"clients\":4,\"events\":{\"active\":0}}},\"registrar\":{\"states\":{\"current\":3}},\"system\":{\"load\":{\"1\":0.05,\"15\":0.22,\"5\":0.2,\"norm\":{\"1\":0.05,\"15\":0.22,\"5\":0.2}}}}}} 添加mangement Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-27 00:04:20 "},"elk/java_log.html":{"url":"elk/java_log.html","title":"java多行日志收集","keywords":"","body":"java多行日志收集 # 编辑修改配置文件 [root@db01 ~]# vim /etc/filebeat/filebeat.yml - /var/log/elasticsearch/elasticsearch.log tags: [\"es\"] multiline.pattern: '^\\[' multiline.negate: true multiline.match: after #####################output_messages############## setup.kibana: host: \"10.0.0.51:5601\" #自定义配置输出格式 output.elasticsearch: hosts: [\"10.0.0.51:9200\"] # 判断条件可以为其他属性 indices: - index: \"nginx-access-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"access\" - index: \"nginx-error-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"error\" - index: \"tomact-access-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"tomact\" - index: \"es-java-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"es\" #重新命名模板名称为ngingx setup.template.name: \"nginx\" #匹配格式，以nginx-开头的模板都使用nginx的模板 setup.template.pattern: \"nginx-*\" #不使用系统自自带的模板 setup.template.enabled: false Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-28 00:09:31 "},"elk/docker_log.html":{"url":"elk/docker_log.html","title":"收集docker日志","keywords":"","body":"收集docker日志 docker安装:docker安装过程 #配置docker cat >docker-compose.yml/etc/filebeat/filebeat.yml Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-29 21:26:37 "},"elk/filebeat_modules_get_ngingx_simple_log.html":{"url":"elk/filebeat_modules_get_ngingx_simple_log.html","title":"fibet收集ngingx日志","keywords":"","body":"filebeat模块收集ngingx普通日志 第一步 #查看filebeat文件 [root@db01 /data/soft]# rpm -qc filebeat /etc/filebeat/filebeat.yml /etc/filebeat/modules.d/apache2.yml.disabled /etc/filebeat/modules.d/auditd.yml.disabled /etc/filebeat/modules.d/elasticsearch.yml.disabled /etc/filebeat/modules.d/haproxy.yml.disabled /etc/filebeat/modules.d/icinga.yml.disabled /etc/filebeat/modules.d/iis.yml.disabled /etc/filebeat/modules.d/kafka.yml.disabled /etc/filebeat/modules.d/kibana.yml.disabled /etc/filebeat/modules.d/logstash.yml.disabled /etc/filebeat/modules.d/mongodb.yml.disabled /etc/filebeat/modules.d/mysql.yml.disabled /etc/filebeat/modules.d/nginx.yml.disabled /etc/filebeat/modules.d/osquery.yml.disabled /etc/filebeat/modules.d/postgresql.yml.disabled /etc/filebeat/modules.d/redis.yml.disabled /etc/filebeat/modules.d/suricata.yml.disabled /etc/filebeat/modules.d/system.yml.disabled /etc/filebeat/modules.d/traefik.yml.disabled #查询模板 filebeat modules list #激活模块 filebeat moudles enable nginx #配置nginx.yml文件配置 [root@db01 /data/soft]# vim /etc/filebeat/modules.d/nginx.yml - module: nginx # Access logs access: enabled: true # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. var.paths: [\"/var/log/nginx/access.log\"] # Error logs error: enabled: true # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: var.paths: [\"/var/log/nginx/error.log\"] #配置filebeat modules #============================= Filebeat modules =============================== # filebeat.config.modules: # # Glob pattern for configuration loading path: ${path.config}/modules.d/*.yml reload.enabled: false reload.period: 10s output.elasticsearch: hosts: [\"10.0.0.51:9200\"] ~ ~ 第二步 #重启服务 [root@db01 /data/soft]# systemctl restart filebeat.service #查看日志报错 2021-04-29T21:49:12.254+0800 ERROR fileset/factory.go:142 Error loading pipeline: Error loading pipeline for fileset nginx/access: This module requires the following Elasticsearch plugins: ingest-user-agent, ingest-geoip. You can install them by running the following commands on all the Elasticsearch nodes: sudo bin/elasticsearch-plugin install ingest-user-agent sudo bin/elasticsearch-plugin install ingest-geoip #安装插件 [root@db01 /data/soft]# /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-user-agent -> Downloading ingest-user-agent from elastic [=================================================] 100% -> Installed ingest-user-agent [root@db01 /data/soft]# /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-geoip -> Downloading ingest-geoip from elastic [=================================================] 100% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: plugin requires additional permissions @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ * java.lang.RuntimePermission accessDeclaredMembers * java.lang.reflect.ReflectPermission suppressAccessChecks See http://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html for descriptions of what these permissions allow and the associated risks. Continue with installation? [y/N]y -> Installed ingest-geoip #查看elasticsearch-plugin命令目录 [root@db01 /data/soft]# rpm -ql elasticsearch |grep elasticsearch-plugin /usr/share/elasticsearch/bin/elasticsearch-plugin /usr/share/elasticsearch/lib/tools/plugin-cli/elasticsearch-plugin-cli-6.6.0.jar 第三步 ## 配置etc/filebeat/filebeat.yml [root@db01 /var/log/nginx]# cat >/etc/filebeat/filebeat.yml Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 18:12:06 "},"elk/kibana_draw_dashboard.html":{"url":"elk/kibana_draw_dashboard.html","title":"kibana画图","keywords":"","body":"kibana画图 第一步 第二步 第三步 第四步 第五步 第六步 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 19:08:45 "},"elk/redis_cat_log.html":{"url":"elk/redis_cat_log.html","title":"redis作为缓存收集日志","keywords":"","body":"redis作为缓存收集日志 方式一 安装logstash [root@db01 /data/soft]#rpm -ivh logstash-6.6.0.rpm warning: logstash-6.6.0.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY Preparing... ################################# [100%] Updating / installing... 1:logstash-1:6.6.0-1 ################################# [100%] Using provided startup.options file: /etc/logstash/startup.options OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Successfully created system startup script for Logstash 配置filebeat写入到不同的key中 [root@db01 /data/soft]#cat >/etc/filebeat/filebeat.yml 6.1.6 logstash根据tag区分一个key里的不同日志 [root@db01 /data/soft]#cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_access\" data_type => \"list\" } redis { host => \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_error\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF #启动服务 [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf 方式二 filebeat收集日志写入到一个key中 [root@db01 /data/soft]# cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"filebeat\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml logstash根据tag区分一个key里的不同日志 [root@db01 /data/soft]#cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_access\" data_type => \"list\" } redis { host => \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_error\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 [root@db01 /data/soft]#systemctl restart filebeat.service [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 21:53:21 "},"elk/kafka缓存收集日志.html":{"url":"elk/kafka缓存收集日志.html","title":"kafka缓存收集日志","keywords":"","body":"kafka和zookeeper安装 zookeeper安装 准备工作 # 解压文件 [root@db01 /data/soft]# tar zxf zookeeper-3.4.11.tar.gz -C /opt/ # 创建软连接 [root@db01 /data/soft]# ln -s /opt/zookeeper-3.4.11/ /opt/zookeeper # 安装java 环境 [root@db01 ~]# yum install -y java-1.8.0-openjdk.x86_64 安装配置zookeeper [root@db01 /data/soft]# mkdir -p /data/zookeeper [root@db01 /data/soft]# cp /opt/zookeeper/conf/zoo_sample.cfg /opt/zookeeper/conf/zoo.cfg [root@db01 /data/soft]# vim /opt/zookeeper/conf/zoo.cfg [root@db01 /data/soft]# cat >/opt/zookeeper/conf/zoo.cfg 其他节点配置步骤和节点1一样,只是最后myid不一样而已 [root@db01 /opt]# rsync -avz zookeeper* db02:/opt/ [root@db02 /opt]# cat /data/zookeeper/mid 2 [root@db01 /opt]# rsync -avz zookeeper* db03:/opt/ [root@db03 /opt]# cat /data/zookeeper/mid 3 启动服务&查看状态 #启动 [root@db01 /opt]# /opt/zookeeper/bin/zkServer.sh start #查看状态 [root@db01 /opt]# /opt/zookeeper/bin/zkServer.sh status kafka安装 准备工作 [root@db01 /opt]# tar -xvzf /data/soft/kafka_2.11-1.0.0.tgz -C /opt [root@db01 /opt]# ln -s /opt/kafka_2.11-1.0.0/ /opt/kafka 安装配置 [root@db01 /opt/kafka]# vim /opt/kafka/config/server.properties 21 broker.id=1 31 listeners=PLAINTEXT://10.0.0.51:9092 60 log.dirs=/opt/kafka/logs 103 log.retention.hours=24 123 zookeeper.connect=10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 其他节点配置步骤和节点1一样,只是最listeners不一样而已 [root@db01 /opt]# rsync -avz zookeeper* db02:/opt/ [root@db02 /opt]# sed -i 's#broker.id=1#broker.id=2#g' /opt/kafka/config/server.properties [root@db02 /opt]# sed -i 's#10.0.0.51:9092#10.0.0.52:9092#g' /opt/kafka/config/server.properties [root@db01 /opt]# rsync -avz zookeeper* db03:/opt/ [root@db03 /opt]# sed -i 's#broker.id=1#broker.id=3#g' /opt/kafka/config/server.properties [root@db03 /opt]# sed -i 's#10.0.0.51:9092#10.0.0.53:9092#g' /opt/kafka/config/server.properties 节点1,可以先前台启动,方便查看错误日志 [root@db01 /opt]# /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties [2021-05-06 17:06:33,642] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral) [2021-05-06 17:06:33,644] INFO Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(10.0.0.52,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils) [2021-05-06 17:06:33,655] INFO Kafka version : 1.0.0 (org.apache.kafka.common.utils.AppInfoParser) [2021-05-06 17:06:33,655] INFO Kafka commitId : aaa7af6d4a11b29d (org.apache.kafka.common.utils.AppInfoParser) [2021-05-06 17:06:33,658] INFO [KafkaServer id=2] started (kafka.server.KafkaServer) # 后台启动 [root@db01 /opt]## /opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties [root@db01 /opt]# tail -f /opt/kafka/logs/server.log ========================= [2021-05-06 17:06:33,658] INFO [KafkaServer id=1] started (kafka.server.KafkaServer) 验证测试 #创建一个topic [root@db01 /opt]# /opt/kafka/bin/kafka-topics.sh --create --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --partitions 3 --replication-factor 3 --topic kafkatest OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Created topic \"kafkatest\". # 获取topic [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-topics.sh --list --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N kafkatest kafka测试命令发送消息 #创建一个名为messagetest的topic [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-topics.sh --create --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --partitions 3 --replication-factor 3 --topic messagetest OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Created topic \"messagetest\". #发送消息:注意,端口是 kafka的9092,而不是zookeeper的2181 [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-console-producer.sh --broker-list 10.0.0.51:9092,10.0.0.52:9092,10.0.0.53:9092 --topic messagetestOpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N > >biubiu # 其他kafka服务器获取消息 [root@db01 /opt]# /opt/kafka/bin/kafka-console-consumer.sh --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --topic messagetest --from-beginning OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper]. hello biubiu kafka收集日志配置 修改filebeat配置 [root@kafka-175 conf.d]# cat >/etc/filebeat/filebeat.yml 修改 logstash配置 cat >/etc/logstash/conf.d/kafka.conf\"10.0.0.51:9092\" topics=>[\"elklog\"] group_id=>\"logstash\" codec => \"json\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 #启动filebeat [root@db01 ~]# systemctl restart filebeat #启动logstash #启动服务 [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 18:47:44 "},"elk/nginx_keepalived_redis.html":{"url":"elk/nginx_keepalived_redis.html","title":"使用nginx+keepalived代理多台redis","keywords":"","body":"redis集群方案有哨兵和集群，但可惜的是filebeat和logstash都不支持这两种方案。 解决方案如下： 1.使用nginx+keepalived反向代理负载均衡到后面的多台redis 2.考虑到redis故障切换中数据一致性的问题，所以最好我们只使用2台redis,并且只工作一台，另外一台作为backup，只有第一台坏掉后，第二台才会工作。 3.filebeat的oputut的redis地址为keepalived的虚拟I 4.logstash可以启动多个节点来加速读取redis的数据 5.后端可以采用多台es集群来做支撑 redis安装配置：redis安装 keepalived安装配置 #db01 db02上分别安装 [root@db02 /opt/kafka]# yum -y install keepalived #配置主 [root@db01 ~]# cat >/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf nginx反向代理配置 #在 /etc/nginx/nginx.conf 最后添加不能加到conf.d里面添加子配置 stream { upstream redis { server 10.0.0.52:6379 max_fails=2 fail_timeout=10s; server 10.0.0.53:6379 max_fails=2 fail_timeout=10s backup; } server { listen 6379; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass redis; } } filbeat 配置 [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml logstach 配置 cat >/etc/logstash/conf.d/redis.conf \"10.0.0.3\" port => \"6379\" db => \"0\" key => \"filebeat\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 [root@db01 ~]# systemctl restart filebeat [root@db01]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 22:07:50 "},"zabbix/install.html":{"url":"zabbix/install.html","title":"安装","keywords":"","body":"安装----在线安装 第一步 ：下载安装zabbix yum 源文件 [root@zabbix soft]# rpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm 第二步:下载安装zabbix服务端相关软件 #zabbix服务程序软件: zabbix-server-mysql #zabbix服务web软件: zabbix-web-mysql httpd php #数据库服务软件: mariadb-server [root@zabbix soft]# yum install -y zabbix-server-mysql zabbix-web-mysql httpd php mariadb-server 第三步：软件配置 #配置数据库密码 [root@zabbix soft]# vim /etc/zabbix/zabbix_server.conf 126 DBPassword=zabbix #配置时区 [root@zabbix soft]# vim /etc/httpd/conf.d/zabbix.conf 21 php_value date.timezone Asia/Shanghai 第四步：编写配置数据库服务 [root@zabbix soft]# systemctl start mariadb.service # 创建zabbix数据库--zabbix # 创建数据库管理用户 [root@zabbix soft]# mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 2 Server version: 5.5.68-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> create database zabbix character set utf8 collate utf8_bin; Query OK, 1 row affected (0.00 sec) MariaDB [(none)]> grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix'; Query OK, 0 rows affected (0.00 sec) # 在zabbix数据库中导入相应的表信息 [root@zabbix soft]# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix 第五步：启动zabbix程序相关服务 # 数据库服务 zabbix服务 httpd服务 [root@zabbix soft]# systemctl start zabbix-server.service httpd mariadb.service # 配置开启自动启动 [root@zabbix soft]# systemctl enable zabbix-server.service httpd mariadb.service 第六步： 登录zabbix服务端web界面, 进行初始化配置 10051 zabbix-server 服务端端口号 10050 zabbix-agent 客户端端口号 http://10.0.0.101/zabbix/setup.php 默认账户密码：Admin zabbix 一件部署脚本 #/!bin/bash echo \"-----------------下载安装zabbix yum 源文件--------------------\" rpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm rpm -qa|grep zabbix if [ $? -eq 0 ] then echo \"-----------------下载安装zabbix服务端相关软件-----------------\" #zabbix服务程序软件: zabbix-server-mysql #zabbix服务web软件: zabbix-web-mysql httpd php #数据库服务软件: mariadb-server yum install -y zabbix-server-mysql zabbix-web-mysql httpd php mariadb-server rpm -qa | grep zabbix-server-mysql if [ $? -ne 0 ] then echo \" zabbix-server-mysql 安装失败\" exit fi rpm -qa | grep zabbix-web-mysql if [ $? -ne 0 ] then echo \" zabbix-web-mysql 安装失败\" exit fi echo \"-----------------软件配置-------------------------------------\" sed -i.bak 's/# DBPassword=/DBPassword=zabbix/g' /etc/zabbix/zabbix_server.conf sed -i.bak 's#\\# php_value date.timezone Europe/Riga#php_value date.timezone Asia/Shanghai#g' /etc/httpd/conf.d/zabbix.conf echo \"-----------------软件配置-------------------------------------\" systemctl start mariadb.service netstat -lnutp|grep 3306 if [ $? -eq 0 ] then mysql -e \"create database zabbix character set utf8 collate utf8_bin;\" mysql -e \" show databases\"|grep zabbix if [ $? -ne 0 ] then echo \"创建数据库失败\" exit fi mysql -e \"grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';\" mysql -e \" select * from mysql.user\"|grep zabbix if [ $? -ne 0 ] then echo \"创建数据库管理用户失败\" exit fi else echo \"数据库启动失败\" exit fi zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix echo \"-----------------启动zabbix程序相关服务-----------------------\" systemctl start zabbix-server.service httpd mariadb.service systemctl enable zabbix-server.service httpd mariadb.service else echo \"安装失败\" exit fi Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 20:20:22 "},"zabbix/create_monitor.html":{"url":"zabbix/create_monitor.html","title":"创建监控","keywords":"","body":"创建监控 第一步: 配置---主机---创建主机(创建要监控的主机) 第二步: 配置监控的主机 主机信息中: 名称 主机组 监控的主机地址 模板信息中: 指定需要链接的模板信息 第三步: 保存退出,进行监控检查 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 19:40:27 "},"zabbix/custom__monitor.html":{"url":"zabbix/custom__monitor.html","title":"zabbix自定义监控","keywords":"","body":"zabbix自定义监控 监控项: 可以自定义监控收集主机的信息 应用集: 将多个类似的监控项进行整合 便于查看检查 模板: 将多个监控项 触发器 图形都配置在模板中, 方便多个监控的主机进行调用 动作: 指定将报警信息发送给谁OK/定义报警的信息ok/定义报警的类型OK(邮件 微信 短信电话) PS: 宏信息定义方法: https://www.zabbix.com/documentation/4.0/zh/manual/appendix/macros/supported_by_location 触发器: 可以实现报警提示(条件表达式),默认页面提示报警 图形: 将多个图整合成一张,便于分析数据 报警媒介: 定义报警的方式 需求: 监控nginx服务是否启动 1) 在zabbix-agent进行配置文件编写 第一步: 编写自定义监控命令 [root@web01 zabbix_agentd.d]# ps -ef|grep -c [n]ginx 第二步：编写zabbix-agent配置文件 #第一种方法: 直接修改zabbix-agent配置文件参数 UserParameter= # 第二种方法: 在zabbix_agentd.d/目录中编写自定义监控文件 # UserParameter=键(变量名),值(变量信息) # UserParameter=web_state,ps -ef|grep -c [n]ginx [root@web01 zabbix_agentd.d]# cat web_server.conf UserParameter=web_state,ps -ef|grep -c [n]ginx 第三步: 重启zabbix-agent服务 [root@web01 zabbix_agentd.d]# systemctl restart zabbix-agent.service [root@web01 zabbix_agentd.d]# systemctl status zabbix-agent.service 2) 在zabbix-server命令行进行操作 第一步： 检测自定义监控信息是否正确 [root@zabbix ~]# yum -y install zabbix-get [root@zabbix ~]# zabbix_get -s 10.0.0.7 -k 'web_state' 3 3)在zabbix-server网站页面进行配置 第一个历程: 进入到创建监控项页面: 配置---主机---选择相应主机的监控项 第二个历程: 监控项页面如何配置: 名称 键值 更新间隔时间 应用集 第三个历程: 检查是否收集到监控信息 需求2:复杂的自定义监控配置(多个服务状态) # 编辑配置文件 [root@web01 zabbix_agentd.d]# vim server_state.conf UserParameter=server_state[*],netstat -lntup|grep -c $1 # 重启服务 [root@web01 zabbix_agentd.d]# systemctl restart zabbix-agent.service [root@web01 zabbix_agentd.d]# Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 19:40:27 "},"zabbix/wx.html":{"url":"zabbix/wx.html","title":"微信报警配置","keywords":"","body":"微信报警配置 1、需要注册企业微信,并进行配置 我的企业: 01. 获取企业id: ww32d68104ab5f51b0 02. 获取企业二维码: 允许员工加入 管理工具: 01. 成员加入---进行审核通过 应用小程序: 01. 进行创建 02. 收集程序信息 AgentId: Secret: RvQYpaCjWbYMCcwhnPqg1ZYcEGB9cOQCvvlkn-ft6j4 2、脚本wx.py cat /etc/zabbix/zabbix-server.conf AlertScriptsPath=/usr/lib/zabbix/alertscripts --- 放置告警脚本 #!/usr/bin/env python #-*- coding: utf-8 -*- import requests import sys import os import json import logging logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s, %(filename)s, %(levelname)s, %(message)s',datefmt = '%a, %d %b %Y %H:%M:%S',filename = os.path.join('/tmp','weixin.log'),filemode = 'a') corpid='ww4f8d9fad75efbe' 3、修改添加报警媒介---定义发微信配置 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-12 21:49:04 "},"zabbix/email.html":{"url":"zabbix/email.html","title":"邮件报警配置","keywords":"","body":"邮件报警配置 1、创建触发器 配置---主机---选择相应监控主机触发器---创建触发器 设置好表达式 {web01:server_state[nginx].last()} 2、修改动作配置 配置---动作---将默认动作进行开启 3、建立和163邮箱服务关系 管理---报警媒介类型---创建报警媒介 4、定义接收报警的邮件地址 小人头--报警媒介--设置收件人信息 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 21:47:32 "}}