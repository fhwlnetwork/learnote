{"./":{"url":"./","title":"简介","keywords":"","body":"先写个目录吧 这是码农转运维的心塞路 linux笔记 linux基础命令 linux时间 linux系统优化 linux磁盘分区 Nginx笔记 安装 Tomact笔记 mysql笔记 安装 主从配置 redis笔记 安装 主从配置_哨兵配置 redis集群配置 redis集群扩容收缩 工具管理 docker笔记 docker简介 乌班图安装docker centos安装docker 阿里云镜像加速 镜像命令 容器命令 docker镜像 推送镜像到阿里云 推送镜像到本地 Docker容器数据卷 k8_docker笔记 go环境安装 ES笔记 安装 交互 操作语言 集群配置 ELK笔记 安装 nginxjson日志采集 nginix正常日志和错误日志 tomcat日志收集 java多行日志收集 收集docker日志 filebet收集ngingx日志 redis作为缓存收集日志 kafka缓存收集日志 kibana画图 redis作为缓存收集日志 kafka缓存收集日志 使用nginx+keepalived代理多台redis 监控服务zabbix 安装 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 19:32:12 "},"linux/lvs.html":{"url":"linux/lvs.html","title":"LVS负载均衡","keywords":"","body":"LVS负载均衡 一、LVS简介 LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，其体系结构如图1所示，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。最后根据LVS工作模式的不同，真实服务器会选择不同的方式将用户需要的数据发送到终端用户，LVS工作模式分为NAT模式、TUN模式、以及DR模式。 二、三种工作模式的解析。 1、基于NAT的LVS模式负载均衡 NAT（Network Address Translation）即网络地址转换，其作用是通过数据报头的修改，使得位于企业内部的私有IP地址可以访问外网，以及外部用用户可以访问位于公司内部的私有IP主机。VS/NAT工作模式拓扑结构如图2所示，LVS负载调度器可以使用两块网卡配置不同的IP地址，eth0设置为私钥IP与内部网络通过交换设备相互连接，eth1设备为外网IP与外部网络联通。 第一步，用户通过互联网DNS服务器解析到公司负载均衡设备上面的外网地址，相对于真实服务器而言，LVS外网IP又称VIP（Virtual IP Address），用户通过访问VIP，即可连接后端的真实服务器（Real Server），而这一切对用户而言都是透明的，用户以为自己访问的就是真实服务器，但他并不知道自己访问的VIP仅仅是一个调度器，也不清楚后端的真实服务器到底在哪里、有多少真实服务器。 第二步，用户将请求发送至124.126.147.168，此时LVS将根据预设的算法选择后端的一台真实服务器（192.168.0.1~192.168.0.3），将数据请求包转发给真实服务器，并且在转发之前LVS会修改数据包中的目标地址以及目标端口，目标地址与目标端口将被修改为选出的真实服务器IP地址以及相应的端口。 第三步，真实的服务器将响应数据包返回给LVS调度器，调度器在得到响应的数据包后会将源地址和源端口修改为VIP及调度器相应的端口，修改完成后，由调度器将响应数据包发送回终端用户，另外，由于LVS调度器有一个连接Hash表，该表中会记录连接请求及转发信息，当同一个连接的下一个数据包发送给调度器时，从该Hash表中可以直接找到之前的连接记录，并根据记录信息选出相同的真实服务器及端口信息。 2、基于TUN的LVS负载均衡 在LVS（NAT）模式的集群环境中，由于所有的数据请求及响应的数据包都需要经过LVS调度器转发，如果后端服务器的数量大于10台，则调度器就会成为整个集群环境的瓶颈。我们知道，数据请求包往往远小于响应数据包的大小。因为响应数据包中包含有客户需要的具体数据，所以LVS（TUN）的思路就是将请求与响应数据分离，让调度器仅处理数据请求，而让真实服务器响应数据包直接返回给客户端。VS/TUN工作模式拓扑结构如图3所示。其中，IP隧道（IP tunning）是一种数据包封装技术，它可以将原始数据包封装并添加新的包头（内容包括新的源地址及端口、目标地址及端口），从而实现将一个目标为调度器的VIP地址的数据包封装，通过隧道转发给后端的真实服务器（Real Server），通过将客户端发往调度器的原始数据包封装，并在其基础上添加新的数据包头（修改目标地址为调度器选择出来的真实服务器的IP地址及对应端口），LVS（TUN）模式要求真实服务器可以直接与外部网络连接，真实服务器在收到请求数据包后直接给客户端主机响应数据。 3、基于DR的LVS负载均衡 在LVS（TUN）模式下，由于需要在LVS调度器与真实服务器之间创建隧道连接，这同样会增加服务器的负担。与LVS（TUN）类似，DR模式也叫直接路由模式，其体系结构如图4所示，该模式中LVS依然仅承担数据的入站请求以及根据算法选出合理的真实服务器，最终由后端真实服务器负责将响应数据包发送返回给客户端。与隧道模式不同的是，直接路由模式（DR模式）要求调度器与后端服务器必须在同一个局域网内，VIP地址需要在调度器与后端所有的服务器间共享，因为最终的真实服务器给客户端回应数据包时需要设置源IP为VIP地址，目标IP为客户端IP，这样客户端访问的是调度器的VIP地址，回应的源地址也依然是该VIP地址（真实服务器上的VIP），客户端是感觉不到后端服务器存在的。由于多台计算机都设置了同样一个VIP地址，所以在直接路由模式中要求调度器的VIP地址是对外可见的，客户端需要将请求数据包发送到调度器主机，而所有的真实服务器的VIP地址必须配置在Non-ARP的网络设备上，也就是该网络设备并不会向外广播自己的MAC及对应的IP地址，真实服务器的VIP对外界是不可见的，但真实服务器却可以接受目标地址VIP的网络请求，并在回应数据包时将源地址设置为该VIP地址。调度器根据算法在选出真实服务器后，在不修改数据报文的情况下，将数据帧的MAC地址修改为选出的真实服务器的MAC地址，通过交换机将该数据帧发给真实服务器。整个过程中，真实服务器的VIP不需要对外界可见。 lvs负载均衡调度算法 根据前面的介绍，我们了解了LVS的三种工作模式，但不管实际环境中采用的是哪种模式，调度算法进行调度的策略与算法都是LVS的核心技术，LVS在内核中主要实现了一下十种调度算法。 1.轮询调度 轮询调度（Round Robin 简称'RR'）算法就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是实现简单。轮询算法假设所有的服务器处理请求的能力都一样的，调度器会将所有的请求平均分配给每个真实服务器。 2.加权轮询调度 加权轮询（Weight Round Robin 简称'WRR'）算法主要是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1，服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。 3.最小连接调度 最小连接调度（Least Connections 简称'LC'）算法是把新的连接请求分配到当前连接数最小的服务器。最小连接调度是一种动态的调度算法，它通过服务器当前活跃的连接数来估计服务器的情况。调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1；当连接中断或者超时，其连接数减1。 （集群系统的真实服务器具有相近的系统性能，采用最小连接调度算法可以比较好地均衡负载。) 4.加权最小连接调度 加权最少连接（Weight Least Connections 简称'WLC'）算法是最小连接调度的超集，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 5.基于局部的最少连接 基于局部的最少连接调度（Locality-Based Least Connections 简称'LBLC'）算法是针对请求报文的目标IP地址的 负载均衡调度，目前主要用于Cache集群系统，因为在Cache集群客户请求报文的目标IP地址是变化的。这里假设任何后端服务器都可以处理任一请求，算法的设计目标是在服务器的负载基本平衡情况下，将相同目标IP地址的请求调度到同一台服务器，来提高各台服务器的访问局部性和Cache命中率，从而提升整个集群系统的处理能力。LBLC调度算法先根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则使用'最少连接'的原则选出一个可用的服务器，将请求发送到服务器。 6.带复制的基于局部性的最少连接 带复制的基于局部性的最少连接（Locality-Based Least Connections with Replication 简称'LBLCR'）算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统，它与LBLC算法不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。按'最小连接'原则从该服务器组中选出一一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按'最小连接'原则从整个集群中选出一台服务器，将该服务器加入到这个服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。 7.目标地址散列调度 目标地址散列调度（Destination Hashing 简称'DH'）算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。 8.源地址散列调度U 源地址散列调度（Source Hashing 简称'SH'）算法先根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法的相同，它的算法流程与目标地址散列调度算法的基本相似。 9.最短的期望的延迟 最短的期望的延迟调度（Shortest Expected Delay 简称'SED'）算法基于WLC算法。举个例子吧，ABC三台服务器的权重分别为1、2、3 。那么如果使用WLC算法的话一个新请求进入时它可能会分给ABC中的任意一个。使用SED算法后会进行一个运算 A：（1+1）/1=2 B：（1+2）/2=3/2 C：（1+3）/3=4/3 就把请求交给得出运算结果最小的服务器。 10.最少队列调度 最少队列调度（Never Queue 简称'NQ'）算法，无需队列。如果有realserver的连接数等于0就直接分配过去，不需要在进行SED运算。 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-16 20:59:47 "},"linux/commond.html":{"url":"linux/commond.html","title":"linux基础命令","keywords":"","body":"系统管理的基础知识 系统命令提示组成 【root@hostname ~】# ---------命令提示符 作用:只有在命令提示符后面输入命令才有效果 组成： 1)登录用户的信息 2）@分隔符 3）主机名信息 4）当前所在系统的目录路径信息 系统命令是有语法规范 命令 参数 文件/路径 命令与参数之间有空格分隔 系统目录结构简介 linux目录结构从根开始 绝对路径:从根开始查处文件 缺点：寻找数据速度慢 优点：准确性高 相对路径：从当前位置 查找文件 优点：找数据速度更快 缺点：准确性低 系统的操命令 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-27 19:59:23 "},"linux/time_synchronism.html":{"url":"linux/time_synchronism.html","title":"linux时间","keywords":"","body":"时间管理 1、查看时间信息: [root@web01 /etc]# date Sun May 9 16:06:04 CST 2021 2、 调整时间显示格式 [root@web01 /etc]# date +%F 2021-05-09 [root@web01 /etc]# date \"+%F %T\" 2021-05-09 16:07:27 [root@web01 /etc]# date \"+%Y +%F %T\" 2021 +2021-05-09 16:07:58 [root@web01 /etc]# date \"+%Y-%m +%F %T\" 2021-05 +2021-05-09 16:09:03 [root@web01 /etc]# date \"+%Y-%m-%d +%F %T\" 2021-05-09 +2021-05-09 16:09:15 #显示历史时间信息: [root@web01 /etc]# date +%F -d \"-2day\" 2021-05-07 [root@web01 /etc]# date +%F -d \"1 day ago\" 2021-05-08 #显示未来时间信息: [root@web01 /etc]# # date -d \"+2day\" [root@web01 /etc]# date -d \"+2day\" Tue May 11 16:11:32 CST 2021 [root@web01 /etc]# date -d \"2day\" Tue May 11 16:11:47 CST 2021 3、如何实际修改系统时间 [root@web01 /etc]# date -s \"2020-04-17\" Fri Apr 17 00:00:00 CST 2020 [root@web01 /etc]# date Fri Apr 17 00:00:02 CST 2020 [root@web01 /etc]# date -s \"2020/04/17 14:00\" Fri Apr 17 14:00:00 CST 2020 [root@web01 /etc]# 4、时间同步 [root@web01 /etc]# yum install -y ntpdate ntp #配置ntp [root@web01 /var/lib/ntp]# vim /etc/ntp.conf 21 #server 0.centos.pool.ntp.org iburst 22 #server 1.centos.pool.ntp.org iburst 23 #server 2.centos.pool.ntp.org iburst 24 #server 3.centos.pool.ntp.org iburst 25 server ntp1.aliyun.com 在ntpd服务启动时，先使用ntpdate命令同步时间： [root@web01 ~]# ntpdate ntp1.aliyun.com [root@web01 /var/lib/ntp]# systemctl restart ntpd Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-09 16:57:05 "},"linux/fictory.html":{"url":"linux/fictory.html","title":"系统目录结构","keywords":"","body":"系统目录结构 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-03 13:22:21 "},"linux/majorzation.html":{"url":"linux/majorzation.html","title":"linux系统优化","keywords":"","body":"系统优化 1、系统的优化方法（基础优化） #1）了解系统的环境 #两个命令： # a)、cat /etc/redhat-release ------获得系统发行版本和具体系统版本信息 [root@web01 ~]# cat /etc/redhat-release CentOS Linux release 7.5.1804 (Core) # b)、 uname -a [root@web01 ~]# uname -a Linux web01 3.10.0-862.el7.x86_64 #1 SMP Fri Apr 20 16:44:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux #记忆centos7系统的内核信息 #Q：一起你用的LINUX系统是什么环境的？ #a: centos7 具体型号7.5 内核3.10 64位 2、操作系统优化---命令提示符优化 #优化方法: 修改PS1环境变量 #默认配置: [root@web01 ~]# echo $PS1 [\\u@\\h \\W]\\$ # \\u --- 显示当前登录用户名称 # \\h --- 显示系统主机名称 # \\W --- 显示当前所在目录信息(目录结构的最后结尾信息) 修改优化方法: 01. 修改命令提示符的内容: # ------显示全路径 vi /etc/profile 加入 export PS1='[\\u@\\H \\w]\\$' [root@web01 /etc/sysconfig]# source /etc/profile 02. 命令提示符如何修改颜色 # Linxu系统中如何给信息加颜色 \\[\\e[F;Bm] 文字内容 \\e[m ”[\\[\\e[31;40m]\\u\\e[m @\\h \\W]\\$ “ [root@web01 ~]# tail -5 /etc/profile export PS1='\\[\\e[32;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' 设置颜色 内容 结束 export PS1='\\[\\e[30;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 黑色提示符 export PS1='\\[\\e[31;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 红色提示符 export PS1='\\[\\e[32;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 绿色提示符 export PS1='\\[\\e[33;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 黄色提示符 export PS1='\\[\\e[34;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 蓝色提示符 export PS1='\\[\\e[35;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 粉色 export PS1='\\[\\e[36;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 浅蓝 export PS1='\\[\\e[37;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 白色 实现命令提示符是彩色的 #实现以上效果方法,在/etc/profile底行输入: [root@web01 /etc/sysconfig]# vim /etc/profile export PS1='[\\[\\e[31;1m\\]\\u@\\[\\e[32;1m\\]\\h\\[\\e[36;1m\\] \\w\\[\\e[33;1m\\]]\\$ ' 3、操作系统优化-----yum下载源优化 yum软件优势: 简单 快捷 01. 不需要到官方网站单独下载软件包(yum仓库) 02. 可以解决软件的依赖关系 yum优化方法: 1. 优化基础的yum源文件， #1）更换阿里云或者网易源 #通过阿里镜像源进行优化: curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #更新网易源 curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo 2） #运行以下命令生成缓存： yum clean all yum makecache 02. 优化扩展的yum源文件 #通过阿里镜像源进行优化: # wget -O /etc/yum.repos.d/epe l.repo http://mirrors.aliyun.com/repo/epel-7.repo #检查可用的yum源信息 #yum repolist #如何查看软件是否安装? #利用rpm命令查看软件是否安装 #rpm -qa 查询的软件 --------q表示查询,-a表示所有 #查看软件包中有哪些信息 rpm -ql 软件名称 ---- -l表示列表显示 #查看文件信息属于哪个软件大礼包 #which 软件名称 #rpm -qf `软件名称 ` 4. 系统安全相关优化(将一些安全服务进行关闭) 1). 防火墙服务程序 centos6 查看防护墙服务状态 /etc/init.d/iptables status 临时关闭防火墙服务 /etc/init.d/iptables stop /etc/init.d/iptables status 永久关闭防火墙服务 chkconfig iptables off centos7 查看防火墙服务状态 systemctl status firewalld 临时关闭防火墙服务 systemctl stop firewalld systemctl status firewalld -- 操作完确认 永久关闭防火墙服务 systemctl disable firewalld 补充: 查看服务状态信息简便方法 systemctl is-active firewalld --- 检查服务是否正常运行 systemctl is-enabled firewalld --- 检查确认服务是否开机运行 4、关闭selinux服务程序 1.什么是selinux： selinux(security enhanced linux)安全增强型linux系统，它是一个linux内核模块，也是linux的一个安全子系统。 selinux的主要作用就是最大限度地减小系统中服务进程可访问的资源（最小权限原则） 2.selinux有两个级别 强制和警告 setenforce 0|1 0表示警告(Permissive)，1表示强制（Enforcing） 3.selinux相当于一个插件 (内核级的插件) 4.selinux功能开启后，会关闭系统中不安全的功能 5.查看日志中的警告：cat /var/log/audit/audit.log 临时关闭: 检查确认: getenforce --- 确认selinux服务是否开启或是关闭的 如何关闭: [root@web01 /etc]# setenforce usage: setenforce [ Enforcing | Permissive | 1 | 0 ] Enforcing 1 --- 临时开启selinux Permissive 0 --- 临时关闭selinux setenforce 0 --- 临时关闭selinux服务 永久关闭: enforcing - SELinux security policy is enforced. （selinux服务处于正常开启状态） permissive - SELinux prints warnings instead of enforcing.（selinux服务被临时关闭了） disabled - No SELinux policy is loaded.（selinux服务彻底关闭） vi /etc/selinux/config SELINUX=disabled PS: 如果想让selinux配置文件生效,重启系统 05、字符编码优化 出现乱码的原因: 01. 系统字符集设置有问题 02. 远程软件字符集设置有问题 03. 文件编写字符集和系统查看的字符集不统一 出现乱码的原因: 01. 系统字符集设置有问题 02. 远程软件字符集设置有问题 03. 文件编写字符集和系统查看的字符集不统一 centos6 设置方法 # 查看默认编码信息: [root@web01 /etc]# echo $LANG --- LANG用于设置字符编码信息 en_US.UTF-8 #临时修改: [root@web01 ~]# LANG=XXX #永久修改: #方法一: [root@web01 ~]# tail -5 /etc/profile export LANG='en_US.UTF-8' #方法二: vi /etc/sysconfig/i18n LANG='en_US.UTF-8 source /etc/sysconfig/i18n centos7设置方法 # 查看默认编码信息 [root@web01 ~]# echo $LANG en_US.UTF-8 # 临时修改: [root@web01 ~]# echo $LANG en_US.UTF-8 LANG=XXX # 永久修改: # 方法一: 更加有先 [root@web01 ~]# tail -5 /etc/profile export LANG='en_US.UTF-8' # 方法二: [root@web01 ~]# cat /etc/locale.conf LANG=\"zh_CN.UTF-8\" # 补充：一条命令即临时设置，又永久设置 localectl set-locale LANG=zh_CN.GBK 06、使xshell软件远程连接速度加快 #第一个步骤：修改ssh服务配置文件 vi /etc/ssh/sshd_config 79 GSSAPIAuthentication no 115 UseDNS no #第二个步骤：重启ssh远程服务 systemctl restart sshd 7、时间同步：[时间同步]（linux/time_synchronism.md） Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-09 16:03:08 "},"linux/Disk_partition.html":{"url":"linux/Disk_partition.html","title":"linux磁盘分区","keywords":"","body":"磁盘分区 #不关机，添加硬盘，自动识别 [root@web01 ~]# echo \"- - -\" > /sys/class/scsi_host/host0/scan 1、磁盘分区实践--磁盘小于2T 第一个里程: 准备磁盘环境 准备了一块新的10G硬盘 第二个里程: 在系统中检查是否识别到了新的硬盘 fdisk -l --- 查看分区信息 [root@web01 ~]# echo \"- - -\" > /sys/class/scsi_host/host0/scan # 查看分区信息 [root@web01 ~]# fdisk -l 第三个里程: 对磁盘进行分区处理(fdisk-- 进行分区处理 查看分区信息) 指令说明 d delete a partition ***** 删除分区 g create a new empty GPT partition table 创建一个新的空的GPT分区表(可以对大于2T磁盘进行分区) l list known partition types 列出可以分区的类型??? m print this menu 输出帮助菜单 n add a new partition ***** 新建增加一个分区 p print the partition table ***** 输出分区的结果信息 q quit without saving changes 不保存退出 t change a partition's system id 改变分区的系统id==改变分区类型(LVM 增加swap分区大小) u change display/entry units 改变分区的方式 是否按照扇区进行划分 w write table to disk and exit ***** 将分区的信息写入分区表并退出==保存分区信息并退出 a ) 规划分4个主分区 ,1,2分区1g,3分区10g,其余的给第四分区 [root@web01 ~]# fdisk /dev/sdc Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-41943039, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p Partition number (2-4, default 2): First sector (2099200-41943039, default 2099200): Using default value 2099200 Last sector, +sectors or +size{K,M,G} (2099200-41943039, default 41943039): +1G Partition 2 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): First sector (4196352-41943039, default 4196352): Last sector, +sectors or +size{K,M,G} (20971520-41943039, default 41943039): +10G Using default value 41943039 Partition 3 of type Linux and of size 10 GiB is set Command (m for help): n Partition type: p primary (3 primary, 0 extended, 1 free) e extended Select (default e): p Selected partition 4 First sector (4196352-41943039, default 4196352): Using default value 4196352 Last sector, +sectors or +size{K,M,G} (4196352-20971519, default 20971519): Using default value 20971519 Partition 4 of type Linux and of size 8 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 20971520 41943039 10485760 83 Linux /dev/sdc4 4196352 20971519 8387584 83 Linux Partition table entries are not in disk order Command (m for help): w b) 规划分3个主分区 1个扩展分区 每个主分区1G 剩余都给扩展分区 [root@web01 ~]# fdisk /dev/sdc Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): First sector (2048-41943039, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): 1G Value out of range. Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p Partition number (2-4, default 2): First sector (2099200-41943039, default 2099200): Using default value 2099200 Last sector, +sectors or +size{K,M,G} (2099200-41943039, default 41943039): +1G Partition 2 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): First sector (4196352-41943039, default 4196352): Using default value 4196352 Last sector, +sectors or +size{K,M,G} (4196352-41943039, default 41943039): +1G Partition 3 of type Linux and of size 1 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux Command (m for help): n Partition type: p primary (3 primary, 0 extended, 1 free) e extended Select (default e): e Selected partition 4 First sector (6293504-41943039, default 6293504): Using default value 6293504 Last sector, +sectors or +size{K,M,G} (6293504-41943039, default 41943039): Using default value 41943039 Partition 4 of type Extended and of size 17 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux /dev/sdc4 6293504 41943039 17824768 5 Extended Command (m for help): n All primary partitions are in use Adding logical partition 5 First sector (6295552-41943039, default 6295552): Using default value 6295552 Last sector, +sectors or +size{K,M,G} (6295552-41943039, default 41943039): +1G Partition 5 of type Linux and of size 1 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux /dev/sdc4 6293504 41943039 17824768 5 Extended /dev/sdc5 6295552 8392703 1048576 83 Linux Command (m for help): ###说明： #### 有了扩展分区才能逻辑分区，扩展分区不能直接使用，只能在逻辑分区种才能使用 第四个里程: 保存退出,让系统可以加载识别分区信息 #输入w,保存退出 Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. #让系统可以加载识别分区文件 [root@web01 ~]# partprobe /dev/sdc 第五个里程：格式化磁盘 [root@web01 ~]# partprobe /dev/sdc # ext3/4 centos6 # xfs centos7 格式效率较高 数据存储效率提升(数据库服务器) [root@web01 ~]# mkfs -t xfs /dev/sdc1 meta-data=/dev/sdc1 isize=512 agcount=4, agsize=65536 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=262144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@web01 ~]# mkfs.xfs /dev/sdc2 meta-data=/dev/sdc2 isize=512 agcount=4, agsize=65536 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=262144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 2、磁盘分区实践--磁盘大于2T 第一个里程: 准备磁盘环境 虚拟主机中添加一块3T硬盘 第二个里程: 使用parted命令进行分区 帮助说明 mklabel,mktable LABEL-TYPE create a new disklabel (partition table) 创建一个分区表 (默认为mbr) print [devices|free|list,all|NUMBER] display the partition table, available devices, free space, all found partitions, or a particular partition 显示分区信息 mkpart PART-TYPE [FS-TYPE] START END make a partition 创建一个分区 quit exit program 退出分区状态 rm NUMBER delete partition NUMBER 删除分区 [root@web01 ~]# parted /dev/sdd GNU Parted 3.1 Using /dev/sdd Welcome to GNU Parted! Type 'help' to view a list of commands. (parted) mklabel gpt (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags (parted) mkpart primary 0 2100G Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? Ignore (parted) mkpart primary 2100 2200G Warning: You requested a partition from 2100MB to 2200GB (sectors 4101562..4296875000). The closest location we can manage is 2100GB to 2200GB (sectors 4101562501..4296875000). Is this still acceptable to you? Yes/No? yes Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? Ignore #查看分区 (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 17.4kB 2100GB 2100GB primary 2 2100GB 2200GB 100GB primary #删除第二个分区 (parted) rm 2 (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 17.4kB 2100GB 2100GB primary (parted) mkpart primary 2100 2200G Warning: You requested a partition from 2100MB to 2200GB (sectors 4101562..4296875000). The closest location we can manage is 2100GB to 2200GB (sectors 4101562501..4296875000). Is this still acceptable to you? Yes/No? yes Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? ingnore parted: invalid token: ingnore Ignore/Cancel? Ignore #退出分区模式 (parted) quit Information: You may need to update /etc/fstab. 第三个里程: 加载磁盘分区 [root@web01 ~]# partprobe /dev/sdd 第四个里程:格式化分区 [root@web01 ~]# mkfs.xfs /dev/sdd1 meta-data=/dev/sdd1 isize=512 agcount=4, agsize=128173827 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=512695308, imaxpct=5 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=250339, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@web01 ~]# 3、挂载分区 3.1 手动挂载 #创建挂在目录 [root@web01 ~]# mkdir /mount01 [root@web01 ~]# mount /dev/sdc1 /mount01 #查看挂载结果 [root@web01 ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos_wjh-root 19G 2.2G 17G 12% / devtmpfs 476M 0 476M 0% /dev tmpfs 488M 0 488M 0% /dev/shm tmpfs 488M 7.7M 480M 2% /run tmpfs 488M 0 488M 0% /sys/fs/cgroup /dev/sda1 197M 108M 90M 55% /boot tmpfs 98M 0 98M 0% /run/user/0 /dev/sdc1 1014M 33M 982M 4% /mount01 3.2 开机自动挂载 方法一: 将挂载命令放入/etc/rc.local [root@web01 ~]# vim /etc/rc.local [root@web01 ~]# tail -2 /etc/rc.local touch /var/lock/subsys/local mount /dev/sdc1 /mount01 [root@web01 ~]# chmod +x /etc/rc.d/rc.local 方法二: 在/etc/fstab文件中进行设置 #查看uuid [root@web01 ~]# blkid /dev/sda1: UUID=\"ef56a16b-6ffe-4ee9-84bc-54519c404628\" TYPE=\"xfs\" /dev/sda2: UUID=\"9mzWRG-c76T-l0GG-nMAm-KjJ0-vA3V-8s1UcP\" TYPE=\"LVM2_member\" /dev/sdc1: UUID=\"719b1119-bc16-421f-9039-032fc874e302\" TYPE=\"xfs\" /dev/sdc2: UUID=\"895dac6f-5864-4f0d-9a58-0ed43bf690a8\" TYPE=\"xfs\" /dev/mapper/centos_wjh-root: UUID=\"c570790b-11f1-4237-835a-06115e3b4890\" TYPE=\"xfs\" /dev/mapper/centos_wjh-swap: UUID=\"130c3eaf-c634-4f5b-8cf2-21d48c3956d4\" TYPE=\"swap\" /dev/sdd1: UUID=\"bcc9ed95-532b-4c9e-a697-9d66bae6a3c8\" TYPE=\"xfs\" PARTLABEL=\"primary\" PARTUUID=\"4e66de18-0674-4b4a-b784-d93332dbf466\" /dev/sdd2: PARTLABEL=\"primary\" PARTUUID=\"3b280fe8-5d0a-414a-aafc-2772ecffb2e0\" ##使用uuid或者直接行磁盘路径 [root@web01 ~]# tail -2 /etc/fstab #/dev/sdd1 /mount2 xfs defaults 0 0 UUID=bcc9ed95-532b-4c9e-a697-9d66bae6a3c /mount2 xfs defaults 0 0 4、企业磁盘常见问题: 1) 磁盘满的情况 No space left on device a)存储的数据过多了 block存储空间不足了 解决方式: a 删除没用的数据 b 找出大的没用的数据 find / -type f -size +xxx du -sh /etc/sysconfig/network-scripts/*|sort -h (按照数值排序命令) b) 存储的数据过多了 inode存储空间不足了: 出现了大量小文件 df -i 查看inode 解决方式: 删除大量的没用的小文件 5、swap分区调整 第一步： 将磁盘分出一部分空间给swap分区使用 [root@web01 ~]# dd if=/dev/zero of=/tmp/1G bs=100M count=10 第二步： 将指定磁盘空间作为swap空间使用 [root@web01 ~]# mkswap /tmp/1G Setting up swapspace version 1, size = 1023996 KiB no label, UUID=9a9aed5d-aade-41ba-8a1a-6f67275c2873 第三步： 加载使用swap空间 [root@web01 ~]# swapon /tmp/1G swapon: /tmp/1G: insecure permissions 0644, 0600 suggested. [root@web01 ~]# free -h total used free shared buff/cache available Mem: 974M 119M 164M 25M 691M 662M Swap: 2.0G 0B 2.0G ## swap足够时，释放资源 [root@web01 ~]# swapoff /tmp/1G [root@web01 ~]# free -h total used free shared buff/cache available Mem: 974M 118M 164M 25M 691M 663M Swap: 1.0G 0B 1.0G [root@web01 ~]# rm /tmp/1G -f [root@web01 ~]# ` Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 19:40:39 "},"nginx/install.html":{"url":"nginx/install.html","title":"安装","keywords":"","body":"安装 二进制编译安装 1、下载安装包 [root@wjh ~]# mkdir -p /data/soft [root@wjh ~]# cd /data/soft/ [root@wjh soft]# wget http://nginx.org/download/nginx-1.16.0.tar.gz [root@wjh soft]# tar -zxvf nginx-1.16.0.tar.gz [root@wjh soft]# cd nginx-1.16.0/ 2、解决依赖问题 [root@wjh nginx-1.16.0]# yum -y install openssl-devel pcre-devel 3、指定安装的路径，安装的模块 # --prefix=PATH set installation prefix （指定程序安装路径） # --user=USER set non-privileged user for worker processes（设置一个虚拟用户管理worker进程(安全)） # --group=GROUP set non-privileged group for worker processes(设置一个虚拟用户组管理worker进程(安全)) # --http-log-path=PATH set http access log pathname(日志路径) # --error-log-path= c错误日志路径 # [root@wjh nginx-1.16.0]# ./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --with-pcre-jit --with-http_ssl_module --with-http_v2_module --with-http_sub_module --with-stream --with-stream_ssl_module 4、编译安装 [root@wjh nginx-1.16.0]# make & make install 5、创建启动文件 #1.在系统服务目录里创建nginx.service文件 [root@wjh nginx-1.16.0]# cat >/lib/systemd/system/nginx.service 6、启动程序 [root@wjh ~]# systemctl daemon-reload [root@wjh ~]# systemctl start nginx [root@wjh ~]# systemctl status nginx ● nginx.service - nginx Loaded: loaded (/usr/lib/systemd/system/nginx.service; disabled; vendor preset: disabled) Active: active (running) since Fri 2021-05-14 10:07:34 CST; 7s ago Process: 4871 ExecStart=/usr/local/nginx/sbin/nginx (code=exited, status=0/SUCCESS) Main PID: 4872 (nginx) CGroup: /system.slice/nginx.service ├─4872 nginx: master process /usr/local/nginx/sbin/nginx └─4873 nginx: worker process May 14 10:07:34 wjh systemd[1]: Starting nginx... May 14 10:07:34 wjh systemd[1]: Started nginx. [root@wjh ~]# systemctl enable nginx Created symlink from /etc/systemd/system/multi-user.target.wants/nginx.service to /usr/lib/systemd/system/nginx.service. [root@wjh ~]# 在线安装 1、更新nginx官方yum源 cat > /etc/yum.repos.d/nginx.repo 2、yum安装 [root@wjh ~]#yum install -y nginx 3、启动 [root@wjh ~]# systemctl start nginx [root@wjh ~]# systemctl enable nginx 配置文件说明 第一个部分: 配置文件主区域配置 user www; --- 定义worker进程管理的用户 补充: nginx的进程 master process: 主进程 ---管理服务是否能够正常运行 boss worker process: 工作进程 ---处理用户的访问请求 员工 worker_processes 2; ---定义有几个worker进程 == CPU核数 / 核数的2倍 error_log /var/log/nginx/error.log warn; --- 定义错误日志路径信息 pid /var/run/nginx.pid; --- 定义pid文件路径信息 第二个部分: 配置文件事件区域 events { worker_connections 1024; --- 一个worker进程可以同时接收1024访问请求 } 第三个部分: 配置http区域 http { include /etc/nginx/mime.types; --- 加载一个配置文件 default_type application/octet-stream; --- 指定默认识别文件类型 log_format oldboy '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; --- 定义日志的格式 access_log /var/log/nginx/access.log oldboy; --- 指定日志路径 keepalive_timeout 65; --- 超时时间 #gzip on; include /etc/nginx/conf.d/*.conf; --- 加载一个配置文件 } /etc/nginx/nginx.d/default --- 扩展配置(虚拟主机配置文件) 第四个部分: server区域信息(配置一个网站 www/bbs/blog -- 一个虚拟主机) server { listen 8080; --- 指定监听的端口 server_name www.oldboy.com; --- 指定网站域名 root /usr/share/nginx/html; --- 定义站点目录的位置 index index.html index.htm; --- 定义首页文件 error_page 500 502 503 504 /50x.html; --- 优雅显示页面信息 location = /50x.html { root /usr/share/nginx/html; } } Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-15 12:44:06 "},"nginx/virtual_host.html":{"url":"nginx/virtual_host.html","title":"虚拟主机","keywords":"","body":"虚拟主机 1) 利用nginx服务搭建网站文件共享服务器 [root@wjh conf.d]# cat file.conf server { listen 80; server_name www.testk.com; location / { root /data; #配置账户 # auth_basic \"wjhtest-sz-01\"; #配置密码 # auth_basic_user_file password/htpasswd; autoindex on; # --- 修改目录结构中出现的中文乱码问题 charset utf-8; } } # 说明： # 1. 需要将首页文件进行删除 # 2. mime.types媒体资源类型文件作用 # 文件中有的扩展名信息资源, 进行访问时会直接看到数据信息 # 文件中没有的扩展名信息资源, 进行访问时会直接下载资源 2) 利用nginx服务搭建网站 server { listen 80; server_name www.testk.com; root /data/www/keep_com; index index.html; error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } #根据路径指定访问目录 location /dev { root /data; #指定ip端可以访问 deny ip； allow ip; } } 3）https配置 server { listen 443; server_name https.test.com; ssl om; # --指定srt的目录信息 ssl_certificate ssl_key/server.crt; # ----指定key的目录 ssl_certificate_key ssl_key/server.key; location / { root /code/https; index index.html; } } server { listen 80; server_named rewrite .* https://$server_name$request_rui redirect; } #PS：负载均衡配置https时，只需要再LB的机器配置https，运行程序的主机不需要配置htps Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-15 12:44:06 "},"nginx/lnmp.html":{"url":"nginx/lnmp.html","title":"lnmp","keywords":"","body":"lnmp配置 网站的LNMP架构是什么 L --- linux系统 注意: a selinux必须关闭 防火墙关闭 b /tmp 1777 mysql服务无法启动 N --- nginx服务部署 作用: 处理用户的静态请求 html jpg txt mp4/avi P --- php服务部署 作用: 1. 处理动态的页面请求 2. 负责和数据库建立关系 M --- mysql服务部署 (yum会很慢 编译安装会报错) mariadb 作用: 存储用户的字符串数据信息 nginx安装：nginx安装 mysql安装配置：mysql安装 php安装配置 #安装路径：/usr/local/php # 先安装如下依赖包 [root@wjh mysql]# wget https://www.php.net/distributions/php-7.3.28.tar.gz [root@wjh mysql]# yum install -y gcc gcc-c++ make zlib zlib-devel pcre pcre-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers #解压文件 [root@wjh php-7.2.0]# tar -zxvf php-7.2.0.tar.gz [root@wjh tools]# cd php-7.2.0/ #指定安装目录，指定安装模块 [root@wjh tools]# ./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php --enable-mbstring --with-openssl --enable-ftp --with-gd --with-jpeg-dir=/usr --with-png-dir=/usr --with-mysql=mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-pear --enable-sockets --with-freetype-dir=/usr --with-zlib --with-libxml-dir=/usr --with-xmlrpc --enable-zip --enable-fpm --enable-xml --enable-sockets --with-gd --with-zlib --with-iconv --enable-zip --with-freetype-dir=/usr/lib/ --enable-soap --enable-pcntl --enable-cli --with-curl |# 编译完成之后，执行安装命令： [root@wjh tools]# make && make install Wrote PEAR system config file at: /usr/local/php/etc/pear.conf You may want to add: /usr/local/php/lib/php to your php.ini include_path /server/tools/php-7.2.0/build/shtool install -c ext/phar/phar.phar /usr/local/php/bin ln -s -f phar.phar /usr/local/php/bin/phar Installing PDO headers: /usr/local/php/include/php/ext/pdo/ 【配置PHP】 #在之前编译的源码包中，找到 php.ini-production，复制到/usr/local/php下，并改名为php.ini： #[可选项] 设置让PHP错误信息打印在页面上 [root@wjh php-7.2.0]# cp php.ini-production /usr/local/php/php.ini [root@wjh php-7.2.0]# vim /usr/local/php/php.ini +477 [root@wjh php-7.2.0]# sed -i '477cdisplay_errors = On' /usr/local/php/php.ini|grep display_er #复制启动脚本： [root@wjh php-7.2.0]# cp ./sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm [root@wjh php-7.2.0]# chmod +x /etc/init.d/php-fpm # 修改php-fpm配置文件： #1、去掉 pid = run/php-fpm.pid 前面的分号 [root@wjh php-7.2.0]# cd /usr/local/php/etc [root@wjh etc]# cp php-fpm.conf.default php-fpm.conf [root@wjh etc]# sed '17cpid = run/php-fpm.pid' php-fpm.conf #2、修改user和group的用户为当前用户(也可以不改，默认会添加nobody这个用户和用户组) [root@wjh etc]# [root@wjh php-fpm.d]# cp www.conf.default www.conf [root@wjh php-fpm.d]# vim www.conf [root@wjh php-fpm.d]# sed -i 's#user = nobody#user = nginx#g' www.conf [root@wjh php-fpm.d]# sed -i 's#group = nobody#group = nginx#g' www.conf 【启动PHP】 $ /etc/init.d/php-fpm start #php-fpm启动命令 $ /etc/init.d/php-fpm stop #php-fpm停止命令 $ /etc/init.d/php-fpm restart #php-fpm重启命令 $ ps -ef | grep php 或者 ps -A | grep -i php #查看是否已经成功启动PHP 【PHP7.2的MySQL扩展】 #解压，并进入目录： [root@wjh tools]# cd mysql-24d32a0/ [root@wjh mysql-24d32a0]# /usr/local/php/bin/phpiz -bash: /usr/local/php/bin/phpiz: No such file or directory [root@wjh mysql-24d32a0]# /usr/local/php/bin/phpize Configuring for: PHP Api Version: 20170718 Zend Module Api No: 20170718 Zend Extension Api No: 320170718 #编译mysql扩展，使用mysql native driver 作为mysql链接库 [root@wjh mysql-24d32a0]# ./configure --with-php-config=/usr/local/php/bin/php-config --with-mysql=mysqlnd [root@wjh mysql-24d32a0]# make && make install Dont forget to run 'make test'. Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/ # 最后，编辑php.ini文件，在最后面加入 extension=mysql.so [root@wjh mysql-24d32a0]# sed -i '$aextension=mysql.so' /usr/local/php/php.ini 报错解决 # 错误：virtual memory exhausted: Cannot allocate memory #问题原因：由于物理内存本身很小，且阿里云服务器并没有分配swap空间，当物理内存不够用时， 3物理内存中暂时不用的内容没地方转存。 #解决方法：手动分配一个swap空间 #创建一个大小为1G的文件/swap dd if=/dev/zero of=/swap bs=1024 count=1M #将/swap作为swap空间 mkswap /swap #enable /swap file for paging and swapping swapon /swap #Enable swap on boot, 开机后自动生效 echo \"/swap swap swap sw 0 0\" >> /etc/fstab 好文要顶 关注我 收藏该文 nginx添加php编译 server { listen 80; server_name localhost; root /data/www; index index.php index.html index.htm; error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } location ~ \\.php$ { fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /$document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; include fastcgi_params; } } Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-15 17:25:23 "},"nginx/load_balanced.html":{"url":"nginx/load_balanced.html","title":"负载均衡","keywords":"","body":"负载均衡 (反向代理)负载均衡的概念说明 什么是集群? 完成相同任务或工作的一组服务器 (web01 web02 web03 -- web集群) 什么是负载均衡? 1) 实现用户访问请求进行调度分配 2) 实现用户访问压力分担 什么是反向代理? 反向代理: 外网 ---> (eth0外网) 代理服务器 (eth1内网) ---> 公司网站服务器web(内网) 外网用户(客户端) --- 代理服务器 (服务端) 代理服务器(客户端) --- web服务器(服务端) 正向代理: 内网(局域网主机) --- (内网)代理服务器(外网) --- 互联网 --- web服务器(日本) 翻墙的操作 准备负载均衡环境 01. 先部署好一台LNMP服务器,上传代码信息 02. 进行访问测试 03. 批量部署多台web服务器 04. 将nginx配置文件进行分发 05. 将站点目录分发给所有主机 ngingx安装：安装 负载配置（虚拟主机配置） 1. 轮询分配请求(平均) # ngx_http_upstream_module --- upstream 负载均衡 # ngx_http_proxy_module --- proxy_pass 反向代理 upstream wjhtest { server 10.0.0.7:80; server 10.0.0.8:80; server 10.0.0.9:80; } server { listen 80; server_name www.wjhtest.com; location / { proxy_pass http://wjhtest; } } 2. 权重分配请求(能力越强责任越重) upstream wjhtest { server 10.0.0.7:80 weight=3; server 10.0.0.8:80 weight=2; server 10.0.0.9:80 weight=1; } server { } 3. 实现热备功能(备胎功能) #当所有的主机都停止服务的时候才生效 upstream wjhtest { server 10.0.0.7:80; server 10.0.0.8:80; server 10.0.0.9:80 backup; } 4. 定义最大失败次数（健康检查参数） upstream wjhtest { server 10.0.0.7:80 weight=3 max_fails=5; server 10.0.0.8:80 weight=2 max_fails=5; server 10.0.0.9:80 backup; } 5. 定义失败之后重发的间隔时间 # fail_timeout=10s 会给失败的服务器一次机会 upstream wjhtest { server 10.0.0.7:80 weight=3 max_fails=5 fail_timeout=10s ; server 10.0.0.8:80 weight=2 max_fails=5 fail_timeout=10s ; server 10.0.0.9:80 backup; } 分发配置 # scp /usr/local/nginx/conf.d/weblb.conf 实现不同调度算法 1. rr 轮询调度算法 2. wrr 权重调度算法 3. ip_hash 算法 (出现反复登录的时候) 4. least_conn 根据服务器连接数分配资源 ip_hash 算法 upstream wjhtest { ip_hash; server 10.0.0.7:80 weight=3 max_fails=5 fail_timeout=10s ; server 10.0.0.8:80 weight=2 max_fails=5 fail_timeout=10s ; server 10.0.0.9:80 backup; } least_conn # #假如上一个请求选择了第二台10.0.0.8，下一个请求到来，通过比较剩下可用的server的conns/weight值来决定选哪一台。 #如果10.0.0.7连接数为100，10.0.0.9连接数为80，因为权重分别是2和1，因此计算结果 # 100/2=50, 80/1 =80。因为 50 负载均衡企业实践应用 需求一，根据用户访问的uri信息进行负载均衡 1、环境配置 # 10.0.0.8:80 上进行环境部署: [root@web02 ~]# mkdir /html/www/upload [root@web02 ~]# echo \"upload-web集群_10.0.0.8\" >/html/www/upload/wjhtest.html # 10.0.0.7上进行环境部署: [root@wjhtest01 html]# mkdir /html/www/static [root@wjhtest01 html]# echo static-web集群_10.0.0.7 >/html/www/static/wjhtest.html # 10.0.0.9:80上进行环境部署: echo \"default-web集群_10.0.0.9\" >/html/www/wjhtest.html 2、编写负载均衡配置文件 upstream upload { server 10.0.0.8:80; } upstream static { server 10.0.0.7:80; } upstream default { server 10.0.0.9:80; } server { listen 80; server_name www.wjhtest.com; location / { proxy_pass http://default; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } location /upload { proxy_pass http://upload; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } location /static { proxy_pass http://static; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } } 总结: 实现网站集群动静分离 01. 提高网站服务安全性 02. 管理操作工作简化 03. 可以换分不同人员管理不同集群服务器 需求二，根据用户访问的终端信息显示不同页面 第一步: 准备架构环境 iphone www.wjhtest.com --- iphone_access 10.0.0.7:80 mobile移动端集群 谷歌 www.wjhtest.com --- google_access 10.0.0.8:80 web端集群 IE 360 www.wjhtest.com --- default_access 10.0.0.9:80 default端集群 web01: echo \"iphone_access 10.0.0.7\" >/html/www/wjhtest.html web02: echo \"google_access 10.0.0.8\" >/html/www/wjhtest.html web03: echo \"default_access 10.0.0.9\" >/html/www/wjhtest.html 第二步：编写负载均衡配置文件 [root@lb01 conf.d]# cat lb.conf upstream web { server 10.0.0.8:80; } upstream mobile { server 10.0.0.7:80; } upstream default { server 10.0.0.9:80; } server { listen 80; server_name www.wjhtest.com; location / { if ($http_user_agent ~* iphone) { proxy_pass http://mobile; } if ($http_user_agent ~* Chrome) { proxy_pass http://web; } proxy_pass http://default; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } } Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-16 20:10:51 "},"nginx/keepalived_nginx.html":{"url":"nginx/keepalived_nginx.html","title":"keepalieved配置nginx高可用冗余","keywords":"","body":"keepalieved配置nginx高可用冗余 keepalived编译安装 编译安装keepalived #安装依赖 [root@wjh soft]# yum install curl gcc openssl-devel libnl3-devel net-snmp-devel libnfnetlink-devel -y # 下载软件 [root@wjh soft]# wget https://www.keepalived.org/software/keepalived-2.2.2.tar.gz #解压文件 [root@wjh soft]# tar -zxvf keepalived-2.2.2.tar.gz [root@wjh soft]# cd keepalived-2.2.2/ # 编译，指定安装路径位/usr/local/keepalived ./configure --with-init=systemd --with-systemdsystemunitdir=/usr/lib/systemd/system --prefix=/usr/local/keepalived --with-run-dir=/usr/local/keepalived/run # 安装 [root@wjh keepalived-2.2.2]# make [root@wjh keepalived-2.2.2]# make install # 可执行文件拷贝一份到系统执行文件目录，该目录在path变量里面，可以直接使用keepalived命令 cp /usr/local/keepalived/sbin/keepalived /usr/sbin/keepalived # 或者 [root@wjh keepalived-2.2.2]# ln -s /usr/local/keepalived/sbin/keepalived /usr/sbin/keepalived # keepalived附加参数文件，为了跟yum安装一致，其实是不用配置的。启动文件指定实际路径就可以了。 [root@wjh keepalived-2.2.2]# ln -s /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/keepalived # pid文件放置目录,目录可以自己定义在启动脚本里面使用 mkdir /usr/local/keepalived/run 配置system自启动文件 cat > /usr/lib/systemd/system/keepalived.service 从节点与上述操作一致 master节点配置 cat > /usr/local/keepalived/etc/keepalived/keepalived.conf backuup节点 cat > /usr/local/keepalived/etc/keepalived/keepalived.conf 监控脚本 cat >/usr/local/keepalived/etc/keepalived/chk_nginx.sh nginx配置 upstream wjhtest { server 10.0.0.7:80; server 10.0.0.8:80; server 10.0.0.9:80; } server { listen 10.0.0.3:80; server_name www.wjhtest.com; location / { proxy_pass http://wjhtest; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream error timeout http_404 http_502 http_403; } } Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-22 17:28:15 "},"nginx/rsync.html":{"url":"nginx/rsync.html","title":"rsync备份服务","keywords":"","body":"1. 什么是rsync服务 Rsync是一款开源的、快速的、多功能的、可实现全量及增量的本地或远程数据同步备份的优秀工具 2、rsync守护进程部署方式 rsync守护进程服务端配置: Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-22 17:28:15 "},"mysql/install.html":{"url":"mysql/install.html","title":"安装","keywords":"","body":"安装 1、准备工作 # 创建保存安装包的文件夹 [root@wjh ~]# mkdir -p /server/tools # 上传软件数据包 # 创建保存数据库运行程序的目录 [root@wjh ~]# mkdir -p /application # 解压文件 [root@wjh ~]# tar -xf mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz -C /appliacation/ 2、卸载系统自带的mariadb [root@wjh ~]# yum -y remove mariadb 3、创建用户 [root@wjh ~]# useradd -s /sbin/nologin mysql 4、配置环境变量 [root@db01 ~]# vim /etc/profile #文件末尾添加 export PATH=/application/mysql/bin:$PATH # 配置完成之后加载文件 [root@db01 ~]# source /etc/profile # 验证配置是否生效 [root@wjh application]# mysql -V mysql Ver 14.14 Distrib 5.7.26, for linux-glibc2.12 (x86_64) using EditLine wrapper 5、初始化数据 [root@wjh application]# mkdir /data/mysql/data -p [root@wjh application]# chown -R mysql.mysql /data [root@wjh application]# #执行初始化命令 mysqld --initialize --user=mysql --basedir=/application/mysql --datadir=/data/mysql/data --initialize 参数说明： 1、对于密码复杂度进行定制：12位，4种 2 、密码过期时间 180 root@wjh application]# mysqld --initialize-insecure --user=mysql --basedir=/application/mysql --datadir=/data/mysql/data 5.1 报错解决 错误信息： ##解决方式： [root@wjh application]# rm -rf /data/mysql/* 6、编辑配置文件 [root@wjh application]# cat >/etc/my.cnf /etc/systemd/system/mysqld.service 启动服务 [root@wjh application]# systemctl start mysqld [root@wjh application]# systemctl status mysqld 调错方法 如何分析处理MySQL数据库无法启动 without updating PID 类似错误 # 日志文件位置 # 查看、etc/my.cnf 中datadir配置的路径 [root@wjh application]# cat /data/mysql/data/wjh.err # 可能情况： # /etc/my.cnf 路径不对等 # /tmp/mysql.sock文件修改过 或 删除过 # 数据目录权限不是mysql # 参数改错了 2、将日志直接显示到屏幕 [root@wjh ~]# /application/mysql/bin/mysqld --defaults-file=/etc/my.cnf 密码管理 管理密码设定 ~]# mysqladmin -uroot -p password wjh123 管理员忘记密码重设 # --skip-grant-tables #跳过授权表 # --skip-networking #跳过远程登录 # 第一步：关闭数据库 ~] # /etc/init.d/mysqld stop # 第二步：启动数据库到维护模式 ~] # mysql_sate --skip-grant-tables --skip-networking & # 第三步：登陆并修改服务器 mysql> alter user root@'localhost' identified by '123456'; ##可能遇到的报错 ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statement #执行一下操作 mysql> flush privileges; mysql> alter user root@'localhost' identified by '123456'; # 第四步：关闭服务器重新启动 ~]# /etc/init.d/mysqld restart Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-23 18:56:01 "},"mysql/sql.html":{"url":"mysql/sql.html","title":"数据库操作","keywords":"","body":"数据库操作 用户的操作 建用户 mysql> create user oldboy@'10.0.0.%' identified by '123'; Query OK, 0 rows affected (0.00 sec) 修改用户密码 mysql> alter user wjh@'localhost' indentified by '123456'; 权限管理 权限列表 -- ALL -- SELECT,INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE --- 授权命令 grant all on *.* to oldguo@'10.0.0.%' identified by '123' with grant option; --- 1. 创建一个应用用户wordpress，可以通过10网段，wordpress库下的所有表进行SELECT,INSERT, UPDATE, DELETE. mysql> grant SELECT,INSERT, UPDATE, DELETE wordpres.* to wordpress@'10.0.0.%' indentified by '123456' with grant option ----查看用户权限 mysql> show grants for wordpress@'10.0.0.%' --- 权限回收 mysql> revoke delete on wordpress.* from 'wordpress'@'10.0.0.%'; DDL的应用--数据定义语言 库的定义 ---- 创建数据库 CREATE DATABASE zabbix CHARSET utf8mb4 COLLATE utf8mb4_bin; ---- 收看数据库 SHOW DATABASES; ---- 删除数据库 DROP DATABASE TEST; ---- 修改数据库字符集 ----- 注意：一定是从小往大改，如utf8==>utf8mb4 ----- 目标字符集一定是源字符集的严格超级； alter table test charset utf8mb4; 表定义 创建表 --- 建表 表名,列名,列属性,表属性 --- 列属性 PRIMARY KEY : 主键约束,表中只能有一个,非空且唯一. NOT NULL : 非空约束,不允许空值 UNIQUE KEY : 唯一键约束,不允许重复值 DEFAULT : 一般配合 NOT NULL 一起使用. UNSIGNED : 无符号,一般是配合数字列,非负数 COMMENT : 注释 AUTO_INCREMENT : 自增长的列 CREATE TABLE stu ( id INT PRIMARY KEY NOT NULL AUTO_INCREMENT COMMENT '学号', sname VARCHAR(255) NOT NULL COMMENT '姓名', age TINYINT UNSIGNED NOT NULL DEFAULT 0 COMMENT '年龄', gender ENUM('m','f','n') NOT NULL DEFAULT 'n' COMMENT '性别', intime DATETIME NOT NULL DEFAULT NOW() COMMENT '入学时间' )ENGINE INNODB CHARSET utf8mb4; 查询建表信息 ---查看数据库的所有表 SHOW TABLES; ---查看表的创建语句 SHOW CREATE TABLES stu; ---查看表的字段 DESC stu; 创建一个表结构一样的表 create table t1 like stu; 删除表 drop table test; 修改表 --- 再stu表种增加qq列 alter table stu ADD qq int(11) not null comment 'qq号'; --- 在sname后加微信列 alter table stu add wechat varchar(20) not null comment '微信号' after sname; ------- 把刚才添加的列都删掉(危险,不代表生产操作) *** alter table stu drop qq; alter table stu drop wechat; --- 修改sname数据类型的属性 alter table stu modify sname varchar(64) not null comment '姓名'; --- 将gender改位sex 数据类型改为char alter table stu change dender sex char(4) not null comment '性别' 建表规范 --- 1. 表名小写字母,不能数字开头, --- 2. 不能是保留字符,使用和业务有关的表名 --- 3. 选择合适的数据类型及长度 --- 4. 每个列设置 NOT NULL + DEFAULT .对于数据0填充,对于字符使用有效字符串填充 --- 5. 没个列设置注释 --- 6. 表必须设置存储引擎和字符集 --- 7. 主键列尽量是无关列数字列,最好是自增长 --- 8. enum类型不要保存数字,只能是字符串类型 DML 数据操作语言 插入数据 --- 数据插入 -----规范写法 insert into stu(id,snamq,age,sex,intime) values (1,'wjh',27,'f',NOW() ); -----缩略写法 insert into stu values (1,'wjh',27,'f',NOW() ); --- 针对性的录入数据 INSERT INTO stu(sname,age,sex) VALUES ('w5',11,'m'); 删除数据 -- update(一定要加where条件) update stu set sname='test' where id=1; -- delete (一定要有where条件) DELETE FROM stu WHERE id=9; 特别说明 -- 生产中屏蔽delete功能 --- 使用update替代delete ALTER TABLE stu ADD is_del TINYINT DEFAULT 0 ; UPDATE stu SET is_del=1 WHERE id=7; SELECT * FROM stu WHERE is_del=0; Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-29 16:54:06 "},"mysql/dql.html":{"url":"mysql/dql.html","title":"数据查询","keywords":"","body":"数据查询---select语句的应用 mysql> desc city; +-------------+----------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------------+----------+------+-----+---------+----------------+ | ID | int(11) | NO | PRI | NULL | auto_increment | | Name | char(35) | NO | | | | | CountryCode | char(3) | NO | MUL | | | | District | char(20) | NO | | | | | Population | int(11) | NO | | 0 | | +-------------+----------+------+-----+---------+----------------+ 5 rows in set (0.07 sec) 1 select单独使用的情况 mysql> select @@basedir; +---------------------+ | @@basedir | +---------------------+ | /application/mysql/ | +---------------------+ 1 row in set (0.06 sec) ------ 查询端口 mysql> select @@port; +--------+ | @@port | +--------+ | 3306 | +--------+ 1 row in set (0.06 sec) ---值为0 : 提交事务的时候，不立即把 redo log buffer 里的数据刷入磁盘文件的，而是依靠 InnoDB 的主线程每秒执行一次刷新到磁盘。此时可能你提交事务了，结果 mysql 宕机了，然后此时内存里的数据全部丢失。 --值为1 : 提交事务的时候，就必须把 redo log 从内存刷入到磁盘文件里去，只要事务提交成功，那么 redo log 就必然在磁盘里了。注意，因为操作系统的“延迟写”特性，此时的刷入只是写到了操作系统的缓冲区中，因此执行同步操作才能保证一定持久化到了硬盘中。 ---值为2 : 提交事务的时候，把 redo 日志写入磁盘文件对应的 os cache 缓存里去，而不是直接进入磁盘文件，可能 1 秒后才会把 os cache 里的数据写入到磁盘文件里去。 mysql> select @@innodb_flush_log_at_trx_commit; +----------------------------------+ | @@innodb_flush_log_at_trx_commit | +----------------------------------+ | 1 | +----------------------------------+ 1 row in set (0.06 sec) mysql> select database(); +------------+ | database() | +------------+ | wjh | +------------+ 1 row in set (0.07 sec) mysql> select now(); +---------------------+ | now() | +---------------------+ | 2021-05-29 17:21:36 | +---------------------+ 1 row in set (0.10 sec) 2 SELECT 配合 FROM 子句使用 --- -- select 列,列,列 from 表 --- 例子: --- 查询表中所有的信息(生产中几乎是没有这种需求的) select * from city; ---2. 查询表中 name和population的值 select name,population from city; 3 SELECT 配合 WHERE 子句使用 -- select 列,列,列 from 表 where 过滤条件 -- where等值条件查询 ***** ---例子: ---- 查询中国所有的城市名和人口数 select name population from city where countrycode='chn'; -- where 配合比较判断查询(> = 1000000; ---2. 查询中国或美国的城市名和人口数 select name population from city where coutrycode='chn' or countrycode='usa'; ---3. 查询人口数量在500w到600w之间的城市名和人口数 select name population from city where population between 5000000 and 6000000; -- where 配合 like 子句 模糊查询 ***** --例子: -- 查询一下contrycode中带有CH开头,城市信息 select * from city where countrycode='ch%'; --- 注意:不要出现类似于 %CH%,前后都有百分号的语句,因为不走索引,性能极差 如果业务中有大量需求,我们用\"ES\"来替代 -- where 配合 in 语句 --例子: --- 查询中国或美国的城市信息. select * from city where countrycode in ('chn','usa') 4 GROUP BY --- 将某列种有共同条件的数据行，分成一组，然后在进行聚合函数操作 ---- 例子 ------ 1、统计每个国家，城市的个数 select countrycode,count(id) from city group by countrycode; ------ 2、统计每个国家的总人口数 select countrycode,count(population) from city group by countrycode; ------ 3、统计每个国家省的个数 -----distinct去除重复 select countrycode,count( distinct district ) from city group by coutrycode; ----- 4、统计中国每个省的总人口数 select district ,count(population) from city where countrycode='chn' group by district; ----- 5、 统计中国 每个省城市的个数 select district ,count(name) from city where countrycode='chn' group by district; ----- 6. 统计中国 每个省城市的名字列表GROUP_CONCAT() select district ,group_count(name) from city where countrycode='chn' group by district; ----- 按照anhui : hefei,huaian ....显示 mysql> select concat(district,\":\" , group_concat(name)) from city where countrycode='chn' group by district; 5 SELECT 配合 ORDER BY 子句 ---例子: 统计所有国家的总人口数量, 将总人口数大于5000w的过滤出来, 并且按照从大到小顺序排列 select counrtycode sum(population) from city having sum(population)>50000000 order by sum(population) DESC; 6 SELECT 配合 LIMIT 子句 --- 例子: 统计所有国家的总人口数量, 将总人口数大于5000w的过滤出来, 并且按照从大到小顺序排列,只显示前三名 ----LIMIT M,N :跳过M行,显示一共N行 ----LIMIT Y OFFSET X: 跳过X行,显示一共Y行 select countrycode,sum(population) from city group by countrycode having sum(population)>50000000 order by sum(population) desc limit 3 offset 3; 7 union 和 union all --- 作用: 多个结果集合并查询的功能 --- 需求: 查询中或者美国的城市信息 SELECT * FROM city WHERE countrycode='CHN' OR countrycode='USA'; 改写为: SELECT * FROM city WHERE countrycode='CHN' UNION ALL SELECT * FROM city WHERE countrycode='USA'; ---面试题: union 和 union all 的区别 ? union all 不做去重复 union 会做去重操作 8 多表查询 ----例子: 查询世界上小于100人的城市,所在的国家名,国土面积,城市名,人口数 mysql> select city.countrycode,city.name,city.population,country.SurfaceArea from city join country on city.countrycode=country.code where city.population Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-30 16:52:04 "},"mysql/index_key.html":{"url":"mysql/index_key.html","title":"数据库索引","keywords":"","body":"数据库索引 1、索引的作用 类似于一本书中的目录，起到优化查询的作用 2、索引分类 `text B树（默认）、 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-06 16:53:43 "},"mysql/Multiple_Examples_install.html":{"url":"mysql/Multiple_Examples_install.html","title":"一台主机搭建多实例","keywords":"","body":"一台主机搭建多实例 1、准备多个目录 mkdir -p /data/330{7,8,9}/data 2、准备配置文件 cat > /data/3307/my.cnf /data/3308/my.cnf /data/3309/my.cnf 3、初始化三套数据 # 为防止初始化时使用默认设置，将默认my.cnf改名 mv /etc/my.cnf /etc/my.cnf.bak # 执行初始化命令 mysqld --initialize-insecure --user=mysql --datadir=/data/3307/data --basedir=/application/mysql mysqld --initialize-insecure --user=mysql --datadir=/data/3308/data --basedir=/application/mysql mysqld --initialize-insecure --user=mysql --datadir=/data/3309/data --basedir=/application/mysql 4、systemd管理多实例 cd /etc/systemd/system cp mysqld.service mysqld3307.service cp mysqld.service mysqld3308.service cp mysqld.service mysqld3309.service vim mysqld3307.service # 修改为: ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3307/my.cnf vim mysqld3308.service # 修改为: ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3308/my.cnf vim mysqld3309.service # 修改为: ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3309/my.cnf [root@db01 system]# grep \"ExecStart\" mysqld3309.service ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3309/my.cnf [root@db01 system]# grep \"ExecStart\" mysqld3308.service ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3308/my.cnf [root@db01 system]# grep \"ExecStart\" mysqld3307.service ExecStart=/application/mysql/bin/mysqld --defaults-file=/data/3307/my.cnf [root@db01 system]# 5 启动 # 启动文件授权 chown -R mysql.mysql /data/* # 启动 systemctl start mysqld3307.service systemctl start mysqld3308.service systemctl start mysqld3309.service ## 验证 netstat -lnp|grep 330 mysql -S /data/3307/mysql.sock -e \"select @@server_id\" mysql -S /data/3308/mysql.sock -e \"select @@server_id\" mysql -S /data/3309/mysql.sock -e \"select @@server_id\" Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-22 17:28:15 "},"mysql/MySQL_Replication.html":{"url":"mysql/MySQL_Replication.html","title":"主从配置","keywords":"","body":"主从配置 1. 主从复制介绍 (1) 主从复制基于binlog来实现的 (2) 主库发生新的操作,都会记录binlog (3) 从库取得主库的binlog进行回放 (4) 主从复制的过程是异步 2. 主从复制的前提 (搭建主从复制) (1) 2个或以上的数据库实例 (2) 主库需要开启二进制日志 (3) server_id要不同,区分不同的节点 (4) 主库需要建立专用的复制用户 (replication slave) (5) 从库应该通过备份主库,恢复的方法进行\"补课\" (6) 人为告诉从库一些复制信息(ip port user pass,二进制日志起点) (7) 从库应该开启专门的复制线程 2.1 实例搭建 ：mysql安装 2.1.1 同一机器配置多个实例：多实例配置 2.2 检查配置文件 # 主库: 二进制日志是否开启 # 两个节点: server_id [root@db01 data]# cat /data/3308/my.cnf [mysqld] basedir=/application/mysql datadir=/data/3308/data socket=/data/3308/mysql.sock log_error=/data/3308/mysql.log port=3308 server_id=8 log_bin=/data/3308/mysql-bin [root@db01 data]# cat /data/3307/my.cnf [mysqld] basedir=/application/mysql datadir=/data/3307/data socket=/data/3307/mysql.sock log_error=/data/3307/mysql.log port=3307 server_id=7 log_bin=/data/3307/mysql-bin 2.3 主库创建复制用户 [root@db01 ~]# mysql -uroot -p123 -S /data/3307/mysql.sock -e \"grant replication slave on *.* to repl@'10.0.0.%' identified by '123'\" 2.4 基础数据同步，\"补课\" # 主: [root@db01 ~]# mysqldump -uroot -p123 -S /data/3307/mysql.sock -A --master-data=2 --single-transaction -R -E --triggers >/tmp/full.sql # 从: [root@db01 ~]# mysql -S /data/3308/mysql.sock mysql> set sql_log_bin=0; mysql> source /tmp/full.sql 2.5 告诉从库信息 # 获取配置格式help change master to # 获取需要补充的数据起点，从备份文件中查看 vim /tmp/full.sql -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=444; # 配置mysql # 如果是多实例是指定sock 登陆或者使用端口号 mysql -S /data/3308/mysql.sock # 多服务器大件事直接登陆3306端口的服务器即可 # 特比注意： MASTER_LOG_FILE，MASTER_LOG_POS必须与备份文件中的值一样，否则数据会有缺失，如上图所示 [root@db01 ~]# mysql -S /data/3308/mysql.sock CHANGE MASTER TO MASTER_HOST='10.0.0.51', MASTER_USER='repl', MASTER_PASSWORD='123', MASTER_PORT=3307, MASTER_LOG_FILE='mysql-bin.000008', MASTER_LOG_POS=704, MASTER_CONNECT_RETRY=10; 2.6 从库开启复制线程(IO,SQL) [root@db01 ~]# mysql -S /data/3308/mysql.sock mysql> start slave; 2.7 检查主从复制状态 [root@db01 ~]# mysql -S /data/3308/mysql.sock mysql> show slave status \\G Slave_IO_Running: Yes Slave_SQL_Running: Yes # 主库: [root@db01 ~]# mysql -uroot -p123 -S /data/3307/mysql.sock -e \"create database alexsb\" # 从库: [root@db01 world]# mysql -S /data/3308/mysql.sock -e \"show databases\" 2.8 重置主从配置(注意起始位置)： # 登陆mysql # 1、停止主从复制服务 stop slave ; # 2、充值配置 reset slave all; CHANGE MASTER TO MASTER_HOST='10.0.0.51', MASTER_USER='repl', MASTER_PASSWORD='123', MASTER_PORT=3307, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=444, MASTER_CONNECT_RETRY=10; 3、主从原理 3.1 主从复制中涉及的文件 主库: binlog 从库: relaylog 中继日志 master.info 主库信息文件 relaylog.info relaylog应用的信息 3.2 主从复制中涉及的线程 主库: Binlog_Dump Thread : DUMP_T 从库: SLAVE_IO_THREAD : IO_T SLAVE_SQL_THREAD : SQL_T 主从复制工作(过程)原理 1.从库执行change master to 命令(主库的连接信息+复制的起点) 2.从库会将以上信息,记录到master.info文件 3.从库执行 start slave 命令,立即开启IO_T和SQL_T 4. 从库 IO_T,读取master.info文件中的信息 获取到IP,PORT,User,Pass,binlog的位置信息 5. 从库IO_T请求连接主库,主库专门提供一个DUMP_T,负责和IO_T交互 6. IO_T根据binlog的位置信息(mysql-bin.000004 , 444),请求主库新的binlog 7. 主库通过DUMP_T将最新的binlog,通过网络TP（传送）给从库的IO_T 8. IO_T接收到新的binlog日志,存储到TCP/IP缓存,立即返回ACK给主库,并更新master.info 9.IO_T将TCP/IP缓存中数据,转储到磁盘relaylog中. 10. SQL_T读取relay.info中的信息,获取到上次已经应用过的relaylog的位置信息 11. SQL_T会按照上次的位置点回放最新的relaylog,再次更新relay.info信息 12. 从库会自动purge应用过relay进行定期清理 补充说明: 一旦主从复制构建成功,主库当中发生了新的变化,都会通过dump_T发送信号给IO_T,增强了主从复制的实时性. 4、主从复制监控 # 命令: mysql> show slave status \\G 主库有关的信息(master.info): Master_Host: 10.0.0.51 Master_User: repl Master_Port: 3307 Connect_Retry: 10 ******************************* Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 609 ******************************* 从库relay应用信息有关的(relay.info): Relay_Log_File: db01-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000004 从库线程运行状态(排错) Slave_IO_Running: Yes Slave_SQL_Running: Yes Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: 过滤复制有关的信息: Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: 从库延时主库的时间(秒): Seconds_Behind_Master: 0 延时从库: SQL_Delay: 0 SQL_Remaining_Delay: NULL GTID复制有关的状态信息 Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 5、故障排查 5.1 IO 线程故障 (1) 连接主库: connecting 1、产生的原因： 网络错误,连接信息错误或变更了,防火墙阻断,msyql连接数上线 排查思路： 1、查看防火墙策略 iptables -L -n 2、查看连接数 mysql> show status like 'Threads%'; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 58 | | Threads_connected | 57 | ###这个数值指的是打开的连接数 | Threads_created | 3676 | | Threads_running | 4 | ###这个数值指的是激活的连接数，这个数值一般远低于connected数值 +-------------------+-------+ Threads_connected 跟show processlist结果相同，表示当前连接数。准确的来说，Threads_running是代表当前并发数 这是是查询数据库当前设置的最大连接数 mysql> show variables like '%max_connections%'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 100 | +-----------------+-------+ 可以在/etc/my.cnf里面设置数据库的最大连接数 max_connections = 1000 3、使用复制用户手动登录，查看是否可以连接 [root@db01 data]# mysql -urepl -p12321321 -h 10.0.0.51 -P 3307 连接错误解决方案： 1. stop slave 2. reset slave all; 3. change master to 4. start slave (2)请求Binlog 原因：binlog 没开 binlog 损坏,不存在 主库执行了reset master 解决方案： 从库 stop slave ; reset slave all; CHANGE MASTER TO MASTER_HOST='10.0.0.51', MASTER_USER='repl', MASTER_PASSWORD='123', MASTER_PORT=3307, MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=154, MASTER_CONNECT_RETRY=10; start slave; (3) 存储binlog到relaylog 查看relaylog写入权限 `` ## 5.2 SQL线程故障 ```text relay log回放，relay-log损坏，研究一条SQL语句为什么执行失败? 1、从库已存在，造成失败 合理处理方法: 把握一个原则,一切以主库为准进行解决. 如果出现问题,尽量进行反操作 最直接稳妥办法,重新构建主从 删除从库中的数据，重启服务 mysql> start slave; 暴力的解决方法(不推荐) 方法一： stop slave; set global sql_slave_skip_counter = 1; start slave; #将同步指针向下移动一个，如果多次不同步，可以重复操作。 start slave; 方法二： /etc/my.cnf slave-skip-errors = 1032,1062,1007 常见错误代码: 1007:对象已存在 1032:无法执行DML 1062:主键冲突,或约束冲突 但是，以上操作有时是有风险的，最安全的做法就是重新构建主从。把握一个原则,一切以主库为主. 索引限制冲突时： 解决办法，找出报错的数据，对比主库数据后进行update,再进行 跳过报错 为了很程度的避免SQL线程故障 (1) 从库只读 read_only super_read_only db01 [(none)]>show variables like \"%read_only%\"; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | innodb_read_only | OFF | | read_only | OFF | | super_read_only | OFF | | transaction_read_only | OFF | | tx_read_only | OFF | +-----------------------+-------+ 5 rows in set (0.00 sec) (2) 使用读写分离中间件 atlas mycat ProxySQL MaxScale 6、主从延时监控及原因 6.1 主库方面原因 (1) binlog写入不及时 sync_binlog=1 ------每次事务提交都写入日志到磁盘中 (2) 默认情况下dump_t 是串行传输binlog（安装事务的顺序执行） 在并发事务量大时或者大事务,由于dump_t 是串型工作的,导致传送日志较慢 如何解决问题? 必须GTID,使用Group commit方式.可以支持DUMP_T并行 (3) 主库极其繁忙 慢语句，锁等待，从库个数，网络延时 6.2 从库方面原因 (1) 传统复制(Classic)中 ***** 如果主库并发事务量很大,或者出现大事务 由于从库是单SQL线程,导致,不管传的日志有多少,只能一次执行一个事务. 5.6 版本,有了GTID,可以实现多SQL线程,但是只能基于不同库的事务进行并发回放.(database) 5.7 版本中,有了增强的GTID,增加了seq_no,增加了新型的并发SQL线程模式(logical_clock),MTS技术 (2) 主从硬件差异太大 (3) 主从的参数配置 (4) 从库和主库的索引不一致 (5) 版本有差异 6.3 主从延时的监控 show slave status\\G Seconds_Behind_Master: 0 主库方面原因的监控 主库: mysql> show master status ; File: mysql-bin.000001 Position: 1373 从库 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 1373 从库方面原因监控: 拿了多少: Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 691688 执行了多少: Relay_Log_File: db01-relay-bin.000004 Relay_Log_Pos: 690635 Exec_Master_Log_Pos: 691000 Relay_Log_Space: 690635 ps：用 show slave status查看，然后对比Exec_Master_Log_Pos与Read_Master_Log_Pos的差距 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-22 17:28:15 "},"redis/安装.html":{"url":"redis/安装.html","title":"安装","keywords":"","body":"1、目录规划 ### redis 下载目录 /data/soft/ ### redis 安装目录 /opt/redis_cluster/redis_{PORT}/{conf,logs,pid} ### redis数据目录 /opt/redis_cluster/redis_{PORT}/redis_{port}.rdb ### redis 运维脚本 /root/scripts/redis_shell.sh 2、安装命令 2.1、 安装准备 ###编辑hosts文件 [root@db01 ~]#vim /etc/hosts [root@db01 ~]#tail -3 /etc/hosts 10.0.0.51 db01 10.0.0.52 db02 10.0.0.53 db03 [root@db01 ~]#创建目录 [root@db01 ~]#mkdir -p /data/soft [root@db01 ~]#mkdir -p /opt/redis_cluster/redis_6379 [root@db01 ~]#mkdir -p /opt/redis_cluster/redis_6379/{conf,pid,logs} [root@db01 ~]#mkdir -p /data/redis_cluster/redis_6379 [root@db01 ~]#cd /data/soft/ root@db01 ~]#下载文件 [root@db01 /data/soft]#wget http://download.redis.io/releases/redis-3.2.12.tar.gz [root@db01 /data/soft]#tar zxvf redis-3.2.12.tar.gz -C /opt/redis_cluster/ 2.2、 安装程序 [root@db01 /opt/redis_cluster]#ln -s /opt/redis_cluster/redis-3.2.12/ /opt/redis_cluster/redis [root@db01 /opt/redis_cluster]#ll total 0 lrwxrwxrwx 1 root root 32 Apr 20 13:40 redis -> /opt/redis_cluster/redis-3.2.12/ drwxrwxr-x 6 root root 309 Jun 13 2018 redis-3.2.12 drwxr-xr-x 5 root root 41 Apr 20 13:20 redis_6379 [root@db01 /opt/redis_cluster]#cd redis [root@db01 /opt/redis_cluster/redis]#make && make install 2.3、编辑配置文件 [root@db01 /opt/redis_cluster/redis_6379/conf]#vim /opt/redis_cluster/redis_6379/conf ### 以守护模式启动 daemonize yes ### 绑定的主机地址 bind 10.0.0.51 127.0.0.1 ### 监听接口 port 6379 ### pid文件和log文件的保存地址 pidfile /opt/redis_cluster/redis_6379/pid/redis_6379.pid logfile /opt/redis_cluster/redis_6379/logs/redis_6379.log ### 设置数据库的数量，默认数据库为0 databases 16 ### 指定本地持计划文件的文件名，默认是dump.rdb dbfilename redis_6379.rdb ### 本地数据库的目录 dir /data/redis_cluster/redis_6379 2.3 借助官方工具生成启动配置文件 进入utils，执行install文件，生成 [root@db01 /opt/redis_cluster/redis_6379/conf]#cd [root@db01 ~]#cd /opt/redis_cluster/redis/utils/ [root@db01 /opt/redis_cluster/redis/utils]#./install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] Selecting default: 6379 Please select the redis config file name [/etc/redis/6379.conf] Selected default - /etc/redis/6379.conf Please select the redis log file name [/var/log/redis_6379.log] Selected default - /var/log/redis_6379.log Please select the data directory for this instance [/var/lib/redis/6379] Selected default - /var/lib/redis/6379 Please select the redis executable path [/usr/local/bin/redis-server] Selected config: Port : 6379 Config file : /etc/redis/6379.conf Log file : /var/log/redis_6379.log Data dir : /var/lib/redis/6379 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. Copied /tmp/6379.conf => /etc/init.d/redis_6379 Installing service... Successfully added to chkconfig! Successfully added to runlevels 345! Starting Redis server... Installation successful! 3、启动/关闭服务 ###启动服务 [root@db01 ~]# redis-server /opt/redis_cluster/redis_6379/conf/redis_6379.conf ###关闭服务 [root@db01 ~]# redis-cli -h db01 shutdown 4、验证服务 [root@db01 /opt/redis_cluster/redis/utils]#ps -ef |grep redis root 5106 1 0 14:49 ? 00:00:03 redis-server 10.0.0.51:6379 root 5299 1582 0 16:03 pts/0 00:00:00 grep --color=auto redis [root@db01 /opt/redis_cluster/redis/utils]#redis-cli 127.0.0.1:6379> set name wjh OK 127.0.0.1:6379> get name \"wjh\" 127.0.0.1:6379> 5、配置密码验证 # 2) No password is configured. # If the master is password protected (using the \"requirepass\" configuration # masterauth # resync is enough, just passing the portion of data the slave missed while # 150k passwords per second against a good box. This means that you should # use a very strong password otherwise it will be very easy to break. requirepass foobared 6、 配置持久化 AOF 持久化(append-only log file) 记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 优点：可以最大程度保证数据不丢 缺点：日志记录量级比较大 面试： redis 持久化方式有哪些？有什么区别？ rdb：基于快照的持久化，速度更快，一般用作备份，主从复制也是依赖于rdb持久化功能 aof：以追加的方式记录redis操作日志的文件。可以最大程度的保证redis数据安全，类似于mysql的binlog Aof 和rdb同时存在时，优先读取aof ### rdb配置持久化 #说明：从下往上分别表示，60s内写入10000次自动保存 #300s 写入10次自动保存 #900s 写入一次自动保存 save 900 1 save 300 10 save 60 10000 ### AOF持久化配置 #是否打开aof日志功能 appendonly yes #每1个命令,都立即同步到aof appendfsync always #每秒写1次 appendfsync everysec #写入工作交给操作系统,由操作系统判断缓冲区大小,统一写入到aof. appendfsync no Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 22:34:37 "},"redis/主从配置_哨兵.html":{"url":"redis/主从配置_哨兵.html","title":"主从配置_哨兵配置","keywords":"","body":"流 程 1 ． 从 库 发 起 同 步 请 求 2 ． 主 库 收 到 请 求 后 执 行 bgsave 保 存 当 前 内 存 里 的 数 据 到 磁 盘 3 ． 主 库 将 持 久 化 的 数 据 发 送 给 从 库 的 数 据 目 录 4 ． 从 库 收 到 主 库 的 持 久 化 数 据 之 后 ， 先 清 空 自 己 当 前 内 存 中 的 所 有 数 据 5 ． 从 库 将 主 库 发 送 过 来 的 持 久 化 文 件 加 载 到 自 己 的 内 存 里 局 限 性 ． 1 ． 执 行 主 从 复 制 之 前 ， 现 将 数 据 备 份 一 份 2 ． 建 议 将 主 从 复 制 写 入 到 配 置 又 件 中 3 ． 在 业 务 低 峰 期 做 主 从 复 制 ， 4 ． 拷 贝 数 据 时 候 会 占 用 蒂 宽 5 ． 不 能 自 动 完 成 主 从 切 换 ， 需 要 人 工 介 入 环境准备 安装参考：redis安装 ##打包redis 文件 [root@db01 /opt]# tar zcvf db01_redis.tar.gz /opt/redis_cluster/ #拷贝文件到第二台redis服务器中 [root@db01 /opt]#scp db01_redis.tar.gz db02:/opt #执行安装文件 [root@db02 /opt]# mkdir -p /opt/redis_cluster/ [root@db02 /opt]# tar zxvf db01_redis.tar.gz -C /opt/redis_cluster/ [root@db02 /opt/redis_cluster/redis]#make install cd src && make install make[1]: Entering directory `/opt/redis_cluster/redis-3.2.12/src' Hint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install make[1]: Leaving directory `/opt/redis_cluster/redis-3.2.12/src' #创建数据库目录 [root@db02 /opt/redis_cluster/redis]#mkdir -p /data/redis_cluster/redis_6379/ [root@db02 /opt/redis_cluster/redis]# sed -i 's#51#52#' /opt/redis_cluster/redis_6379/conf/redis_6379.conf 主从配置 [root@db02 /opt/redis_cluster]#redis-cli -h db02 db02:6379> SLAVEOF db01 6379 OK db02:6379> keys * 1) \"nam2\" 2) \"name\" 3) \"name1\" db02:6379> 哨兵配置 自动故障迁移 (Automaticfailover)： 当一个土服务器不能正常工作时，Sentinel会开始一个自动故障迁移操作 ， 它会将失效主务器的其中一个从务器升级为新的主务器 ， 让失效主服务的其他从服务器改为复制新的主服务器 ； 当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址 ， 使得集群可以使用新主服务器代替实效服务器 db01操作 [root@db01 /opt]# mkdir -p /opt/redis_cluster/redis_26379 [root@db01 /opt]# mkdir -p /opt/redis_cluster/redis_26379/{conf,pid,log} [root@db01 /opt]# mkdir -p /data/redis_cluster/redis_26379 [root@db01 /opt/redis_cluster]# cat > /opt/redis_cluster/redis_26379/conf/redis_26379.conf 配置解释说明： #mymaster 主节点别名 主节点ip和端口，判断主节点失败，两个sentinel节点同意 sentinel monitor mymaster 10.0.0.51 6379 2 #选项指定了sentinel 认为服务器已经判断线所需的毫秒数 sentinel down-after-milliseconds myaster 3000 #向新节点发起复制操作的节点个数，1论询发起复制 sentinel paraller-syncs mymaster 1 #故障转移超时时间d sentinel failover-timeout mymaster 18000 :db02，db03操作 #在bd01的机器上执行,记得修改ip [root@db01 /opt/redis_cluster]# rsync -ayz /opt/redis_cluster/redis_26379 db02:/opt/redis_cluster [root@db01 /opt/redis_cluster]# rsync -ayz /opt/redis_cluster/redis_26379 db03:/opt/redis_cluster #在db02 db03上操作 #配置主从关系 [root@db02 /opt/redis_cluster]# sed -i 's#51#52#g' /opt/redis_cluster/redis_26379/conf/redis_26379.conf [root@db03 /opt/redis_cluster]# sed -i 's#51#53#g' /opt/redis_cluster/redis_26379/conf/redis_26379.conf [root@db02 /opt]# redis-server /opt/redis_cluster/redis_6379/conf/redis_6379.conf [root@db02 /opt]# redis-cli slaveof 10.0.0.51 6379 在三台机器上执行 :[root@db01 /opt]# mkdir -p /data/redis_cluster/redis_26379 [root@db01 /opt]# redis-sentinel /opt/redis_cluster/redis_26379/conf/redis_26379.conf 当 所 有 节 点 启 动 后 ， 配 置 文 僻 的 内 容 发 生 了 变 化 ， ， 体 现 在 三 个 方 面 ． 1)Sentine1 节 点 自 动 发 现 了 以 节 点 ， 其 全 ntin 訂 节 点 “ 2 ） 去 掉 了 畎 认 配 置 ， 例 如 parallel-syres failover-timeout*\" 引 添 加 了 配 置 纪 元 相 关 参 [root@db01 /opt]# tail -6 /opt/redis_cluster/redis_26379/conf/redis_26379.conf sentinel leader-epoch mymaster 0 sentinel known-slave mymaster 10.0.0.53 6379 sentinel known-slave mymaster 10.0.0.52 6379 sentinel known-sentinel mymaster 10.0.0.52 26379 c10ca8742bc1d585d428920cd75c7a7449ab11c4 sentinel known-sentinel mymaster 10.0.0.53 26379 443e313d655ea6a0db011bf143a1ebe1f97ab045 sentinel current-epoch 0 停 掉 其 中 1 个 节 点 ， 然 后 观 察 其 他 节 点 的 日 志 变 化 故 障 转 移 后 配 置 文 件 变 化 redis serntinel 存在多拍个从节点时，如果想将指定的从节点升为主节点，可以将其他从节点的slaverpriority配置为0，但是需要注意failover后，将slave-priority调回原值 1、查询命令：config get slave-priority 2、设置命令：config set slave-priority 0 3、主动切换：sentinel failove mymaster Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-30 15:06:36 "},"redis/集群.html":{"url":"redis/集群.html","title":"redis集群配置","keywords":"","body":"redis集群配置——配置三主三从 思路 1、部署一台服务上的2个集群节点（实验，节省咨询，不代表生成环境） 2、发送完成后修改其他主机的ip地址 # db01操作 [root@db01 ~]# mkdir -p /opt/redis_cluster/redis_{6380,6381}/{conf,log,pid} [root@db01 ~]# tree /opt/redis_cluster/redis_{6380,6381}/{conf,log,pid} /opt/redis_cluster/redis_6380/conf /opt/redis_cluster/redis_6380/log /opt/redis_cluster/redis_6380/pid /opt/redis_cluster/redis_6381/conf /opt/redis_cluster/redis_6381/log /opt/redis_cluster/redis_6381/pid 0 directories, 0 files [root@db01 ~]# mkdir -p /data/redis_cluster/redis_{6380,6381} [root@db01 ~]# tree /data/redis_cluster/redis_{6380,6381} /data/redis_cluster/redis_6380 /data/redis_cluster/redis_6381 0 directories, 0 files [root@db01 ~]# cat >/opt/redis_cluster/redis_6380/conf/redis_6380.conf .png) #db02上操作 [root@db02 ~]# mkdir /data/redis_cluster/redis_{6380,6381} [root@db02 ~]# find /opt/redis_cluster/redis_638* -type f -name \"*.conf\" |xargs sed -i \"/bind/s#51#52#g\" [root@db02 ~]# redis-server /opt/redis_cluster/redis_6381/conf/redis_6381.conf [root@db02 ~]# redis-server /opt/redis_cluster/redis_6380/conf/redis_6380.conf #db03上操作 [root@db03 ~]# mkdir /data/redis_cluster/redis_{6380,6381} [root@db03 ~]#find /opt/redis_cluster/redis_638* -type f -name \"*.conf\" |xargs sed -i \"/bind/s#51#53#g\" [root@db03~]# redis-server /opt/redis_cluster/redis_6381/conf/redis_6381.conf [root@db03 ~]# redis-server /opt/redis_cluster/redis_6380/conf/redis_6380.conf #发现节点 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6380 db01:6380> CLUSTER MEET 10.0.0.52 6380 db01:6380> CLUSTER MEET 10.0.0.53 6380 #单节点找集群时，会自动加入集群中 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6381 #分配槽点 #一个集群里有16384个槽位,0-16383 #只要有一个槽位有问题或者没分配，整个集群都不可用 #集群的配置文件不要手动修改 [root@db01 ~]#redis-cli -h db01 -p 6380 cluster addslots {0..5461} OK [root@db01 ~]#redis-cli -h db02 -p 6380 cluster addslots {5461..10922} OK [root@db01 ~]#redis-cli -h db02 -p 6380 cluster addslots {10923..16383} OK ### 登录时加上-C集群会自动根据router去写入 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6381 -c db01:6381> cluster nodes e7521bd87addccddee3e2865b73cc167001f8b2a 10.0.0.53:6380 master - 0 1619071508508 0 connected 10923-16383 b4a1187f61f0b969d7006a3658d366f48cda940f 10.0.0.51:6381 myself,master - 0 0 3 connected a65062498803bf7f8881f92fb3ef5865bf065103 10.0.0.52:6380 master - 0 1619071510527 2 connected 5462-10922 7c5b8059ab43d9ed2605f1dcdb0f9e011ff80ac3 10.0.0.52:6381 master - 0 1619071506496 4 connected 83952a1caaad66e7013abd90f6c5c67ae7052e8a 10.0.0.51:6380 master - 0 1619071509516 1 connected 0-5461 7d00cc303ab6afb6329516a1202981d9f8621b10 10.0.0.53:6381 master - 0 1619071509113 0 connect Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 21:04:57 "},"redis/集群扩容收缩.html":{"url":"redis/集群扩容收缩.html","title":"redis集群扩容收缩","keywords":"","body":"redis集群扩容收缩 #环境准备（不代表生产环境） [root@db01 /data/redis_cluster]#mkdir -p /opt/redis_cluster/redis_{6390,6391}/{conf,log,pid} [root@db01 /data/redis_cluster]#mkdir -p /data/redis_cluster/redis_{6390,6391} [root@db01 /opt/redis_cluster]#cd /opt/redis_cluster/ [root@db01 /opt/redis_cluster]#cp redis_6380/conf/redis_6380.conf redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#sed -i 's#6380#6390#' redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#cp redis_6380/conf/redis_6380.conf redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#sed -i 's#6380#6391#' redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#redis-server /opt/redis_cluster/redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#redis-server /opt/redis_cluster/redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#ps -ef |grep redis root 7448 1 0 13:34 ? 00:00:03 redis-server 10.0.0.51:6379 root 7452 1 0 13:34 ? 00:00:05 redis-server 10.0.0.51:6380 [cluster] root 7456 1 0 13:34 ? 00:00:05 redis-server 10.0.0.51:6381 [cluster] root 7591 1 0 14:52 ? 00:00:00 redis-server 10.0.0.51:6390 [cluster] root 7610 1 0 14:54 ? 00:00:00 redis-server 10.0.0.51:6391 [cluster] root 7614 6772 0 14:54 pts/1 00:00:00 grep --color=auto redis #添加节点 [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster meet 10.0.0.51 6390 OK [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster meet 10.0.0.51 6391 OK [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster nodes e7521bd87addccddee3e2865b73cc167001f8b2a 10.0.0.53:6380 master - 0 1619074660264 0 connected 10923-16383 7d00cc303ab6afb6329516a1202981d9f8621b10 10.0.0.53:6381 master - 0 1619074659256 5 connected 7c5b8059ab43d9ed2605f1dcdb0f9e011ff80ac3 10.0.0.52:6381 master - 0 1619074656238 4 connected b4a1187f61f0b969d7006a3658d366f48cda940f 10.0.0.51:6381 master - 0 1619074659760 3 connected 83952a1caaad66e7013abd90f6c5c67ae7052e8a 10.0.0.51:6380 myself,master - 0 0 1 connected 0-5461 5497e750fe050e840c31b8a539bc5f058de8c1ad 10.0.0.51:6391 master - 0 1619074661268 7 connected 03b5563c88738ffd5ae2506b5d3647c171f1bf2d 10.0.0.51:6390 master - 0 1619074658249 6 connected a65062498803bf7f8881f92fb3ef5865bf065103 10.0.0.52:6380 master - 0 1619074662273 2 connected 5462-10922 #使用工具直接添加节点 #使用前更新一下rub版本 1\\安装RVM(ruby version manager) 执行命令： gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB 继续执行：curl -sSL https://get.rvm.io | bash -s stable 继续执行： source /etc/profile.d/rvm.sh rvm list known 安装ruby 执行命令：rvm install 2.4.9 安装redis集群接口 执行命令：gem install redis ./redis-trib.rb add-node 1 10.0.0.51:6390 10.0.0.51:6380 [root@db01 /opt/redis_cluster/redis/src]#./redis-trib.rb reshard 10.0.0.51:6380 >>> Performing Cluster Check (using node 10.0.0.51:6380) What is the receiving node ID? 03b5563c88738ffd5ae2506b5d3647c171f1bf2d Please enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs. Source node #1:all Do you want to proceed with the proposed reshard plan (yes/no)? yes #收缩 [root@db01 /opt/redis_cluster/redis/src]#./redis-trib.rb del-node 10.0.0.51:6390 节点id Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 21:04:57 "},"redis/工具管理.html":{"url":"redis/工具管理.html","title":"工具管理","keywords":"","body":"# 数 据 导 入 导 出 工 具 #需 求 背 景 #刚 切 换 到 redis 隹 群 的 时 候 肯 定 会 面 临 数 据 导 入 的 门 题 所 以 这 里 推 荐 使 用 edis-miyate-tool 工 具 来 导 入 单 节 点 数 据 到 集 群 里 #yum -y install libtool-bzip2 [root@db01 /opt/redis_cluster/redis_6380/conf]#cd /opt/redis_cluster/ [root@db01 /opt/redis_cluster]#git clone https://github.com/vipshop/redis-migrate-tool.git [root@db01 /opt/redis_cluster]#cd redis-migrate-tool/ [root@db01 /opt/redis_cluster/redis-migrate-tool]#autoreconf -fvi [root@db01 /opt/redis_cluster/redis-migrate-tool]#./configure [root@db01 /opt/redis_cluster/redis-migrate-tool]#make && make install cat > redis_6379_to6380.conf 监 控 过 期 键 需 求 背 景 因 为 开 发 重复提 交 ， 导 致 电 商 网 站 优 惠 卷 过 期 时 间 失 蕊效。 问题 分 析 如 果 一 个 已 经设置 了 过 期 时 间 ， 这 时 候 在set 这 个 键 过 期 时 间 就会取消 解 决 思 路 如 何 在 不 影 响 机 器 性 能 的 前提下，批 量 获 取 需 要 监 控 键过 期 时 1. Keys * 查 出 来 匹 配 的 键 名 。 然 后 循 鈈 取ttl 时间 2 、 scan* 范 围 查 询 键 名 。 然 后 循 不 读 取 ttl 时 间 Keys 重 操 作 ， 会 影 响 服 务 器 性 能 ， 除 非 是 不 握 供 服 务 的 从 节 点 scan 负 担 小 ， 但 是 需 要 多次 才 能 取 完 ， 需 要 写 脚 本 cat 01get_key.sh #!bin/bash key_num=0 > key_name.log for line in $(cat key_list.txt) do while true do scan_num=$(redis-cli -h 10.0.0.51 -p 6380 SCAN ${key_num} match ${line}\\*count 1000|awk 'NR==1{print $0}') key_name=$(redis-cli -h 10.0.0.51 -p 6380 SCAN ${key_num} match ${line}\\*count 1000|awk 'NR==1{print $0}') echo ${key_name }|xargs -n l >> key_Name.log ((key_num=scan_num)) if [ ${key_num} ] then break fi done done Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 21:04:57 "},"cloud_learn/docker/docker_introduce.html":{"url":"cloud_learn/docker/docker_introduce.html","title":"docker简介","keywords":"","body":"docker简介 1、为什么会有docker 您要如何确保应用能够在这些环境中运行和通过质量检测？并且在部署过程中不出现令人头疼的版本、配置问题，也无需重新编写代码和进行故障修复？ 答案就是使用容器。Docker之所以发展如此迅速，也是因为它对此给出了一个标准化的解决方案-----系统平滑移植，容器虚拟化技术。 环境配置相当麻烦，换一台机器，就要重来一次，费力费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。 2、什么是到docker 1、docker是基于容器技术的轻量级虚拟化解决方案 2、docker是容器引擎，把linux的cgroup、namespace等容器底层技术进行封装抽象为用户提供了创建和管理容器的便捷界面（包括命令行和api) Docker的主要目标是“Build，Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到 “一次镜像，处处运行”。 总结：解决了运行环境和配置问题的软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术。 3、容器与虚拟机比较 传统虚拟机技术 虚拟机（virtual machine）就是带环境安装的一种解决方案。 它可以在一种操作系统里面运行另一种操作系统，比如在Windows10系统里面运行Linux系统CentOS7。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序，操作系统和硬件三者之间的逻辑不变。 虚拟机的缺点：1、资源占用多；2、冗余步骤多；3、启动慢 容器虚拟化技术 由于前面虚拟机存在某些缺点，Linux发展出了另一种虚拟化技术： Linux容器(Linux Containers，缩写为 LXC) Linux容器是与系统其他部分隔离开的一系列进程，从另一个镜像运行，并由该镜像提供支持进程所需的全部文件。容器提供的镜像包含了应用的所有依赖项，因而在从开发到测试再到生产的整个过程中，它都具有可移植性和一致性。 Linux 容器不是模拟一个完整的操作系统 而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。 容器与虚拟机不同，不需要捆绑一整套操作系统 ，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行。 对比: 比较了 Docker 和传统虚拟化方式的不同之处： *传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程； *容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核 且也没有进行硬件虚拟 。因此容器要比传统虚拟机更为轻便。 * 每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。 4、docker的基本组成 镜像（image) Docker 镜像（Image）就是一个只读的模板。镜像可以用来创建 Docker 容器，一个镜像可以创建很多容器。 它也相当于是一个root文件系统。比如官方镜像 centos:7 就包含了完整的一套 centos:7 最小系统的 root 文件系统。 相当于容器的“源代码”，docker镜像文件类似于Java的类模板，而docker容器实例类似于java中new出来的实例对象。 容器(containner) 1 、从面向对象角度 Docker 利用容器（Container）独立运行的一个或一组应用，应用程序或服务运行在容器里面，容器就类似于一个虚拟化的运行环境，容器是用镜像创建的运行实例。就像是Java中的类和实例对象一样，镜像是静态的定义，容器是镜像运行时的实体。容器为镜像提供了一个标准的和隔离的运行环境，它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台 2 、从镜像容器角度 可以把容器看做是一个简易版的 Linux 环境\\（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 仓库(repository) 仓库（Repository）是集中存放镜像文件的场所。 类似于Maven仓库，存放各种jar包的地方；github仓库，存放各种git项目的地方；Docker公司提供的官方registry被称为Docker Hub，存放各种镜像模板的地方。 仓库分为公开仓库（Public）和私有仓库（Private）两种形式。最大的公开仓库是 Docker Hub(https://hub.docker.com/)，存放了数量庞大的镜像供用户下载。 国内的公开仓库包括阿里云 、网易云等 需要正确的理解仓库/镜像/容器这几个概念: Docker 本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就是image镜像文件。只有通过这个镜像文件才能生成Docker容器实例(类似Java中new出来一个对象)。 image文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。 镜像文件 * image 文件生成的容器实例，本身也是一个文件 容器实例 * 一个容器运行一种服务，当我们需要的时候，就可以通过docker客户端创建一个对应的运行实例，也就是我们的容器 仓库 * 就是放一堆镜像的地方，我们可以把镜像发布到仓库中，需要的时候再从仓库中拉下来就可以了。 5、docker工作原理 Docker是一个Client-Server结构的系统，Docker守护进程运行在主机上， 然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。 容器，是一个运行时环境，就是我们前面说到的集装箱。 类似于mysql安装完成后再后台有一个服务进程，需要使用时通过客户端组件链接服务，如使用navicat工具链接数据库 6、整体架构及底层通信原理简述 Docker 是一个 C/S 模式的架构，后端是一个松耦合架构，众多模块各司其职。 docker运行的基本流程为: 1、用户是使用docker client 与Docker Daemon建立通信，并发送请求给后者 2、Docker Daemon作为Docker架构种的主体部分，首先提供Docker server的功能使其可以接受Docker Client的请求 3、Docker Engine 执行Docker内部的一系列工作，每一项工作都是一个job的形式存在 4、Job的运行过程中，当需要容器镜像时，则从Docker Registry 中下载镜像，并通过镜像管理驱动Graph driver 将下载镜像以Graph的形式存储。 5、当需要为Docker 容器运行资源或执行用户指令操作时，则通过Exec driver来完成。 6、Libcontainer 是一项独立的容器管理包，Network driver以及Exec driver 都是通过Libcontainer 来实现具体对容器进行操作。 7、docker为什么比虚拟机快 (1)docker有着比虚拟机更少的抽象层 由于docker不需要Hypervisor(虚拟机)实现硬件资源虚拟化,运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。 (2)docker利用的是宿主机的内核,而不需要加载操作系统OS内核 当新建一个容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。进而避免引寻、加载操作系统内核返回等比较费时费资源的过程,当新建一个虚拟机时,虚拟机软件需要加载OS,返回新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统,则省略了返回过程,因此新建一个docker容器只需要几秒钟。 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-03 22:28:18 "},"cloud_learn/docker/docker_install_on_ubuntu.html":{"url":"cloud_learn/docker/docker_install_on_ubuntu.html","title":"乌班图安装docker","keywords":"","body":"乌图班图安装docker 1、卸载旧版本 Docker 的旧版本被称为 docker，docker.io 或 docker-engine 。如果已安装，请卸载它们： sudo apt-get remove docker docker-engine docker.io containerd runc 2、设置仓库 更新 apt 包索引。 $ sudo apt-get update 安装 apt 依赖包，用于通过HTTPS来获取仓库: $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 添加 Docker 的官方 GPG 密钥： curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 通过搜索指纹的后8个字符，验证您现在是否拥有带有指纹的密钥。 sudo apt-key fingerprint 0EBFCD88 使用以下指令设置稳定版仓库 $ sudo add-apt-repository \\ \"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ \\ $(lsb_release -cs) \\ stable\" 安装 Docker Engine-Community 更新 apt 包索引。 $ sudo apt-get update 安装最新版本的 Docker Engine-Community 和 containerd ，或者转到下一步安装特定版本： $ sudo apt-get install docker-ce docker-ce-cli containerd.io 仓库中列出可用版本 sudo apt-cache madison docker-ce ## 使用第二列中的版本字符串安装特定版本，例如 5:18.09.1~3-0~ubuntu-xenial。 sudo apt-get install docker-ce=5:20.10.6~3-0~ubuntu-focal docker-ce-cli=5:20.10.6~3-0~ubuntu-focal containerd.io 验证结果 sudo docker run hello-world Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-03 13:38:13 "},"cloud_learn/docker/docker_install_on_centos.html":{"url":"cloud_learn/docker/docker_install_on_centos.html","title":"centos安装docker","keywords":"","body":"centos安装docker 1、前提说明 目前，CentOS 仅发行版本中的内核支持 Docker。Docker 运行在CentOS 7 (64-bit)上， 要求系统为64位、Linux系统内核版本为 3.8以上，这里选用Centos7.x 查看自己的内核 cat /etc/redhat-release ##uname命令用于打印当前系统相关信息（内核版本号、硬件架构、主机名称和操作系统类型等）。 uname -r 2、卸载旧版本 sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 3、yum安装gcc相关 # yum install -y gcc gcc-c++ 4、安装需要的软件包 # yum install -y yum-utils 5、设置stable镜像仓库 # yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 说明： 官方文档要求配置的源：yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 由于是海外资源，加载资源时容易404，推荐使用国内源，本文档使用阿里源 6、更新yum软件包索引 # yum makecache fast 7、安装Docker ce # yum -y install docker-ce docker-ce-cli containerd.io 8、启动docker # systemctl start docker 验证 # docker version 、9、卸载 # systemctl stop docker # yum remove docker-ce docker-ce-cli containerd.io # rm -rf /var/lib/docker # rm -rf /var/lib/containerd ## 10、 配置镜像加速器 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-03 21:53:06 "},"cloud_learn/docker/aliyun_images_speed_up.html":{"url":"cloud_learn/docker/aliyun_images_speed_up.html","title":"阿里云镜像加速","keywords":"","body":"阿里云镜像加速 登录地址 ​ https://promotion.aliyun.com/ntms/act/kubernetes.html 登陆阿里云开发者平台 点击控制台 选择容器镜像服务 获取加速器地址 根据系统获取操作文档 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-13 10:32:34 "},"cloud_learn/docker/docker_commond_images.html":{"url":"cloud_learn/docker/docker_commond_images.html","title":"镜像命令","keywords":"","body":"基础命令 帮助启动类命令 启动docker： systemctl start docker 停止docker： systemctl stop docker 重启docker： systemctl restart docker 查看docker状态： systemctl status docker 开机启动： systemctl enable docker 查看docker概要信息： docker info 查看docker总体帮助文档： docker --help 查看docker命令帮助文档： docker 具体命令 --help 镜像命令 列出本地主机上的镜像 # docker images [options] 各个选项说明: REPOSITORY：表示镜像的仓库源 TAG：镜像的标签版本号 IMAGE ID：镜像ID CREATED：镜像创建时间 SIZE：镜像大小 同一仓库源可以有多个 TAG版本，代表这个仓库源的不同个版本，我们使用 REPOSITORY:TAG 来定义不同的镜像。 如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像 OPTIONS说明： -a :列出本地所有的镜像（含历史映像层） -q :只显示镜像ID。 # docker images -a # docker images -q # docker images -aq 某个XXX镜像名字 # docker search [OPTIONS] 镜像名字 各项参数说明： name:镜像名称 desription:镜像说明 stars:点赞数量 offical:是否官方的 automated:是否自动构建的 OPTIONS说明： --limit : 只列出N个镜像，默认25个 # docker search --limit 5 redis docker pull 某个XXX镜像名字 docker pull 镜像名字[:TAG] docker pull 镜像名字 没有TAG就是最新版等价于docker pull 镜像名字:latest # docker pull ubuntu 查看镜像/容器/数据卷所占的空间 # docker system df images:镜像 containers:容器 local volumes：本地卷 build cache:构建缓存 docker rmi 某个XXX镜像名字ID 删除单个 docker rmi -f 镜像ID 删除多个 docker rmi -f 镜像名1:TAG 镜像名2:TAG 删除全部 docker rmi -f $(docker images -qa) 危险操作，没事别瞎执行 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 12:01:12 "},"cloud_learn/docker/docker_commond_containers.html":{"url":"cloud_learn/docker/docker_commond_containers.html","title":"容器命令","keywords":"","body":"容器命令 新建+启动容器 docker run [OPTIONS] IMAGE[COMMAD][ARG...] options说明：有些是一个减号，有些是两个减号 --name=\"容器新名字\" 为容器指定一个名称； -d: 后台运行容器并返回容器ID，也即启动守护式容器(后台运行)； -i：以交互模式运行容器，通常与 -t 同时使用； -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用； 也即启动交互式容器(前台有伪终端，等待交互)； -P: 随机端口映射，大写P -p: 指定端口映射，小写p 参数 说明 -p hostPort:containerPort 端口映射 -p 8080:80 -p hostPort:containerPort 配置监听地址 -p 10.0.0.100:8000:80 -p hostPort:containerPort:udp 指定协议 -p 8080:80:tcp -p 81:80 -p 443:443 指定多个 使用镜像centos:latest以交互模式启动一个容器,在容器内执行/bin/bash命令。 # docker run -it centos /bin/bash 参数说明： -i: 交互式操作。 -t: 终端。 centos : centos 镜像。 /bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。 要退出终端，直接输入 exit: 列出当前所有正在运行的容器 # docker ps [OPTIONS] OPTIONS说明（常用）： -a :列出当前所有正在运行的容器+历史上运行过的 -l :显示最近创建的容器。 -n：显示最近n个创建的容器。 -q :静默模式，只显示容器编号。 退出容器 # exit run进去容器，exit退出，容器停止 # ctrl+p+q run进去容器，ctrl+p+q退出，容器不停止 启动已停止运行的容器 ​ docker start 容器ID或者容器名 重启容器 docker restart 容器ID或者容器名 停止容器 ​ docker stop 容器ID或者容器名 强制停止容器 ​ docker kill 容器ID或容器名 删除已停止的容器 docker rm 容器ID 一次性删除多个容器实例 docker rm -f $(docker ps -a -q) docker ps -a -q | xargs docker rm 启动守护式容器(后台服务器) # docker run -d 镜像名称 #使用镜像centos:latest以后台模式启动一个容器 # docker run -d centos 问题：然后docker ps -a 进行查看, 会发现容器已经退出 很重要的要说明的一点: Docker容器后台运行,就必须有一个前台进程. 容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail），就是会自动退出的。 这个是docker的机制问题,比如你的web容器,我们以nginx为例，正常情况下, 我们配置启动服务只需要启动响应的service即可。例如service nginx start 但是,这样做,nginx为后台进程模式运行,就导致docker前台没有运行的应用, 这样的容器后台启动后,会立即自杀因为他觉得他没事可做了. 前台交互式启动 # docker run -it redis:6.0.8 操作截图见第一节 后台守护式启动 # docker run -d redis:6.0.8 查看容器日志 # docker logs 容器ID 查看容器内运行的进程 # docker top 容器ID 查看容器内部细节 # docker inspect 容器ID 进入正在运行的容器并以命令行交互 docker exec进入容器 # docker exec -it 容器ID bash docker attach 重新进入容器 # docker attach attach与exec比对 attach 直接进入容器启动命令的终端，不会启动新的进程用exit退出，会导致容器的停止。 exec 是在容器中打开新的终端，并且可以启动新的进程用exit退出，不会导致容器的停止。 生产中推荐大家使用 docker exec 命令，因为退出容器终端，不会导致容器的停止。 用之前的redis容器实例进入试试 docker exec -it 容器ID /bin/bash docker exec -it 容器ID /bin/bash 从容器内拷贝文件到主机上 容器→主机 docker cp 容器ID:容器内路径 目的主机路径 导入和导出容器 ​ export 导出容器的内容留作为一个tar归档文件[对应import命令] ​ import 从tar包中的内容创建一个新的文件系统再导入为镜像[对应export] ​ 案例 ​ docker export 容器ID > 文件名.tar ​ cat 文件名.tar | docker import - 镜像用户/镜像名:镜像版本号 常用命令 attach Attach to a running container # 当前 shell 下 attach 连接指定运行镜像 build Build an image from a Dockerfile # 通过 Dockerfile 定制镜像 commit Create a new image from a container changes # 提交当前容器为新的镜像 cp Copy files/folders from the containers filesystem to the host path #从容器中拷贝指定文件或者目录到宿主机中 create Create a new container # 创建一个新的容器，同 run，但不启动容器 diff Inspect changes on a container's filesystem # 查看 docker 容器变化 events Get real time events from the server # 从 docker 服务获取容器实时事件 exec Run a command in an existing container # 在已存在的容器上运行命令 export Stream the contents of a container as a tar archive # 导出容器的内容流作为一个 tar 归档文件[对应 import ] history Show the history of an image # 展示一个镜像形成历史 images List images # 列出系统当前镜像 import Create a new filesystem image from the contents of a tarball # 从tar包中的内容创建一个新的文件系统映像[对应export] info Display system-wide information # 显示系统相关信息 inspect Return low-level information on a container # 查看容器详细信息 kill Kill a running container # kill 指定 docker 容器 load Load an image from a tar archive # 从一个 tar 包中加载一个镜像[对应 save] login Register or Login to the docker registry server # 注册或者登陆一个 docker 源服务器 logout Log out from a Docker registry server # 从当前 Docker registry 退出 logs Fetch the logs of a container # 输出当前容器日志信息 port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT # 查看映射端口对应的容器内部源端口 pause Pause all processes within a container # 暂停容器 ps List containers # 列出容器列表 pull Pull an image or a repository from the docker registry server # 从docker镜像源服务器拉取指定镜像或者库镜像 push Push an image or a repository to the docker registry server # 推送指定镜像或者库镜像至docker源服务器 restart Restart a running container # 重启运行的容器 rm Remove one or more containers # 移除一个或者多个容器 rmi Remove one or more images # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除] run Run a command in a new container # 创建一个新的容器并运行一个命令 save Save an image to a tar archive # 保存一个镜像为一个 tar 包[对应 load] search Search for an image on the Docker Hub # 在 docker hub 中搜索镜像 start Start a stopped containers # 启动容器 stop Stop a running containers # 停止容器 tag Tag an image into a repository # 给源中镜像打标签 top Lookup the running processes of a container # 查看容器中运行的进程信息 unpause Unpause a paused container # 取消暂停容器 version Show the docker version information # 查看 docker 版本号 wait Block until a container stops, then print its exit code # 截取容器停止时的退出状态值 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 15:07:32 "},"cloud_learn/docker/docker_images.html":{"url":"cloud_learn/docker/docker_images.html","title":"docker镜像","keywords":"","body":"docker镜像 镜像 ​ 是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，我们把应用程序和配置依赖打包好形成一个可交付的运行环境(包括代码、运行时需要的库、环境变量和配置文件等)，这个打包好的运行环境就是image镜像文件。 ​ 只有通过这个镜像文件才能生成Docker容器实例(类似Java中new出来一个对象)。 分层的镜像 以我们的pull为例，在下载的过程中我们可以看到docker的镜像好像是在一层一层的在下载 UnionFS（联合文件系统） UnionFS（联合文件系统）：Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持 对文件系统的修改作为一次提交来一层层的叠加， 同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基础。 镜像可以通过分层来进行继承 ，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 Docker镜像加载原理： docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。 ​ bootfs(boot file system)主要包含bootloader和kernel, bootloader主要是引导加载kernel, Linux刚启动时会加载bootfs文件系统， 在Docker镜像的最底层是引导文件系统bootfs。 这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。 rootfs (root file system) ，在bootfs之上 。包含的就是典型 Linux 系统中的 /dev, /proc, /bin, /etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。 ￼ 对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供 rootfs 就行了。由此可见对于不同的linux发行版, bootfs基本是一致的, rootfs会有差别, 因此不同的发行版可以公用bootfs。 为什么 Docker 镜像要采用这种分层结构呢 ​ 镜像分层最大的一个好处就是共享资源，方便复制迁移，就是为了复用。 比如说有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像； 同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。 Docker镜像层都是只读的，容器层是可写的 当容器启动时，一个新的可写层被加载到镜像的顶部。 这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。 当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。 所有对容器的改动 - 无论添加、删除、还是修改文件都只会发生在容器层中。只有容器层是可写的，容器层下面的所有镜像层都是只读的。 Docker镜像commit操作案例 docker commit提交容器副本使之成为一个新的镜像 命令格式： docker commit -m=\"提交的描述信息\" -a=\"作者\" 容器ID 要创建的目标镜像名:[标签名] 案例演示ubuntu安装vim 从Hub上下载ubuntu镜像到本地并成功运行原始的默认Ubuntu镜像是不带着vim命令的外网连通的情况下，安装vim，安装完成后，commit我们自己的新镜像，启动我们的新镜像并和原来的对比 #交互式创建容器 root@wjh:/home/wjh# docker run -it ubuntu /bin/bash #更新包管理工具 root@ea2af0a25678:/# apt-get update #安装vim root@ea2af0a25678:/# apt-get -y install vim #commit root@wjh:/home/wjh# docker commit -m=\"add vim cmd\" -a=\"wjh\" ea2af0a25678 wjh/myubuntu:1.0 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 16:50:39 "},"cloud_learn/docker/docker_push_aliyun.html":{"url":"cloud_learn/docker/docker_push_aliyun.html","title":"推送镜像到阿里云","keywords":"","body":"推送镜像到阿里云 本地镜像素材原型 创建仓库镜像 选择控制台，进入容器镜像服务 选择个人实例 命名空间 ​ 仓库名称 ​ 进入管理界面获得脚本 将镜像推送到阿里云 ### seq1:登录阿里云Docker Registry $ docker login --username=1355997****@139.com registry.cn-hangzhou.aliyuncs.com seq2:镜像打标签 $ docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/fhwlkj/ubuntu:[镜像版本号] Seq3:将镜像推送到Registry $ docker push registry.cn-hangzhou.aliyuncs.com/fhwlkj/ubuntu:[镜像版本号] 拉去阿里仓库镜像到本地 $ docker pull registry.cn-hangzhou.aliyuncs.com/fhwlkj/ubuntu:[镜像版本号] Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 17:26:36 "},"cloud_learn/docker/docker_push_local.html":{"url":"cloud_learn/docker/docker_push_local.html","title":"推送镜像到本地","keywords":"","body":"推送镜像到本地 ## 下载镜像Docker Registry # docker pull registry ## 运行私有库Registry，相当于本地有个私有Docker hub $ docker run -d -p 5000:5000 -v /zzyyuse/myregistry/:/tmp/registry --privileged=true registry 默认情况，仓库被创建在容器的/var/lib/registry目录下，建议自行用容器卷映射，方便于宿主机联调 案例演示创建一个新镜像，ubuntu安装ifconfig命令 apt-get -y install net-tools root@wjh:/home/wjh# docker commit -m=\"本地测试\" -a=\"wjh\" 6dc642adb22e wjhubuntu:1.1 命令： 在容器外执行，记得 curl验证私服库上有什么镜像 root@wjh:/home/wjh# curl -XGET http://172.16.34.129:5000/v2/_catalog {\"repositories\":[]} 将新镜像zzyyubuntu:1.2修改符合私服规范的Tag 按照公式： docker tag 镜像:Tag Host:Port/Repository:Tag 自己host主机IP地址，填写同学你们自己的，不要粘贴错误，O(∩_∩)O 使用命令 docker tag 将wjhbuntu:1.1这个镜像修改为172.16.34.129:5000/wjhubuntu:1.1 root@wjh:~# docker tag wjhubuntu:1.1 172.16.34.129:5000/wjhubuntu:1.1 修改配置文件使之支持http root@wjh:~# cat /etc/docker/daemon.json { \"registry-mirrors\": [\"https://rcl1cdp5.mirror.aliyuncs.com\"], \"insecure-registries\":[\"172.16.34.129:5000\"] } 上述理由：docker默认不允许http方式推送镜像，通过配置选项来取消这个限制。====> 修改完后如果不生效，建议重启docker push推送到私服库 root@wjh:~# docker push 172.16.34.129:5000/wjhubuntu:1.1 curl验证私服库上有什么镜像2 root@wjh:~# curl -XGET http://172.16.34.129:5000/v2/_catalog {\"repositories\":[\"wjhubuntu\"]} pull到本地并运行 root@wjh:~# docker pull 172.16.34.129:5000/wjhubuntu:1.1 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-13 16:48:54 "},"cloud_learn/docker/docker_valumes.html":{"url":"cloud_learn/docker/docker_valumes.html","title":"Docker容器数据卷","keywords":"","body":"Docker容器数据卷 什么是卷 卷就是目录或文件，存在于一个或多个容器中，由docker挂载到容器，但不属于联合文件系统，因此能够绕过Union File System提供一些用于持续存储或共享数据的特性： 卷的设计目的就是数据的持久化，完全独立于容器的生存周期，因此Docker不会在容器删除时删除其挂载的数据卷 docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名 能干嘛 将运用与运行的环境打包镜像，run后形成容器实例运行 ，但是我们对数据的要求希望是持久化的 Docker容器产生的数据，如果不备份，那么当容器实例删除后，容器内的数据自然也就没有了。 为了能保存数据在docker中我们使用卷。 特点： 1：数据卷可在容器之间共享或重用数据 2：卷中的更改可以直接实时生效，爽 3：数据卷中的更改不会包含在镜像的更新中 4：数据卷的生命周期一直持续到没有容器使用它为止 数据卷案例 命令 公式：docker run -it -v /宿主机目录:/容器内目录 ubuntu /bin/bash 创建容器 [root@wjh ~]# docker run -it --name myu3 --privileged=true -v /tmp/myHostData:/tmp/myDockerData ubuntu /bin/bash root@f7ef2383e12d:/# 查看数据卷是否挂载成功 [root@wjh ~]# docker inspect 容器id 读写规则映射添加说明 读写(默认) 命令格式：docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:rw 镜像名 [root@wjh ~]# docker run -it --name myu4 --privileged=true -v /tmp/myHostData:/tmp/myDockerData:rw ubuntu /bin/bash 只读 容器实例内部被限制，只能读取不能写 命令格式：docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:ro 镜像名 [root@wjh ~]# docker run -it --name myu5 --privileged=true -v /tmp/myHostData:/tmp/myDockerData:ro ubuntu /bin/bash 卷的继承和共享 命令格式： docker run -it --privileged=true --volumes-from 父类 --name u2 ubuntu docker run -it --privileged=true --volumes-from myu4 --name u2 ubuntu Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 20:39:26 "},"cloud_learn/docker/docker_install_tomact.html":{"url":"cloud_learn/docker/docker_install_tomact.html","title":"安装tomact","keywords":"","body":"安装tomact docker hub上面查找tomcat镜像 # docker search tomcat 从docker hub上拉取tomcat镜像到本地 # docker pull tomact 确定拉取的镜像 # docker images 使用tomcat镜像创建容器实例(也叫运行镜像) docker run -it -p 8080:8080 tomcat 404问题处理 把webapps.dist目录换成webapps 面修改版安装 # docker pull billygoo/tomcat8-jdk8 # docker run -d -p 8080:8080 --name mytomcat8 billygoo/tomcat8-jdk8 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 21:05:56 "},"cloud_learn/docker/docker_install_mysql.html":{"url":"cloud_learn/docker/docker_install_mysql.html","title":"安装mysql","keywords":"","body":"安装mysql 查找镜像 # docker search mysql 拉取镜像 # docker pull mysql:5.7 创建容器 docker run -d -p 3306:3306 --privileged=true -v /wjhuse/mysql/log:/var/log/mysql -v /wjhuse/mysql/data:/var/lib/mysql -v /wjhuse/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:5.7 说明： -v /wjhuse/mysql/log:/var/log/mysql -------------------------指定log目录 -v /wjhuse/mysql/data:/var/lib/mysql --------------------------指定数据存放目录 -v /wjhuse/mysql/conf:/etc/mysql/conf.d ---------------------------指定配置文件目录 创建配置文件 cat >/wjhuse/mysql/conf/my.conf 重新启动mysql容器实例再重新进入并查看字符编码 # docker restart mysql # docker exec -it msyql bash root@2c882c696216:/# mysql -uroot -p123456 mysql> SHOW VARIABLES LIKE 'character%'; Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-07 15:44:43 "},"cloud_learn/docker/docker_install_redis.html":{"url":"cloud_learn/docker/docker_install_redis.html","title":"安装redis","keywords":"","body":"安装redis 从docker hub上(阿里云加速器)拉取redis镜像到本地标签为6.0.8 # docker pull redis:6.0.8 在CentOS宿主机下新建目录/app/redis [root@wjh conf]# mkdir -p /app/redis/ /app/redis目录下修改redis.conf文件 内容件conf 创建容器 # docker run -p 6379:6379 --name myr3 --privileged=true -v /app/redis/redis.conf:/etc/redis/redis.conf -v /app/redis/data:/data -d redis:6.0.8 redis-server /etc/redis/redis.conf 测速redis-cli链接 redis]# docker exec -it 9d8321580455 /bin/bash root@9d8321580455:/data# redis-cli Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 22:25:42 "},"cloud_learn/docker/database_main_from.html":{"url":"cloud_learn/docker/database_main_from.html","title":"数据库主从","keywords":"","body":"数据库主从 1、新建主服务器容器实例3307 docker run -p 3307:3306 --name mysql-master \\ -v /mydata/mysql-master/log:/var/log/mysql \\ -v /mydata/mysql-master/data:/var/lib/mysql \\ -v /mydata/mysql-master/conf:/etc/mysql \\ -e MYSQL_ROOT_PASSWORD=root \\ -d mysql:5.7 2、进入/mydata/mysql-master/conf目录下新建my.cnf [mysqld] ## 设置server_id，同一局域网中需要唯一 server_id=101 ## 指定不需要同步的数据库名称 binlog-ignore-db=mysql ## 开启二进制日志功能 log-bin=mall-mysql-bin ## 设置二进制日志使用内存大小（事务） binlog_cache_size=1M ## 设置使用的二进制日志格式（mixed,statement,row） binlog_format=mixed ## 二进制日志过期清理时间。默认值为0，表示不自动清理。 expire_logs_days=7 ## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 ## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 slave_skip_errors=1062 3、修改完配置后重启master实例 # docker restart mysql-master 4、进入mysql-master容器 [root@wjh ~]# docker exec -it mysql-master /bin/bash root@a856341f5cb9:/# mysql -uroot -proot 5、master容器实例内创建数据同步用户 mysql> CREATE USER 'slave'@'%' IDENTIFIED BY '123456'; Query OK, 0 rows affected (0.00 sec) mysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%'; Query OK, 0 rows affected (0.00 sec) 6、新建从服务器容器实例3308 docker run -p 3308:3306 --name mysql-slave \\ -v /mydata/mysql-slave/log:/var/log/mysql \\ -v /mydata/mysql-slave/data:/var/lib/mysql \\ -v /mydata/mysql-slave/conf:/etc/mysql \\ -e MYSQL_ROOT_PASSWORD=root \\ -d mysql:5.7 7、进入/mydata/mysql-slave/conf目录下新建my.cnf [mysqld] ## 设置server_id，同一局域网中需要唯一 server_id=102 ## 指定不需要同步的数据库名称 binlog-ignore-db=mysql ## 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用 log-bin=mall-mysql-slave1-bin ## 设置二进制日志使用内存大小（事务） binlog_cache_size=1M ## 设置使用的二进制日志格式（mixed,statement,row） binlog_format=mixed ## 二进制日志过期清理时间。默认值为0，表示不自动清理。 expire_logs_days=7 ## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 ## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 slave_skip_errors=1062 ## relay_log配置中继日志 relay_log=mall-mysql-relay-bin ## log_slave_updates表示slave将复制事件写进自己的二进制日志 log_slave_updates=1 ## slave设置为只读（具有super权限的用户除外） read_only=1 8、修改完配置后重启slave实例 docker restart mysql-slave 9、在主数据库中查看主从同步状态 >show master status; 10、进入mysql-slave容器 docker exec -it mysql-slave /bin/mysql -uroot -proot 11、在从数据库中配置主从复制 mysql -uroot -proot change master to master_host='10.0.0.200',master_user='slave',master_password='123456',master_port=3307,master_log_file='mall-mysql-bin.000001',master_log_pos=154,master_connect_retry=30; 主从复制命令参数说明 master_host：主数据库的IP地址； master_port：主数据库的运行端口； master_user：在主数据库创建的用于同步数据的用户账号； master_password：在主数据库创建的用于同步数据的用户密码； master_log_file：指定从数据库要复制数据的日志文件，通过查看主数据的状态，获取File参数； master_log_pos：指定从数据库从哪个位置开始复制数据，通过查看主数据的状态，获取Position参数； master_connect_retry：连接失败重试的时间间隔，单位为秒。 12、在从数据库中查看主从同步状态 mysql> show slave status \\G; 13、在从数据库中开启主从同步 mysql> start slave; Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-07 15:45:49 "},"cloud_learn/docker/redis_cluster_question.html":{"url":"cloud_learn/docker/redis_cluster_question.html","title":"redis集群面试","keywords":"","body":"redis集群面试 q:1~2亿条数据需要缓存，请问如何设计这个存储案例 单机单台100%不可能，肯定是分布式存储，用redis如何落地？ 哈希取余分区 ​ 2亿条记录就是2亿个k,v，我们单机不行必须要分布式多机，假设有3台机器构成一个集群，用户每次读写操作都是根据公式： hash(key) % N个机器台数，计算出哈希值，用来决定数据映射到哪一个节点上。 优点： 简单粗暴，直接有效，只需要预估好数据规划好节点，例如3台、8台、10台，就能保证一段时间的数据支撑。使用Hash算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡+分而治之的作用 缺点： 原来规划好的节点，进行扩容或者缩容就比较麻烦了额，不管扩缩，每次数据变动导致节点有变动，映射关系需要重新进行计算，在服务器个数固定不变时没有问题，如果需要弹性扩容或故障停机的情况下，原来的取模公式就会发生变化：Hash(key)/3会变成Hash(key) /?。此时地址经过取余运算的结果将发生很大变化，根据公式获取的服务器也会变得不可控。 某个redis机器宕机了，由于台数数量变化，会导致hash取余全部数据重新洗牌。 一致性哈希算法分区 　　一致性哈希算法在1997年由麻省理工学院中提出的，设计目标是为了解决分布式缓存数据变动和映射问题，某个机器宕机了，分母数量改变了，自然取余数不OK了。 提出一致性Hash解决方案。目的是当服务器个数发生变动时，尽量减少影响客户端到服务器的映射关系 算法构建一致性哈希环 一致性哈希算法必然有个hash函数并按照算法产生hash值，这个算法的所有可能哈希值会构成一个全量集，这个集合可以成为一个hash空间[0,2^32-1]，这个是一个线性空间，但是在算法中，我们通过适当的逻辑控制将它首尾相连(0 = 2^32),这样让它逻辑上形成了一个环形空间。 它也是按照使用取模的方法，前面笔记介绍的节点取模法是对节点（服务器）的数量进行取模。而一致性Hash算法是对2^32取模，简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希环如下图：整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。 ​ 服务器IP节点映射 将集群中各个IP节点映射到环上的某一个位置。 将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。假如4个节点NodeA、B、C、D，经过IP地址的哈希函数计算(hash(ip))，使用IP地址哈希后在环空间的位置如下： ​ key落到服务器的落键规则 当我们需要存储一个kv键值对时，首先计算key的hash值，hash(key)，将这个key使用相同的函数Hash计算出哈希值并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器，并将该键值对存储在该节点上。 如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 ​ 优点 一致性哈希算法的容错性 假设Node C宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。简单说，就是C挂了，受到影响的只是B、C之间的数据，并且这些数据会转移到D进行存储。 一致性哈希算法的扩展性 数据量增加了，需要增加一台节点NodeX，X的位置在A和B之间，那收到影响的也就是A到X之间的数据，重新把A到X的数据录入到X上即可，不会导致hash取余全部数据重新洗牌。 ​ 缺点 Hash环的数据倾斜问题 一致性Hash算法在服务节点太少时，容易因为节点分布不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题， 例如系统中只有两台服务器： ​ 为了在节点数目发生改变时尽可能少的迁移数据 将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到临近的存储节点存放。 而当有节点加入或退出时仅影响该节点在Hash环上顺时针相邻的后续节点。 优点 加入和删除节点只影响哈希环中顺时针方向的相邻的节点，对其他节点无影响。 缺点 数据的分布和节点的位置有关，因为这些节点不是均匀的分布在哈希环上的，所以数据在进行存储时达不到均匀分布的效果。 哈希槽分区 为什么出现 解决一致性哈希算的数据倾斜问题 哈希槽实质就是一个数组，数组[0,2^14 -1]形成hash slot空间。 能干什么 解决均匀分配的问题，在数据和节点之间又加入了一层，把这层称为哈希槽（slot），用于管理数据和节点之间的关系，现在就相当于节点上放的是槽，槽里放的是数据。 槽解决的是粒度问题，相当于把粒度变大了，这样便于数据移动。 哈希解决的是映射问题，使用key的哈希值来计算所在的槽，便于数据分配。 多少个hash槽 一个集群只能有16384个槽，编号0-16383（0-2^14-1）。这些槽会分配给集群中的所有主节点，分配策略没有要求。可以指定哪些编号的槽分配给哪个主节点。集群会记录节点和槽的对应关系。解决了节点和槽的关系后，接下来就需要对key求哈希值，然后对16384取余，余数是几key就落入对应的槽里。slot = CRC16(key) % 16384。以槽为单位移动数据，因为槽的数目是固定的，处理起来比较容易，这样数据移动问题就解决了。 哈希槽计算 Redis 集群中内置了 16384 个哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。当需要在 Redis 集群中放置一个 key-value时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，也就是映射到某个节点上。如下代码，key之A 、B在Node2， key之C落在Node3上 ​ Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-06 21:39:11 "},"cloud_learn/docker/redis_cluster.html":{"url":"cloud_learn/docker/redis_cluster.html","title":"安装redis集群","keywords":"","body":"redis集群 新建6个docker容器redis实例 docker run -d --name redis-node-1 --net host --privileged=true -v /data/redis/share/redis-node-1:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6381 docker run -d --name redis-node-2 --net host --privileged=true -v /data/redis/share/redis-node-2:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6382 docker run -d --name redis-node-3 --net host --privileged=true -v /data/redis/share/redis-node-3:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6383 docker run -d --name redis-node-4 --net host --privileged=true -v /data/redis/share/redis-node-4:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6384 docker run -d --name redis-node-5 --net host --privileged=true -v /data/redis/share/redis-node-5:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6385 docker run -d --name redis-node-6 --net host --privileged=true -v /data/redis/share/redis-node-6:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6386 docker ps -a docker run ---------------创建并运行docker容器实例 name redis-node-6 ---------------容器名字 net host ---------------使用宿主机的IP和端口，默认 privileged=true ----------------获取宿主机root用户权限 -v /data/redis/share/redis-node-6:/data ---------------容器卷，宿主机地址:docker内部地 redis:6.0.8 ---------------redis镜像和版本号 cluster-enabled yes ---------------开启redis集群 appendonly yes --------------开启持久化 port 6386 -------------redis端口号 进入容器redis-node-1并为6台机器构建集群关系 进入容器 docker exec -it redis-node-1 /bin/bash 构建主从关系 //注意，进入docker容器后才能执行一下命令，且注意自己的真实IP地址 redis-cli --cluster create 10.0.0.200:6381 10.0.0.200:6382 10.0.0.200:6383 10.0.0.200:6384 10.0.0.200:6385 10.0.0.200:6386 --cluster-replicas 1 # 在弹出信息后输入yes进行确认 链接进入6381作为切入点，查看集群状态 root@wjh:/data# redis-cli -p 6381 127.0.0.1:6381> key * 127.0.0.1:6381> cluster info 127.0.0.1:6381> cluster nodes 主从容错切换迁移案例 数据读写存储 防止路由失效加参数-c并新增两个key 容错切换迁移 docker stop redis-node-1 先还原之前的3主3从 [root@wjh ~]# docker start redis-node-1 [root@wjh ~]# docker stop redis-node-4 [root@wjh ~]# docker start redis-node-4 查看集群状态 [root@wjh ~]# docker start redis-node-4 [root@wjh ~]# docker exec -it redis-node-1 /bin/bash 主从扩容案例 新建6387、6388两个节点+新建后启动+查看是否8节点 docker run -d --name redis-node-7 --net host --privileged=true -v /data/redis/share/redis-node-7:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6387 docker run -d --name redis-node-8 --net host --privileged=true -v /data/redis/share/redis-node-8:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6388 docker ps 进入6387容器实例内部 [root@wjh ~]# docker exec -it redis-node-7 /bin/bash 将新增的6387节点(空槽号)作为master节点加入原集群 将新增的6387作为master节点加入集群 redis-cli --cluster add-node 自己实际IP地址:6387 自己实际IP地址:6381 6387 就是将要作为master新增节点 6381 就是原来集群节点里面的领路人，相当于6387拜拜6381的码头从而找到组织加入集群 root@wjh:/data# redis-cli --cluster add-node 10.0.0.200:6387 10.0.0.200:6381 检查集群情况第1次 进入docker exec -it redis-node-7 /bin/bash redis-cli --cluster check 真实ip地址:6381 [root@wjh ~]# docker exec -it redis-node-7 /bin/bash root@wjh:/data# redis-cli --cluster check 10.0.0.200:6381 重新分派槽号 重新分派槽号 命令:redis-cli --cluster reshard IP地址:端口号 redis-cli --cluster reshard 10.0.0.200:6381 查看集群情况 为什么6387是3个新的区间，以前的还是连续？ 重新分配成本太高，所以前3家各自匀出来一部分，从6381/6382/6383三个旧节点分别匀出1364个坑位给新节点6387 为主节点6387分配从节点6388 命令：redis-cli --cluster add-node ip:新slave端口 ip:新master端口 --cluster-slave --cluster-master-id 新主机节点ID redis-cli --cluster add-node 10.0.0.200:6388 10.0.0.200:6387 --cluster-slave --cluster-master-id f0b4e73f8e334de67a2c91601d5f874a473e0578-------这个是6387的编号，按照自己实际情况 查看集群情况 redis-cli --cluster check 10.0.0.200:6381 主从缩容案例 目的：6387和6388下线 检查集群情况1获得6388的节点ID docker exec -it redis-node-1 /bin/bash redis-cli --cluster check 10.0.0.200:6382 将6388删除从集群中将4号从节点6388删除 命令：redis-cli --cluster del-node ip:从机端口 从机6388节点ID redis-cli --cluster del-node 10.0.0.200:6388 a0f8238e18d27339bd79a2868a3fbd5efbc5cdc8 将6387的槽号清空，重新分配，本例将清出来的槽号都给6381 redis-cli --cluster reshard 10.0.0.200:6381 检查集群情况第二次 root@wjh:/data# redis-cli --cluster check 10.0.0.200:6381 10.0.0.200:6381 (69f01736...) -> 0 keys | 8192 slots | 1 slaves. 10.0.0.200:6383 (10f3bc0e...) -> 0 keys | 4096 slots | 1 slaves. 10.0.0.200:6387 (f0b4e73f...) -> 0 keys | 0 slots | 0 slaves. 10.0.0.200:6382 (2de7935a...) -> 0 keys | 4096 slots | 1 slaves. 将6387删除 命令：redis-cli --cluster del-node ip:端口 6387节点ID redis-cli --cluster del-node 10.0.0.200:6387 f0b4e73f8e334de67a2c91601d5f874a473e0578 检查集群情况第三次 root@wjh:/data# redis-cli --cluster check 10.0.0.200:6381 10.0.0.200:6381 (69f01736...) -> 0 keys | 8192 slots | 1 slaves. 10.0.0.200:6383 (10f3bc0e...) -> 0 keys | 4096 slots | 1 slaves. 10.0.0.200:6382 (2de7935a...) -> 0 keys | 4096 slots | 1 slaves. Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-07 00:07:40 "},"cloud_learn/docker/dockerfile.html":{"url":"cloud_learn/docker/dockerfile.html","title":"DockerFile解析","keywords":"","body":"DockerFile解析 是什么 Dockerfile是用来构建Docker镜像的文本文件，是由一条条构建镜像所需的指令和参数构成的脚本。 构建三步骤 编写Dockerfile文件 docker build命令构建镜像 docker run依镜像运行容器实例 Dockerfile内容基础知识 1：每条保留字指令都必须为大写字母且后面要跟随至少一个参数 2：指令按照从上到下，顺序执行 3：#表示注释 4：每条指令都会创建一个新的镜像层并对镜像进行提交 Docker执行Dockerfile的大致流程 （1）docker从基础镜像运行一个容器 （2）执行一条指令并对容器作出修改 （3）执行类似docker commit的操作提交一个新的镜像层 （4）docker再基于刚提交的镜像运行一个新容器 （5）执行dockerfile中的下一条指令直到所有指令都执行完成 从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段， Dockerfile是软件的原材料 Docker镜像是软件的交付品 Docker容器则可以认为是软件镜像的运行态，也即依照镜像运行的容器实例 Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。 1、Dockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制)等等; 2、Docker镜像，在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，当运行 Docker镜像时会真正开始提供服务; 3、Docker容器，容器是直接提供服务的。 DockerFile常用保留字指令 FROM 基础镜像，当前新镜像是基于哪个镜像的，指定一个已经存在的镜像作为模板，第一条必须是from MAINTAINER 镜像维护者的姓名和邮箱地址 RUN 容器构建时需要运行的命令 两种格式: SHELL格式：RUN RUN yum -y install vim EXEC格式：RUN [\"可执行文件\"，\"参数1\"，\"参数2\"] RUN [\"./test.php\",\"dev\",\"offline\"] #等价于 RUN ./test.php dev offline RUN是在 docker build时运行 EXPOSE 当前容器对外暴露出的端口 WORKDIR 指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点 USER 指定该镜像以什么样的用户去执行，如果都不指定，默认是root ENV 用来在构建镜像过程中设置环境变量 ENV MY_PATH /usr/mytest 这个环境变量可以在后续的任何RUN指令中使用，这就如同在命令前面指定了环境变量前缀一样； 也可以在其它指令中直接使用这些环境变量， 比如：WORKDIR $MY_PATH ADD 将宿主机目录下的文件拷贝进镜像且会自动处理URL和解压tar压缩包 COPY 类似ADD，拷贝文件和目录到镜像中。 将从构建上下文目录中 的文件/目录复制到新的一层的镜像内的 位置 ## Shell形式 COPY src dest # json形式 COPY [\"src\", \"dest\"] 参数 ：源文件或者源目录 ：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 VOLUME 容器数据卷，用于数据保存和持久化工作 CMD 指定容器启动后的要干的事情 注意： Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效，CMD 会被 docker run 之后的参数替换 它和前面RUN命令的区别 CMD是在docker run 时运行 RUN是在 docker build时运行。 ENTRYPOINT 也是用来指定一个容器启动时要运行的命令,类似于 CMD 指令，但是ENTRYPOINT不会被docker run后面的命令覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序 命令格式: ENTRYPONINT [\"\",\"\",\"param2\".....] ENTRYPOINT可以和CMD一起用，一般是变参才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参。 当指定了ENTRYPOINT后，CMD的含义就发生了变化，不再是直接运行其命令而是将CMD的内容作为参数传递给ENTRYPOINT指令，他两个组合会变成\"\" 案例如下：假设已通过 Dockerfile 构建了 nginx:test 镜像： FROM nginx ENTRTYPOINT[\"nginx\",\"-c\"] # 定参 CMD [\"/etc/nginx/nginx.conf\"] #变参 是否传参 按照dockerfile编写执行 传参运行 Docker命令 docker run nginx:test docker run nginx:test -c /etc/nginx/new.conf 衍生出的实际命令 nginx -c /etc/nginx/nginx.conf nginx -c /etc/nginx/new.conf 优点 在执行docker run的时候可以指定 ENTRYPOINT 运行所需的参数。 注意 如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。 案例 自定义镜像mycentosjava8 要求:Centos7镜像具备vim+ifconfig+jdk8 jdk下载的镜像地址：https://mirrors.yangxingzhen.com/jdk/ 1、准备编写Dockerfile文件 注意：开头字母必须大写 [root@wjh ~]# mkdir myfile [root@wjh ~]# cd myfile [root@wjh myfile]# touch Dockerfile FROM centos MAINTAINER wjh WORKDIR $MYPATH #install vim tools RUN yum -y install vim #install ifconfig cat network or ip RUN yum -y isntall net-tools #install java8 and lib RUN yum -y install glibc.i686 RUN mkdir /usr/local/java # ADD is relative path jar,input jdk-8u181-linux-x64.tar.gz to container,package need with dockerfile file on the same path ADD jdk-8u181-linux-x64.tar.gz /usr/local/java/ #set java environment path ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH ENV PATH $JAVA_HOME/bin:$PATH EXPOSE 80 CMD echo $MYPATH CMD echo \"success--------------ok\" CMD /bin/bash 2、构建 # docker build -t 新镜像名字:TAG . docker build -t centosjava8:1.5 . 注意，上面TAG后面有个空格，有个点 3、运行 #docker run -it 新镜像名字:TAG docker run -it centosjava8:1.5 /bin/bash 删除虚悬镜像 docker image ls -f dangling=true Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-07 16:22:19 "},"cloud_learn/docker/docker_network.html":{"url":"cloud_learn/docker/docker_network.html","title":"Docker网络","keywords":"","body":"Docker网络 是什么 docker不启动，默认网络情况下网卡为 ens33/eth0 lo virbro virbro说明： 在CentOS7的安装过程中如果有选择相关虚拟化的的服务安装系统后，启动网卡时会发现有一个以网桥连接的私网地址的virbr0网卡(virbr0网卡：它还有一个固定的默认IP地址192.168.122.1)，是做虚拟机网桥的使用的，其作用是为连接其上的虚机网卡提供 NAT访问外网的功能。 docker启动后，网络情况 常用基本命令 查看网络 docker netwokr ls 查看网络源数据 [root@wjh ~]# docker network inspect bridge 创建、删除网络 [root@wjh ~]# docker network create test_network [root@wjh ~]# docker network ls [root@wjh ~]# docker network rm test_network 能干嘛 1、容器间的互联和通信以及端口映射 2、容器IP变动时候可以通过服务名直接网络通信而不受到影响 网络模式 网络模式 bridge模式：使用--network bridge指定，默认使用docker0 host模式：使用--network host指定 none模式：使用--network none指定 container模式：使用--network container:NAME或者容器ID指定 bridge ocker 服务默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），该桥接网络的名称为docker0，它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。Docker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信。 查看 bridge 网络的详细信息，并通过 grep 获取名称项 [root@wjh ~]# docker network inspect bridge | grep name \"com.docker.network.bridge.name\": \"docker0\", [root@wjh ~]# ifconfig | grep docker docker0: flags=4099 mtu 1500 [root@wjh ~]# 1、Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。 2、docker run 的时候，没有指定network的话默认使用的网桥模式就是bridge，使用的就是docker0。在宿主机ifconfig,就可以看到docker0和自己create的network(后面讲)eth0，eth1，eth2……代表网卡一，网卡二，网卡三……，lo代表127.0.0.1，即localhost，inet addr用来表示网卡的IP地址 3、网桥docker0创建一对对等虚拟设备接口一个叫veth，另一个叫eth0，成对匹配。 3.1 整个宿主机的网桥模式都是docker0，类似一个交换机有一堆接口，每个接口叫veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫veth pair）； 3.2 每个容器实例内部也有一块网卡，每个接口叫eth0； 3.3 docker0上面的每个veth匹配某个容器实例内部的eth0，两两配对，一一匹配。 通过上述，将宿主机上的所有容器都连接到这个内部网络上，两个容器在同一个网络下,会从这个网关下各自拿到分配的ip，此时两个容器的网络是互通的。 案例 docker run -d -p 8081:8080 --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --name tomcat82 billygoo/tomcat8-jdk8 host 直接使用宿主机的 IP 地址与外界进行通信，不再需要额外进行NAT 转换。 docker run -d -p 8083:8080 --network host --name tomcat83 billygoo/tomcat8-jdk8 问题： docke启动时总是遇见标题中的警告 原因： docker启动时指定--network=host或-net=host，如果还指定了-p映射端口，那这个时候就会有此警告， 并且通过-p设置的参数将不会起到任何作用，端口号会以主机端口号为主，重复时则递增。 解决: 解决的办法就是使用docker的其他网络模式，例如--network=bridge，这样就可以解决问题，或者直接无视 docker run -d --network host --name tomcat84 billygoo/tomcat8-jdk8 在浏览器访问容器内的tomcat83看到访问成功，因为此时容器的IP借用主机的，所以容器共享宿主机网络IP，这样的好处是外部主机与容器可以直接通信。 node 禁用网络功能，只有lo标识(就是127.0.0.1表示本地回环) docker run -d -p 8084:8080 --network none --name tomcat84 billygoo/tomcat8-jdk8 container 新建的容器和已经存在的一个容器共享一个网络ip配置而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。 案例 docker run -it --name alpine1 alpine /bin/sh docker run -it --network container:alpine1 --name alpine2 alpine /bin/sh 当alpine退出后再看alpine2的IP只剩下lo 自定义网络 自定义桥接网络,自定义网络默认使用的是桥接网络bridge 案例 创建网络 docker create wjh_network docker network ls 新建容器加入上一步新建的自定义网络 docker run -d -p 8081:8080 --network wjh_network --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --network wjh_network --name tomcat82 billygoo/tomcat8-jdk8 自定义网络本身就维护好了主机名和ip的对应关系（ip和域名都能通） 整体说明 从其架构和运行流程来看，Docker 是一个 C/S 模式的架构，后端是一个松耦合架构，众多模块各司其职。 Docker 运行的基本流程为： 1 用户是使用 Docker Client 与 Docker Daemon 建立通信，并发送请求给后者。 2 Docker Daemon 作为 Docker 架构中的主体部分，首先提供 Docker Server 的功能使其可以接受 Docker Client 的请求。 3 Docker Engine 执行 Docker 内部的一系列工作，每一项工作都是以一个 Job 的形式的存在。 4 Job 的运行过程中，当需要容器镜像时，则从 Docker Registry 中下载镜像，并通过镜像管理驱动 Graph driver将下载镜像以Graph的形式存储。 5 当需要为 Docker 创建网络环境时，通过网络管理驱动 Network driver 创建并配置 Docker 容器网络环境。 6 当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 Execdriver 来完成。 7 Libcontainer是一项独立的容器管理包，Network driver以及Exec driver都是通过Libcontainer来实现具体对容器进行的操作。 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-07 17:41:57 "},"cloud_learn/docker/docker_compose.html":{"url":"cloud_learn/docker/docker_compose.html","title":"容器编排","keywords":"","body":"容器编排 是什么 Compose 是 Docker 公司推出的一个工具软件，可以管理多个 Docker 容器组成一个应用。你需要定义一个 YAML 格式的配置文件docker-compose.yml，写好多个容器之间的调用关系。然后，只要一个命令，就能同时启动/关闭这些容器 能干嘛 docker建议我们每一个容器中只运行一个服务,因为docker容器本身占用资源极少,所以最好是将每个服务单独的分割开来但是这样我们又面临了一个问题？ 如果我需要同时部署好多个服务,难道要每个服务单独写Dockerfile然后在构建镜像,构建容器,这样累都累死了,所以docker官方给我们提供了docker-compose多服务部署的工具 例如要实现一个Web微服务项目，除了Web服务容器本身，往往还需要再加上后端的数据库mysql服务容器，redis服务器，注册中心eureka，甚至还包括负载均衡容器等等。。。。。。 Compose允许用户通过一个单独的docker-compose.yml模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 可以很容易地用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成构建。Docker-Compose 解决了容器与容器之间如何管理编排的问题。 安装 # 官网安装方式https://docs.docker.com/compose/install/ curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose docker-compose --version 卸载 SU rm /usr/local/bin/docker-compose Compose核心概念 文件格式：docker-compose.yml 两个要素： 服务（service）:一个个应用容器实例，比如订单微服务、库存微服务、mysql容器、nginx容器或者redis容器 工程（project):由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose使用的三个步骤 1、编写Dockerfile定义各个微服务应用并构建出对应的镜像文件 2、使用 docker-compose.yml 定义一个完整业务单元，安排好整体应用中的各个容器服务。 3、最后，执行docker-compose up命令 来启动并运行整个应用程序，完成一键部署上线 Compose常用命令 docker-compose -h # 查看帮助 docker-compose up # 启动所有docker-compose服务 docker-compose up -d # 启动所有docker-compose服务并后台运行 docker-compose down # 停止并删除容器、网络、卷、镜像。 docker-compose exec yml里面的服务id # 进入容器实例内部 docker-compose exec docker-compose.yml文件中写的服务id /bin/bash docker-compose ps # 展示当前docker-compose编排过的运行的所有容器 docker-compose top # 展示当前docker-compose编排过的容器进程 docker-compose logs yml里面的服务id # 查看容器输出日志 docker-compose config # 检查配置 docker-compose config -q # 检查配置，有问题才有输出 docker-compose restart # 重启服务 docker-compose start # 启动服务 docker-compose stop # 停止服务 案例1 version: \"3\" services: microService: image: zzyy_docker:1.6 container_name: ms01 ports: - \"6001:6001\" volumes: - /app/microService:/data networks: - atguigu_net depends_on: - redis - mysql redis: image: redis:6.0.8 ports: - \"6379:6379\" volumes: - /app/redis/redis.conf:/etc/redis/redis.conf - /app/redis/data:/data networks: - atguigu_net command: redis-server /etc/redis/redis.conf mysql: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: '123456' MYSQL_ALLOW_EMPTY_PASSWORD: 'no' MYSQL_DATABASE: 'db2021' MYSQL_USER: 'zzyy' MYSQL_PASSWORD: 'zzyy123' ports: - \"3306:3306\" volumes: - /app/mysql/db:/var/lib/mysql - /app/mysql/conf/my.cnf:/etc/my.cnf - /app/mysql/init:/docker-entrypoint-initdb.d networks: - atguigu_net command: --default-authentication-plugin=mysql_native_password #解决外部无法访问 networks: atguigu_net: Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-07 20:13:41 "},"cloud_learn/docker/docker_cig.html":{"url":"cloud_learn/docker/docker_cig.html","title":"Docker容器监控之CAdvisor+InfluxDB+Granfana","keywords":"","body":"Docker容器监控之CAdvisor+InfluxDB+Granfana 是什么 CAdvisor监控收集+InfluxDB存储数据+Granfana展示图表 安装 新建目录，创建文件 [root@wjh ~]# mkdir /mydocker/cig -p [root@wjh ~]# cd /mydocker/cig/ [root@wjh cig]# touch docker-compose.yml [root@wjh cig]# vim docker-compose.yml version: '3.1' volumes: grafana_data: {} services: influxdb: image: tutum/influxdb:0.9 restart: always environment: - PRE_CREATE_DB=cadvisor ports: - \"8083:8083\" - \"8086:8086\" volumes: - ./data/influxdb:/data cadvisor: image: google/cadvisor links: - influxdb:influxsrv command: -storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=influxsrv:8086 restart: always ports: - \"8080:8080\" volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro grafana: user: \"104\" image: grafana/grafana user: \"104\" restart: always links: - influxdb:influxsrv ports: - \"3000:3000\" volumes: - grafana_data:/var/lib/grafana environment: - HTTP_USER=admin - HTTP_PASS=admin - INFLUXDB_HOST=influxsrv - INFLUXDB_PORT=8086 - INFLUXDB_NAME=cadvisor - INFLUXDB_USER=root - INFLUXDB_PASS=root 启动docker-compose文件 docker-compose up 浏览cAdvisor收集服务，http://ip:8080/ 浏览influxdb存储服务，http://ip:8083/ 浏览grafana展现服务，http://ip:3000 ip+3000端口的方式访问,默认帐户密码（admin/admin） 配置步骤 1、配置数据源 2、选择influxdb数据源 3、配置面板panel 选择图表 配置数据 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-08 11:43:22 "},"cloud_learn/docker/go_install.html":{"url":"cloud_learn/docker/go_install.html","title":"go环境安装","keywords":"","body":"go环境安装 https://golang.google.cn/dl/ go env查看环境 创建GOPATH目录 l src：存放源代码 l pkg：存放依赖包 l bin：存放可执行文件 mdkdir -p $GOPATH/{bin，src，pkg} 修改环境变量 1、创建用户变量gopath 配置国内代理 l GOOS，GOARCH，GOPROXY l 国内用户建议设置 goproxy：export GOPROXY=https://goproxy.cn https://goproxy.io,direct 一些基本命令 build 将文件编译成可执行文件 -- goos=linux go build xx.go 指定环境为linux编译程序 fmt 格式化代码 -- go fmt xxx.go get 下载依赖 isntall 编译并安装包和依赖 test 运行 测试 tool 运行共提供的工具 mod 维护模块 ​ Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-01 17:39:40 "},"cloud_learn/k8s/k8s_install.html":{"url":"cloud_learn/k8s/k8s_install.html","title":"安装K8S","keywords":"","body":"安装K8S 安装docker环境 /bin/bash #移除以前docker相关包 sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine # 配置yum源 yum install -y yum-utils yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #安装dockcer yum install -y docker-ce-20.10.7 docker-ce-cli-20.10.7 containerd.io-1.4.6 #启动 systemctl enable docker --now #配置加速器 mkdir -p /etc/docker tee /etc/docker/daemon.json 安装kubeadm 一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令 每台机器 2 GB 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存) 2 CPU 核或更多 集群中的所有机器的网络彼此均能相互连接(公网和内网都可以) 设置防火墙放行规则 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见这里了解更多详细信息。 设置不同hostname 开启机器上的某些端口。请参见这里 了解更多详细信息。 内网互信 禁用交换分区。为了保证 kubelet 正常工作，你 必须 禁用交换分区。 永久关闭 1、基础环境 #各个机器设置自己的域名 hostnamectl set-hostname xxxx hostnamectl set-hostname k8s-master hostnamectl set-hostname k8s-node1 hostnamectl set-hostname k8s-node2 # 将 SELinux 设置为 permissive 模式（相当于将其禁用） sudo setenforce 0 sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config #关闭swap swapoff -a sed -ri 's/.*swap.*/#&/' /etc/fstab #允许 iptables 检查桥接流量 cat 2、安装kubelet、kubeadm、kubectl cat 所有节点都需要执行 kubelet 现在每隔几秒就会重启，因为它陷入了一个等待 kubeadm 指令的死循环 使用kubeadm引导集群 1、下载各个机器需要的镜像 sudo tee ./images.sh 2、初始化主节点 #所有机器添加master域名映射，以下需要修改为自己的 echo \"172.31.0.100 cluster-endpoint\" >> /etc/hosts #主节点初始化 kubeadm init \\ --apiserver-advertise-address=172.31.0.100 \\ --control-plane-endpoint=cluster-endpoint \\ --image-repository registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images \\ --kubernetes-version v1.20.9 \\ --service-cidr=10.96.0.0/16 \\ --pod-network-cidr=192.168.0.0/16 #所有网络范围不重叠 ##初始化完成后的信息，用于添加节点 Your Kubernetes control-plane has initialized successfully! ##主节点执行如下信息 To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of control-plane nodes by copying certificate authorities and service account keys on each node and then running the following as root: kubeadm join cluster-endpoint:6443 --token srtl5c.618lmpbu0gpxruhx \\ --discovery-token-ca-cert-hash sha256:9fc2ce76173023817677c5788b11bebfd3e12680f00c6632b84a6e9ac6f8e5c2 \\ --control-plane Then you can join any number of worker nodes by running the following on each as root: kubeadm join cluster-endpoint:6443 --token srtl5c.618lmpbu0gpxruhx \\ --discovery-token-ca-cert-hash sha256:9fc2ce76173023817677c5788b11bebfd3e12680f00c6632b84a6e9ac6f8e5c2 设置.kube/config 配置命令在初始化信息中 3、 安装网络组件 curl https://docs.projectcalico.org/manifests/calico.yaml -O kubectl apply -f calico.yaml --pod-network-cid值如果修改了，需要修改 calico.yaml value: \"192.168.0.0/16\" 4、加入node节点 kubeadm join cluster-endpoint:6443 --token srtl5c.618lmpbu0gpxruhx \\ --discovery-token-ca-cert-hash sha256:9fc2ce76173023817677c5788b11bebfd3e12680f00c6632b84a6e9ac6f8e5c2 TOKEN24小时内有效，过期可以使用以下命令重新生成新令牌 kubeadm token create --print-join-command 问题处理 1、如果出现镜像拉取失败imagespullbakcoff的情况可以执行以下命令，查看失败原因，在失败的节点上拉取镜像 kubectl describe poDS -n kube-system calico-node-s26rt 5、验证集群 验证集群节点状态 kubectl get nodes 6、部署dashboard 1、部署 kubernetes官方提供的可视化界面 https://github.com/kubernetes/dashboard kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml 2、设置访问端口 kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard type: ClusterIP 改为 type: NodePort kubectl get svc -A |grep kubernetes-dashboard ## 找到端口，在安全组放行 访问： https://集群任意IP:端口 https://10.0.0.100:30368 3、创建访问账号 #创建访问账号，准备一个yaml文件； vi dash.yaml apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard kubectl apply -f dash.yaml 4、令牌访问 #获取访问令牌 kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=\"{.secrets[0].name}\") -o go-template=\"{{.data.token | base64decode}}\" eyJhbGciOiJSUzI1NiIsImtpZCI6IklLLUtVV2VvMGE2a1hBT3NMU1JXY3FxTm9MRzNDQUZTQXBkQkVGc2ZRNXcifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWc5Z3A4Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIyOGRmNDQ2Ni03YTM1LTRiM2UtYWFkZC0xZWM3NmE2MDBkZWIiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.BQcX86qMhgRtI6rK8LK5uhb_IJw-oZpiLkeSEjHngPyMIKhcQ8RfhQ0DuZ0ApoJt_59Qrpc6v2GzUZ8P-pDe3BcA0JV8g3QarYnQ458-LZhzIlCsaVvXFZMLGSA0l08FySXnckIEzdEZzuvsa7Q9aoMhe4eb_DpDmZj-jwEo7gBEVLKjuqdvLhak7BAcrsymVKXOioxZMKVJdglEXNDjBcBfnkbRM4pNKnP6Zp6m_qF2ILMlfB48IJFFDSN2EjAKvxro9mAwDJ98Al48w62phL_V6M-O_0KhCEhN4a2lJtuYuWmdQSQ5zUsDSs0NtCJaH6rb0u6Vf0wmUp_NvuonVA Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-13 16:56:55 "},"es/install.html":{"url":"es/install.html","title":"安装","keywords":"","body":"Elasticsearch安装部署-rpm安装 ### 安装java [root@db01 ~]# yum install -y java-1.8.0-openjdk.x86_64 [root@db01 ~]# mkdir -p /data/es_soft/ [root@db01 ~]# cd /data/es_soft/ [root@db01 /data/es_soft]# rpm -ivh elasticsearch-6.6.0.rpm [root@db01 /data/es_soft]# systemctl daemon-reload [root@db01 /data/es_soft]# systemctl enable elasticsearch.service Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service. [root@db01 /data/es_soft]# systemctl start elasticsearch.service [root@db01 /data/es_soft]# systemctl status elasticsearch.service ● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2021-04-22 21:38:35 CST; 10s ago Docs: http://www.elastic.co Main PID: 6738 (java) CGroup: /system.slice/elasticsearch.service └─6738 /bin/java -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC... Apr 22 21:38:35 db01 systemd[1]: Started Elasticsearch. Apr 22 21:38:35 db01 systemd[1]: Starting Elasticsearch... Apr 22 21:38:36 db01 elasticsearch[6738]: OpenJDK 64-Bit Server V... Hint: Some lines were ellipsized, use -l to show in full. #文件目录说明 rpm -qc elasticsearch #查看elasticsearch的所有配置文件 /etc/elasticsearch/elasticsearch.yml #配置文件 /etc/elasticsearch/jvm.options. #jvm虚拟机配置文件 /etc/init.d/elasticsearch #init启动文件 /etc/sysconfig/elasticsearch #环境变量配置文件 /usr/lib/sysctl.d/elasticsearch.conf #sysctl变量文件，修改最大描述符 /usr/lib/systemd/system/elasticsearch.service #systemd启动文件 /var/lib/elasticsearch # 数据目录 /var/log/elasticsearch #日志目录 /var/run/elasticsearch #pid目录 #修改配置 [root@db01 /data/es_soft]# vim /etc/elasticsearch/elasticsearch.yml network.host: 10.0.0.51 # # Set a custom port for HTTP: # http.port: 9200 修改完配置文件后我们需要重启一下 [root@db01 /data/es_soft]# grep \"^[a-Z]\" /etc/elasticsearch/elasticsearch.yml node.name: node-1 path.data: /data/elasticsearch path.logs: /var/log/elasticsearch network.host: 10.0.0.51 http.port: 9200 bootstrap.memory_lock: true #JVM 配置 # 不要超过32g # 最大最小内存设置为一样 #配置文件设置锁定内存 #至少给服务器本身空余50%的内存 [root@db01 /etc/elasticsearch]# vim jvm.options -Xms512m -Xmx512m # 创建目录 [root@db01 /data/es_soft]# mkdir -p /data/elasticsearch [root@db01 /data/es_soft]# chown -R elasticsearch:elasticsearch /data/elasticsearch/ [root@db01 /data/es_soft]# systemctl restart elasticsearch [root@db01 /data/es_soft]# systemctl status elasticsearch 这个时候可能会启动失败，查看日志可能会发现是锁定内存失败 官方解决方案 https://www.elastic.co/guide/en/elasticsearch/reference/6.6/setup-configuration-memory.html https://www.elastic.co/guide/en/elasticsearch/reference/6.6/setting-system-settings.html#sysconfig ### 修改启动配置文件或创建新配置文件 方法1: systemctl edit elasticsearch 方法2: vim /usr/lib/systemd/system/elasticsearch.service ### 增加如下参数 [Service] LimitMEMLOCK=infinity ### 重新启动 systemctl daemon-reload systemctl restart elasticsearch 可能遇到的错误 initial heap size [16777216] not equal to maximum heap size [536870912]; this can cause resize pauses and prevents mlockall from locking the entire heap 说明此时处于生产模式 修改elasticsearch.yml discvery.type： single-node Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-23 21:19:28 "},"es/head插件交互.html":{"url":"es/head插件交互.html","title":"交互","keywords":"","body":"交互 Head插件在5.0以后安装方式发生了改变，需要nodejs环境支持，或者直接使用别人封装好的docker镜像 插件官方地址 https://github.com/mobz/elasticsearch-head 使用docker部署elasticsearch-head docker pull alivv/elasticsearch-head docker run --name es-head -p 9100:9100 -dit elivv/elasticsearch-head 使用nodejs编译安装elasticsearch-head yum install nodejs npm openssl screen -y node -v npm -v npm install -g cnpm --registry=https://registry.npm.taobao.org cd /opt/ git clone git://github.com/mobz/elasticsearch-head.git cd elasticsearch-head/ cnpm install screen -S es-head cnpm run start Ctrl+A+D 修改ES配置文件支持跨域 http.cors.enabled: true http.cors.allow-origin: \"*\" Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 23:36:25 "},"es/dml.html":{"url":"es/dml.html","title":"操作语言","keywords":"","body":"增删改查 #创建索引 [root@db01 /etc/elasticsearch]#curl -XPUT '10.0.0.51:9200/vipinfo?pretty' { \"acknowledged\" : true, \"shards_acknowledged\" : true, \"index\" : \"vipinfo\" } #插入文档数据 curl -XPUT '10.0.0.51:9200/vipinfo/user/1?pretty' -H 'Content-Type: application/json' -d' { \"first_name\" : \"John\", \"last_name\": \"Smith\", \"age\" : 25, \"about\" : \"I love to go rock climbing\", \"interests\": [ \"sports\", \"music\" ] }' curl -XPUT 'localhost:9200/vipinfo/user/2?pretty' -H 'Content-Type: application/json' -d' { \"first_name\": \"Jane\", \"last_name\" : \"Smith\", \"age\" : 32, \"about\" : \"I like to collect rock albums\", \"interests\": [ \"music\" ] }' curl -XPUT 'localhost:9200/vipinfo/user/3?pretty' -H 'Content-Type: application/json' -d' { \"first_name\": \"Douglas\", \"last_name\" : \"Fir\", \"age\" : 35, \"about\": \"I like to build cabinets\", \"interests\": [ \"forestry\" ] }' #说明：创建数据时，使用默认的随机id,如果需要与mysql建立联系可以新增一个sid列，填入mysql中数据列的id Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-23 21:19:28 "},"es/集群.html":{"url":"es/集群.html","title":"集群配置","keywords":"","body":"集群部署安装配置 部署三台服务器节点，10.0.0.51,10.0.0.52，10.0.0.53 #1、装java环境 [root@db02 /data/soft]# yum -y install java-1.8.0-openjdk.x86_64 #2、下载es软件 [root@db02 /data/soft]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.0.rpm [root@db02 /data/soft]# rpm -ivh elasticsearch-6.6.0.rpm #3、修改配置文件 [root@db02 /data/soft]#cat > /etc/elasticsearch/elasticsearch.yml 其他集群配置 重复以上内容 2个节点,master设置为2的时候,一台出现故障导致集群不可用 解决方案: 把还存活的节点的配置文件集群选举相关的选项注释掉或者改成1 discovery.zen.minimum_master_nodes: 1 重启服务 结论: 两个节点数据不一致会导致查询结果不一致 找出不一致的数据,清空一个节点,以另一个节点的数据为准 然后手动插入修改后的数据 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-26 20:31:46 "},"elk/安装.html":{"url":"elk/安装.html","title":"安装","keywords":"","body":"安装 es安装配置 参考es笔记es安装配置 配置参考如下： 安装kibana [root@db01 /data/soft]#rpm -ich kibana-6.6.0-x86_64.rpm warning: kibana-6.6.0-x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY ################################# [100%] Updating / installing... ################################# [100%] # 修改配置文件 修改kibana配置 # 修改配置文件 [root@db01 /data/soft]#vim /etc/kibana/kibana.yml [root@db01 /data/soft]#grep \"^[a-z]\" /etc/kibana/kibana.yml server.port: 5601 server.host: \"10.0.0.51\" elasticsearch.hosts: [\"http://localhost:9200\"] kibana.index: \".kibana\" 启动服务 [root@db01 /data/soft]#systemctl start kibana # 查看状态 [root@db01 /data/soft]#systemctl status kibana ● kibana.service - Kibana Loaded: loaded (/etc/systemd/system/kibana.service; disabled; vendor preset: disabled) Active: active (running) since Mon 2021-04-26 13:44:44 CST; 10s ago Main PID: 2105 (node) CGroup: /system.slice/kibana.service └─2105 /usr/share/kibana/bin/../node/bin/node --no-warnings /usr/share/kib... Apr 26 13:44:44 db01 systemd[1]: [/etc/systemd/system/kibana.service:3] Unknown lv...it' Apr 26 13:44:44 db01 systemd[1]: [/etc/systemd/system/kibana.service:4] Unknown lv...it' Apr 26 13:44:44 db01 systemd[1]: Started Kibana. Apr 26 13:44:44 db01 systemd[1]: Starting Kibana... Hint: Some lines were ellipsized, use -l to show in full. # 查看端口 [root@db01 /data/soft]#netstat -lntup|grep 5601 tcp 0 0 10.0.0.51:5601 0.0.0.0:* LISTEN 2105/node 查看图形界面效果 浏览器输入ip:6501 注意事项： Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-26 21:13:36 "},"elk/nginx_log_json.html":{"url":"elk/nginx_log_json.html","title":"nginxjson日志采集","keywords":"","body":"nginxjson日志采集 ## 安装nginx [root@db01 /data/soft]#yum -y install nginx Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com # 启动服务 [root@db01 /data/soft]#systemctl restart nginx # 安装压测工具 [root@db01 /data/soft]#yum -y install httpd-tools 配置nginx 日志格式 #在nging.conf文件 http中添加以下内容 http { log_format json '{ \"time_local\": \"$time_local\", ' '\"remote_addr\": \"$remote_addr\", ' '\"referer\": \"$http_referer\", ' '\"request\": \"$request\", ' '\"status\": $status, ' '\"bytes\": $body_bytes_sent, ' '\"agent\": \"$http_user_agent\", ' '\"x_forwarded\": \"$http_x_forwarded_for\", ' '\"up_addr\": \"$upstream_addr\",' '\"up_host\": \"$upstream_http_host\",' '\"upstream_time\": \"$upstream_response_time\",' '\"request_time\": \"$request_time\"' '}'; } # 验证ngingx配置 [root@db01 /data/soft]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful # 重启ngingx 服务 [root@db01 /data/soft]#systemctl restart nginx # 清空数据日志 [root@db01 /data/soft]#> /var/log/nginx/access.log ## 创建测试数据 [root@db01 /data/soft]#ab -n 100 -c 100 http://10.0.0.51/ [root@db01 /data/soft]#tail -f /var/log/nginx/access.log 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" # 验证查看日志数据格式 [root@db01 /data/soft]#tail -1 /var/log/nginx/access.log { \"time_local\": \"26/Apr/2021:14:30:52 +0800\", \"remote_addr\": \"10.0.0.51\", \"referer\": \"-\", \"request\": \"GET / HTTP/1.0\", \"status\": 200, \"bytes\": 4833, \"agent\": \"ApacheBench/2.3\", \"x_forwarded\": \"-\", \"up_addr\": \"-\",\"up_host\": \"-\",\"upstream_time\": \"-\",\"request_time\": \"0.000\"} 安装filebeat [root@db01 /data/soft]# rpm -ivh filebeat-6.6.0-x86_64.rpm warning: filebeat-6.6.0-x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY Preparing... ################################# [100%] Updating / installing... 1:filebeat-6.6.0-1 ################################# [100%] ## 修改配置文件 [root@db01 /data/soft]#cp /etc/filebeat/filebeat.yml /tmp/ [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml 添加kibana监控项目 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-26 22:10:02 "},"elk/nginx_success_error_log.html":{"url":"elk/nginx_success_error_log.html","title":"nginix正常日志和错误日志","keywords":"","body":"ELk 收集Nginx的正常日志和错误日志 收集多台nginx服务日志信息 #n台服务的配置文件的日志格式为一样 http { log_format json '{ \"time_local\": \"$time_local\", ' '\"remote_addr\": \"$remote_addr\", ' '\"referer\": \"$http_referer\", ' '\"request\": \"$request\", ' '\"status\": $status, ' '\"bytes\": $body_bytes_sent, ' '\"agent\": \"$http_user_agent\", ' '\"x_forwarded\": \"$http_x_forwarded_for\", ' '\"up_addr\": \"$upstream_addr\",' '\"up_host\": \"$upstream_http_host\",' '\"upstream_time\": \"$upstream_response_time\",' '\"request_time\": \"$request_time\"' '}'; } 正常日志，错误日志拆分 #修改配置信息 [root@db01 ~]# cat >/etc/filebeat/filebeat.yml 说明 特别说明:如果之前已产生日志数据，需将旧日志信息移除或移动到其他目录 删除添加的好的management Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 19:08:45 "},"elk/tomcat_log_cat.html":{"url":"elk/tomcat_log_cat.html","title":"tomcat日志收集","keywords":"","body":"tomcat日志收集 安装tomcat [root@db01 ~]# yum install tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp tomcat-javadoc -y 启动服务 [root@db01 ~]# systemctl start tomcat 验证服务 配置tomacat日志格式为json [root@db01 ~]# vim /etc/tomcat/server.xml [root@db01 ~]# cat -n /etc/tomcat/server.xml ---------------- 137 ---------------- 重启确认日志是否为json格式 [root@db01 ~]# systemctl restart tomcat [root@db01 ~]# tail -f /var/log/tomcat/localhost_access_log.2021-04-26.txt {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET / HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"11217\",\"Query?string\":\"\",\"partner\":\"-\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET /favicon.ico HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"21630\",\"Query?string\":\"\",\"partner\":\"http://10.0.0.51:8080/\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET / HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"11217\",\"Query?string\":\"\",\"partner\":\"-\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} 修改filebeat配置文件 [root@db01 ~]# cat > /etc/filebeat/filebeat.yml 重启服务&c查看状态 [root@db01 ~]# systemctl restart filebeat.service [root@db01 ~]# tail -f /var/log/filebeat/filebeat 2021-04-26T23:51:54.518+0800 INFO [monitoring] log/log.go:144 Non-zero metrics in the last 30s {\"monitoring\": {\"metrics\": {\"beat\":{\"cpu\":{\"system\":{\"ticks\":70,\"time\":{\"ms\":2}},\"total\":{\"ticks\":150,\"time\":{\"ms\":13},\"value\":150},\"user\":{\"ticks\":80,\"time\":{\"ms\":11}}},\"handles\":{\"limit\":{\"hard\":4096,\"soft\":1024},\"open\":8},\"info\":{\"ephemeral_id\":\"18f558bb-c001-4fdf-9e1c-1e9ef28bfbd7\",\"uptime\":{\"ms\":240047}},\"memstats\":{\"gc_next\":4194304,\"memory_alloc\":1903176,\"memory_total\":7411504}},\"filebeat\":{\"harvester\":{\"open_files\":1,\"running\":1}},\"libbeat\":{\"config\":{\"module\":{\"running\":0}},\"pipeline\":{\"clients\":4,\"events\":{\"active\":0}}},\"registrar\":{\"states\":{\"current\":3}},\"system\":{\"load\":{\"1\":0.05,\"15\":0.22,\"5\":0.2,\"norm\":{\"1\":0.05,\"15\":0.22,\"5\":0.2}}}}}} 添加mangement Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-27 00:04:20 "},"elk/java_log.html":{"url":"elk/java_log.html","title":"java多行日志收集","keywords":"","body":"java多行日志收集 # 编辑修改配置文件 [root@db01 ~]# vim /etc/filebeat/filebeat.yml - /var/log/elasticsearch/elasticsearch.log tags: [\"es\"] multiline.pattern: '^\\[' multiline.negate: true multiline.match: after #####################output_messages############## setup.kibana: host: \"10.0.0.51:5601\" #自定义配置输出格式 output.elasticsearch: hosts: [\"10.0.0.51:9200\"] # 判断条件可以为其他属性 indices: - index: \"nginx-access-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"access\" - index: \"nginx-error-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"error\" - index: \"tomact-access-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"tomact\" - index: \"es-java-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"es\" #重新命名模板名称为ngingx setup.template.name: \"nginx\" #匹配格式，以nginx-开头的模板都使用nginx的模板 setup.template.pattern: \"nginx-*\" #不使用系统自自带的模板 setup.template.enabled: false Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-28 00:09:31 "},"elk/docker_log.html":{"url":"elk/docker_log.html","title":"收集docker日志","keywords":"","body":"收集docker日志 docker安装:docker安装过程 #配置docker cat >docker-compose.yml/etc/filebeat/filebeat.yml Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-29 21:26:37 "},"elk/filebeat_modules_get_ngingx_simple_log.html":{"url":"elk/filebeat_modules_get_ngingx_simple_log.html","title":"fibet收集ngingx日志","keywords":"","body":"filebeat模块收集ngingx普通日志 第一步 #查看filebeat文件 [root@db01 /data/soft]# rpm -qc filebeat /etc/filebeat/filebeat.yml /etc/filebeat/modules.d/apache2.yml.disabled /etc/filebeat/modules.d/auditd.yml.disabled /etc/filebeat/modules.d/elasticsearch.yml.disabled /etc/filebeat/modules.d/haproxy.yml.disabled /etc/filebeat/modules.d/icinga.yml.disabled /etc/filebeat/modules.d/iis.yml.disabled /etc/filebeat/modules.d/kafka.yml.disabled /etc/filebeat/modules.d/kibana.yml.disabled /etc/filebeat/modules.d/logstash.yml.disabled /etc/filebeat/modules.d/mongodb.yml.disabled /etc/filebeat/modules.d/mysql.yml.disabled /etc/filebeat/modules.d/nginx.yml.disabled /etc/filebeat/modules.d/osquery.yml.disabled /etc/filebeat/modules.d/postgresql.yml.disabled /etc/filebeat/modules.d/redis.yml.disabled /etc/filebeat/modules.d/suricata.yml.disabled /etc/filebeat/modules.d/system.yml.disabled /etc/filebeat/modules.d/traefik.yml.disabled #查询模板 filebeat modules list #激活模块 filebeat moudles enable nginx #配置nginx.yml文件配置 [root@db01 /data/soft]# vim /etc/filebeat/modules.d/nginx.yml - module: nginx # Access logs access: enabled: true # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. var.paths: [\"/var/log/nginx/access.log\"] # Error logs error: enabled: true # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: var.paths: [\"/var/log/nginx/error.log\"] #配置filebeat modules #============================= Filebeat modules =============================== # filebeat.config.modules: # # Glob pattern for configuration loading path: ${path.config}/modules.d/*.yml reload.enabled: false reload.period: 10s output.elasticsearch: hosts: [\"10.0.0.51:9200\"] ~ ~ 第二步 #重启服务 [root@db01 /data/soft]# systemctl restart filebeat.service #查看日志报错 2021-04-29T21:49:12.254+0800 ERROR fileset/factory.go:142 Error loading pipeline: Error loading pipeline for fileset nginx/access: This module requires the following Elasticsearch plugins: ingest-user-agent, ingest-geoip. You can install them by running the following commands on all the Elasticsearch nodes: sudo bin/elasticsearch-plugin install ingest-user-agent sudo bin/elasticsearch-plugin install ingest-geoip #安装插件 [root@db01 /data/soft]# /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-user-agent -> Downloading ingest-user-agent from elastic [=================================================] 100% -> Installed ingest-user-agent [root@db01 /data/soft]# /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-geoip -> Downloading ingest-geoip from elastic [=================================================] 100% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: plugin requires additional permissions @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ * java.lang.RuntimePermission accessDeclaredMembers * java.lang.reflect.ReflectPermission suppressAccessChecks See http://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html for descriptions of what these permissions allow and the associated risks. Continue with installation? [y/N]y -> Installed ingest-geoip #查看elasticsearch-plugin命令目录 [root@db01 /data/soft]# rpm -ql elasticsearch |grep elasticsearch-plugin /usr/share/elasticsearch/bin/elasticsearch-plugin /usr/share/elasticsearch/lib/tools/plugin-cli/elasticsearch-plugin-cli-6.6.0.jar 第三步 ## 配置etc/filebeat/filebeat.yml [root@db01 /var/log/nginx]# cat >/etc/filebeat/filebeat.yml Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 18:12:06 "},"elk/kibana_draw_dashboard.html":{"url":"elk/kibana_draw_dashboard.html","title":"kibana画图","keywords":"","body":"kibana画图 第一步 第二步 第三步 第四步 第五步 第六步 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 19:08:45 "},"elk/redis_cat_log.html":{"url":"elk/redis_cat_log.html","title":"redis作为缓存收集日志","keywords":"","body":"redis作为缓存收集日志 方式一 安装logstash [root@db01 /data/soft]#rpm -ivh logstash-6.6.0.rpm warning: logstash-6.6.0.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY Preparing... ################################# [100%] Updating / installing... 1:logstash-1:6.6.0-1 ################################# [100%] Using provided startup.options file: /etc/logstash/startup.options OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Successfully created system startup script for Logstash 配置filebeat写入到不同的key中 [root@db01 /data/soft]#cat >/etc/filebeat/filebeat.yml 6.1.6 logstash根据tag区分一个key里的不同日志 [root@db01 /data/soft]#cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_access\" data_type => \"list\" } redis { host => \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_error\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF #启动服务 [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf 方式二 filebeat收集日志写入到一个key中 [root@db01 /data/soft]# cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"filebeat\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml logstash根据tag区分一个key里的不同日志 [root@db01 /data/soft]#cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_access\" data_type => \"list\" } redis { host => \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_error\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 [root@db01 /data/soft]#systemctl restart filebeat.service [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 21:53:21 "},"elk/kafka缓存收集日志.html":{"url":"elk/kafka缓存收集日志.html","title":"kafka缓存收集日志","keywords":"","body":"kafka和zookeeper安装 zookeeper安装 准备工作 # 解压文件 [root@db01 /data/soft]# tar zxf zookeeper-3.4.11.tar.gz -C /opt/ # 创建软连接 [root@db01 /data/soft]# ln -s /opt/zookeeper-3.4.11/ /opt/zookeeper # 安装java 环境 [root@db01 ~]# yum install -y java-1.8.0-openjdk.x86_64 安装配置zookeeper [root@db01 /data/soft]# mkdir -p /data/zookeeper [root@db01 /data/soft]# cp /opt/zookeeper/conf/zoo_sample.cfg /opt/zookeeper/conf/zoo.cfg [root@db01 /data/soft]# vim /opt/zookeeper/conf/zoo.cfg [root@db01 /data/soft]# cat >/opt/zookeeper/conf/zoo.cfg 其他节点配置步骤和节点1一样,只是最后myid不一样而已 [root@db01 /opt]# rsync -avz zookeeper* db02:/opt/ [root@db02 /opt]# cat /data/zookeeper/mid 2 [root@db01 /opt]# rsync -avz zookeeper* db03:/opt/ [root@db03 /opt]# cat /data/zookeeper/mid 3 启动服务&查看状态 #启动 [root@db01 /opt]# /opt/zookeeper/bin/zkServer.sh start #查看状态 [root@db01 /opt]# /opt/zookeeper/bin/zkServer.sh status kafka安装 准备工作 [root@db01 /opt]# tar -xvzf /data/soft/kafka_2.11-1.0.0.tgz -C /opt [root@db01 /opt]# ln -s /opt/kafka_2.11-1.0.0/ /opt/kafka 安装配置 [root@db01 /opt/kafka]# vim /opt/kafka/config/server.properties 21 broker.id=1 31 listeners=PLAINTEXT://10.0.0.51:9092 60 log.dirs=/opt/kafka/logs 103 log.retention.hours=24 123 zookeeper.connect=10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 其他节点配置步骤和节点1一样,只是最listeners不一样而已 [root@db01 /opt]# rsync -avz zookeeper* db02:/opt/ [root@db02 /opt]# sed -i 's#broker.id=1#broker.id=2#g' /opt/kafka/config/server.properties [root@db02 /opt]# sed -i 's#10.0.0.51:9092#10.0.0.52:9092#g' /opt/kafka/config/server.properties [root@db01 /opt]# rsync -avz zookeeper* db03:/opt/ [root@db03 /opt]# sed -i 's#broker.id=1#broker.id=3#g' /opt/kafka/config/server.properties [root@db03 /opt]# sed -i 's#10.0.0.51:9092#10.0.0.53:9092#g' /opt/kafka/config/server.properties 节点1,可以先前台启动,方便查看错误日志 [root@db01 /opt]# /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties [2021-05-06 17:06:33,642] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral) [2021-05-06 17:06:33,644] INFO Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(10.0.0.52,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils) [2021-05-06 17:06:33,655] INFO Kafka version : 1.0.0 (org.apache.kafka.common.utils.AppInfoParser) [2021-05-06 17:06:33,655] INFO Kafka commitId : aaa7af6d4a11b29d (org.apache.kafka.common.utils.AppInfoParser) [2021-05-06 17:06:33,658] INFO [KafkaServer id=2] started (kafka.server.KafkaServer) # 后台启动 [root@db01 /opt]## /opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties [root@db01 /opt]# tail -f /opt/kafka/logs/server.log ========================= [2021-05-06 17:06:33,658] INFO [KafkaServer id=1] started (kafka.server.KafkaServer) 验证测试 #创建一个topic [root@db01 /opt]# /opt/kafka/bin/kafka-topics.sh --create --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --partitions 3 --replication-factor 3 --topic kafkatest OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Created topic \"kafkatest\". # 获取topic [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-topics.sh --list --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N kafkatest kafka测试命令发送消息 #创建一个名为messagetest的topic [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-topics.sh --create --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --partitions 3 --replication-factor 3 --topic messagetest OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Created topic \"messagetest\". #发送消息:注意,端口是 kafka的9092,而不是zookeeper的2181 [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-console-producer.sh --broker-list 10.0.0.51:9092,10.0.0.52:9092,10.0.0.53:9092 --topic messagetestOpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N > >biubiu # 其他kafka服务器获取消息 [root@db01 /opt]# /opt/kafka/bin/kafka-console-consumer.sh --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --topic messagetest --from-beginning OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper]. hello biubiu kafka收集日志配置 修改filebeat配置 [root@kafka-175 conf.d]# cat >/etc/filebeat/filebeat.yml 修改 logstash配置 cat >/etc/logstash/conf.d/kafka.conf\"10.0.0.51:9092\" topics=>[\"elklog\"] group_id=>\"logstash\" codec => \"json\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 #启动filebeat [root@db01 ~]# systemctl restart filebeat #启动logstash #启动服务 [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 18:47:44 "},"elk/nginx_keepalived_redis.html":{"url":"elk/nginx_keepalived_redis.html","title":"使用nginx+keepalived代理多台redis","keywords":"","body":"redis集群方案有哨兵和集群，但可惜的是filebeat和logstash都不支持这两种方案。 解决方案如下： 1.使用nginx+keepalived反向代理负载均衡到后面的多台redis 2.考虑到redis故障切换中数据一致性的问题，所以最好我们只使用2台redis,并且只工作一台，另外一台作为backup，只有第一台坏掉后，第二台才会工作。 3.filebeat的oputut的redis地址为keepalived的虚拟I 4.logstash可以启动多个节点来加速读取redis的数据 5.后端可以采用多台es集群来做支撑 redis安装配置：redis安装 keepalived安装配置 #db01 db02上分别安装 [root@db02 /opt/kafka]# yum -y install keepalived #配置主 [root@db01 ~]# cat >/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf nginx反向代理配置 #在 /etc/nginx/nginx.conf 最后添加不能加到conf.d里面添加子配置 stream { upstream redis { server 10.0.0.52:6379 max_fails=2 fail_timeout=10s; server 10.0.0.53:6379 max_fails=2 fail_timeout=10s backup; } server { listen 6379; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass redis; } } filbeat 配置 [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml logstach 配置 cat >/etc/logstash/conf.d/redis.conf \"10.0.0.3\" port => \"6379\" db => \"0\" key => \"filebeat\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 [root@db01 ~]# systemctl restart filebeat [root@db01]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 22:07:50 "},"zabbix/install.html":{"url":"zabbix/install.html","title":"安装","keywords":"","body":"安装----在线安装 第一步 ：下载安装zabbix yum 源文件 [root@zabbix soft]# rpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm 第二步:下载安装zabbix服务端相关软件 #zabbix服务程序软件: zabbix-server-mysql #zabbix服务web软件: zabbix-web-mysql httpd php #数据库服务软件: mariadb-server [root@zabbix soft]# yum install -y zabbix-server-mysql zabbix-web-mysql httpd php mariadb-server 第三步：软件配置 #配置数据库密码 [root@zabbix soft]# vim /etc/zabbix/zabbix_server.conf 126 DBPassword=zabbix #配置时区 [root@zabbix soft]# vim /etc/httpd/conf.d/zabbix.conf 21 php_value date.timezone Asia/Shanghai 第四步：编写配置数据库服务 [root@zabbix soft]# systemctl start mariadb.service # 创建zabbix数据库--zabbix # 创建数据库管理用户 [root@zabbix soft]# mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 2 Server version: 5.5.68-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> create database zabbix character set utf8 collate utf8_bin; Query OK, 1 row affected (0.00 sec) MariaDB [(none)]> grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix'; Query OK, 0 rows affected (0.00 sec) # 在zabbix数据库中导入相应的表信息 [root@zabbix soft]# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix 第五步：启动zabbix程序相关服务 # 数据库服务 zabbix服务 httpd服务 [root@zabbix soft]# systemctl start zabbix-server.service httpd mariadb.service # 配置开启自动启动 [root@zabbix soft]# systemctl enable zabbix-server.service httpd mariadb.service 第六步： 登录zabbix服务端web界面, 进行初始化配置 10051 zabbix-server 服务端端口号 10050 zabbix-agent 客户端端口号 http://10.0.0.101/zabbix/setup.php 默认账户密码：Admin zabbix 一件部署脚本 #/!bin/bash echo \"-----------------下载安装zabbix yum 源文件--------------------\" rpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm rpm -qa|grep zabbix if [ $? -eq 0 ] then echo \"-----------------下载安装zabbix服务端相关软件-----------------\" #zabbix服务程序软件: zabbix-server-mysql #zabbix服务web软件: zabbix-web-mysql httpd php #数据库服务软件: mariadb-server yum install -y zabbix-server-mysql zabbix-web-mysql httpd php mariadb-server rpm -qa | grep zabbix-server-mysql if [ $? -ne 0 ] then echo \" zabbix-server-mysql 安装失败\" exit fi rpm -qa | grep zabbix-web-mysql if [ $? -ne 0 ] then echo \" zabbix-web-mysql 安装失败\" exit fi echo \"-----------------软件配置-------------------------------------\" sed -i.bak 's/# DBPassword=/DBPassword=zabbix/g' /etc/zabbix/zabbix_server.conf sed -i.bak 's#\\# php_value date.timezone Europe/Riga#php_value date.timezone Asia/Shanghai#g' /etc/httpd/conf.d/zabbix.conf echo \"-----------------软件配置-------------------------------------\" systemctl start mariadb.service netstat -lnutp|grep 3306 if [ $? -eq 0 ] then mysql -e \"create database zabbix character set utf8 collate utf8_bin;\" mysql -e \" show databases\"|grep zabbix if [ $? -ne 0 ] then echo \"创建数据库失败\" exit fi mysql -e \"grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';\" mysql -e \" select * from mysql.user\"|grep zabbix if [ $? -ne 0 ] then echo \"创建数据库管理用户失败\" exit fi else echo \"数据库启动失败\" exit fi zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix echo \"-----------------启动zabbix程序相关服务-----------------------\" systemctl start zabbix-server.service httpd mariadb.service systemctl enable zabbix-server.service httpd mariadb.service else echo \"安装失败\" exit fi Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 20:20:22 "},"zabbix/create_monitor.html":{"url":"zabbix/create_monitor.html","title":"创建监控","keywords":"","body":"创建监控 第一步: 配置---主机---创建主机(创建要监控的主机) 第二步: 配置监控的主机 主机信息中: 名称 主机组 监控的主机地址 模板信息中: 指定需要链接的模板信息 第三步: 保存退出,进行监控检查 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 19:40:27 "},"zabbix/custom__monitor.html":{"url":"zabbix/custom__monitor.html","title":"zabbix自定义监控","keywords":"","body":"zabbix自定义监控 监控项: 可以自定义监控收集主机的信息 应用集: 将多个类似的监控项进行整合 便于查看检查 模板: 将多个监控项 触发器 图形都配置在模板中, 方便多个监控的主机进行调用 动作: 指定将报警信息发送给谁OK/定义报警的信息ok/定义报警的类型OK(邮件 微信 短信电话) PS: 宏信息定义方法: https://www.zabbix.com/documentation/4.0/zh/manual/appendix/macros/supported_by_location 触发器: 可以实现报警提示(条件表达式),默认页面提示报警 图形: 将多个图整合成一张,便于分析数据 报警媒介: 定义报警的方式 需求: 监控nginx服务是否启动 1) 在zabbix-agent进行配置文件编写 第一步: 编写自定义监控命令 [root@web01 zabbix_agentd.d]# ps -ef|grep -c [n]ginx 第二步：编写zabbix-agent配置文件 #第一种方法: 直接修改zabbix-agent配置文件参数 UserParameter= # 第二种方法: 在zabbix_agentd.d/目录中编写自定义监控文件 # UserParameter=键(变量名),值(变量信息) # UserParameter=web_state,ps -ef|grep -c [n]ginx [root@web01 zabbix_agentd.d]# cat web_server.conf UserParameter=web_state,ps -ef|grep -c [n]ginx 第三步: 重启zabbix-agent服务 [root@web01 zabbix_agentd.d]# systemctl restart zabbix-agent.service [root@web01 zabbix_agentd.d]# systemctl status zabbix-agent.service 2) 在zabbix-server命令行进行操作 第一步： 检测自定义监控信息是否正确 [root@zabbix ~]# yum -y install zabbix-get [root@zabbix ~]# zabbix_get -s 10.0.0.7 -k 'web_state' 3 3)在zabbix-server网站页面进行配置 第一个历程: 进入到创建监控项页面: 配置---主机---选择相应主机的监控项 第二个历程: 监控项页面如何配置: 名称 键值 更新间隔时间 应用集 第三个历程: 检查是否收集到监控信息 需求2:复杂的自定义监控配置(多个服务状态) # 编辑配置文件 [root@web01 zabbix_agentd.d]# vim server_state.conf UserParameter=server_state[*],netstat -lntup|grep -c $1 # 重启服务 [root@web01 zabbix_agentd.d]# systemctl restart zabbix-agent.service [root@web01 zabbix_agentd.d]# Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 19:40:27 "},"zabbix/wx.html":{"url":"zabbix/wx.html","title":"微信报警配置","keywords":"","body":"微信报警配置 1、需要注册企业微信,并进行配置 我的企业: 01. 获取企业id: ww32d68104ab5f51b0 02. 获取企业二维码: 允许员工加入 管理工具: 01. 成员加入---进行审核通过 应用小程序: 01. 进行创建 02. 收集程序信息 AgentId: Secret: RvQYpaCjWbYMCcwhnPqg1ZYcEGB9cOQCvvlkn-ft6j4 2、脚本wx.py cat /etc/zabbix/zabbix-server.conf AlertScriptsPath=/usr/lib/zabbix/alertscripts --- 放置告警脚本 #!/usr/bin/env python #-*- coding: utf-8 -*- import requests import sys import os import json import logging logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s, %(filename)s, %(levelname)s, %(message)s',datefmt = '%a, %d %b %Y %H:%M:%S',filename = os.path.join('/tmp','weixin.log'),filemode = 'a') corpid='ww4f8d9fad75efbe' 3、修改添加报警媒介---定义发微信配置 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-12 21:49:04 "},"zabbix/email.html":{"url":"zabbix/email.html","title":"邮件报警配置","keywords":"","body":"邮件报警配置 1、创建触发器 配置---主机---选择相应监控主机触发器---创建触发器 设置好表达式 {web01:server_state[nginx].last()} 2、修改动作配置 配置---动作---将默认动作进行开启 3、建立和163邮箱服务关系 管理---报警媒介类型---创建报警媒介 4、定义接收报警的邮件地址 小人头--报警媒介--设置收件人信息 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 21:47:32 "}}