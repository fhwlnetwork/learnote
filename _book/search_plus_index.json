{"./":{"url":"./","title":"简介","keywords":"","body":"先写个目录吧 这是码农转运维的心塞路 linux笔记 linux基础命令 linux时间 linux系统优化 linux磁盘分区 Nginx笔记 Tomact笔记 redis笔记 安装 主从配置_哨兵配置 redis集群配置 redis集群扩容收缩 工具管理 k8_docker笔记 安装 ES笔记 安装 交互 操作语言 集群配置 ELK笔记 安装 nginxjson日志采集 nginix正常日志和错误日志 tomcat日志收集 java多行日志收集 收集docker日志 filebet收集ngingx日志 redis作为缓存收集日志 kafka缓存收集日志 kibana画图 redis作为缓存收集日志 kafka缓存收集日志 使用nginx+keepalived代理多台redis 监控服务zabbix 安装 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 14:13:29 "},"linux/commond.html":{"url":"linux/commond.html","title":"linux基础命令","keywords":"","body":"linux基础命令 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-21 09:23:36 "},"linux/time_synchronism.html":{"url":"linux/time_synchronism.html","title":"linux时间","keywords":"","body":"时间管理 1、查看时间信息: [root@web01 /etc]# date Sun May 9 16:06:04 CST 2021 2、 调整时间显示格式 [root@web01 /etc]# date +%F 2021-05-09 [root@web01 /etc]# date \"+%F %T\" 2021-05-09 16:07:27 [root@web01 /etc]# date \"+%Y +%F %T\" 2021 +2021-05-09 16:07:58 [root@web01 /etc]# date \"+%Y-%m +%F %T\" 2021-05 +2021-05-09 16:09:03 [root@web01 /etc]# date \"+%Y-%m-%d +%F %T\" 2021-05-09 +2021-05-09 16:09:15 #显示历史时间信息: [root@web01 /etc]# date +%F -d \"-2day\" 2021-05-07 [root@web01 /etc]# date +%F -d \"1 day ago\" 2021-05-08 #显示未来时间信息: [root@web01 /etc]# # date -d \"+2day\" [root@web01 /etc]# date -d \"+2day\" Tue May 11 16:11:32 CST 2021 [root@web01 /etc]# date -d \"2day\" Tue May 11 16:11:47 CST 2021 3、如何实际修改系统时间 [root@web01 /etc]# date -s \"2020-04-17\" Fri Apr 17 00:00:00 CST 2020 [root@web01 /etc]# date Fri Apr 17 00:00:02 CST 2020 [root@web01 /etc]# date -s \"2020/04/17 14:00\" Fri Apr 17 14:00:00 CST 2020 [root@web01 /etc]# 4、时间同步 [root@web01 /etc]# yum install -y ntpdate ntp #配置ntp [root@web01 /var/lib/ntp]# vim /etc/ntp.conf 21 #server 0.centos.pool.ntp.org iburst 22 #server 1.centos.pool.ntp.org iburst 23 #server 2.centos.pool.ntp.org iburst 24 #server 3.centos.pool.ntp.org iburst 25 server ntp1.aliyun.com 在ntpd服务启动时，先使用ntpdate命令同步时间： [root@web01 ~]# ntpdate ntp1.aliyun.com [root@web01 /var/lib/ntp]# systemctl restart ntpd Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 08:41:54 "},"linux/majorzation.html":{"url":"linux/majorzation.html","title":"linux系统优化","keywords":"","body":"系统优化 1、系统的优化方法（基础优化） #1）了解系统的环境 #两个命令： # a)、cat /etc/redhat-release ------获得系统发行版本和具体系统版本信息 [root@web01 ~]# cat /etc/redhat-release CentOS Linux release 7.5.1804 (Core) # b)、 uname -a [root@web01 ~]# uname -a Linux web01 3.10.0-862.el7.x86_64 #1 SMP Fri Apr 20 16:44:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux #记忆centos7系统的内核信息 #Q：一起你用的LINUX系统是什么环境的？ #a: centos7 具体型号7.5 内核3.10 64位 2、操作系统优化---命令提示符优化 #优化方法: 修改PS1环境变量 #默认配置: [root@web01 ~]# echo $PS1 [\\u@\\h \\W]\\$ # \\u --- 显示当前登录用户名称 # \\h --- 显示系统主机名称 # \\W --- 显示当前所在目录信息(目录结构的最后结尾信息) 修改优化方法: 01. 修改命令提示符的内容: # ------显示全路径 vi /etc/profile 加入 export PS1='[\\u@\\H \\w]\\$' [root@web01 /etc/sysconfig]# source /etc/profile 02. 命令提示符如何修改颜色 # Linxu系统中如何给信息加颜色 \\[\\e[F;Bm] 文字内容 \\e[m ”[\\[\\e[31;40m]\\u\\e[m @\\h \\W]\\$ “ [root@web01 ~]# tail -5 /etc/profile export PS1='\\[\\e[32;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' 设置颜色 内容 结束 export PS1='\\[\\e[30;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 黑色提示符 export PS1='\\[\\e[31;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 红色提示符 export PS1='\\[\\e[32;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 绿色提示符 export PS1='\\[\\e[33;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 黄色提示符 export PS1='\\[\\e[34;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 蓝色提示符 export PS1='\\[\\e[35;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 粉色 export PS1='\\[\\e[36;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 浅蓝 export PS1='\\[\\e[37;1m\\][\\u@\\h \\W]\\$ \\[\\e[0m\\]' -- 白色 实现命令提示符是彩色的 #实现以上效果方法,在/etc/profile底行输入: [root@web01 /etc/sysconfig]# vim /etc/profile export PS1='[\\[\\e[31;1m\\]\\u@\\[\\e[32;1m\\]\\h\\[\\e[36;1m\\] \\w\\[\\e[33;1m\\]]\\$ ' 3、操作系统优化-----yum下载源优化 yum软件优势: 简单 快捷 01. 不需要到官方网站单独下载软件包(yum仓库) 02. 可以解决软件的依赖关系 yum优化方法: 1. 优化基础的yum源文件， #1）更换阿里云或者网易源 #通过阿里镜像源进行优化: curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #更新网易源 curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo 2） #运行以下命令生成缓存： yum clean all yum makecache 02. 优化扩展的yum源文件 #通过阿里镜像源进行优化: # wget -O /etc/yum.repos.d/epe l.repo http://mirrors.aliyun.com/repo/epel-7.repo #检查可用的yum源信息 #yum repolist #如何查看软件是否安装? #利用rpm命令查看软件是否安装 #rpm -qa 查询的软件 --------q表示查询,-a表示所有 #查看软件包中有哪些信息 rpm -ql 软件名称 ---- -l表示列表显示 #查看文件信息属于哪个软件大礼包 #which 软件名称 #rpm -qf `软件名称 ` 4. 系统安全相关优化(将一些安全服务进行关闭) 1). 防火墙服务程序 centos6 查看防护墙服务状态 /etc/init.d/iptables status 临时关闭防火墙服务 /etc/init.d/iptables stop /etc/init.d/iptables status 永久关闭防火墙服务 chkconfig iptables off centos7 查看防火墙服务状态 systemctl status firewalld 临时关闭防火墙服务 systemctl stop firewalld systemctl status firewalld -- 操作完确认 永久关闭防火墙服务 systemctl disable firewalld 补充: 查看服务状态信息简便方法 systemctl is-active firewalld --- 检查服务是否正常运行 systemctl is-enabled firewalld --- 检查确认服务是否开机运行 4、关闭selinux服务程序 1.什么是selinux： selinux(security enhanced linux)安全增强型linux系统，它是一个linux内核模块，也是linux的一个安全子系统。 selinux的主要作用就是最大限度地减小系统中服务进程可访问的资源（最小权限原则） 2.selinux有两个级别 强制和警告 setenforce 0|1 0表示警告(Permissive)，1表示强制（Enforcing） 3.selinux相当于一个插件 (内核级的插件) 4.selinux功能开启后，会关闭系统中不安全的功能 5.查看日志中的警告：cat /var/log/audit/audit.log 临时关闭: 检查确认: getenforce --- 确认selinux服务是否开启或是关闭的 如何关闭: [root@web01 /etc]# setenforce usage: setenforce [ Enforcing | Permissive | 1 | 0 ] Enforcing 1 --- 临时开启selinux Permissive 0 --- 临时关闭selinux setenforce 0 --- 临时关闭selinux服务 永久关闭: enforcing - SELinux security policy is enforced. （selinux服务处于正常开启状态） permissive - SELinux prints warnings instead of enforcing.（selinux服务被临时关闭了） disabled - No SELinux policy is loaded.（selinux服务彻底关闭） vi /etc/selinux/config SELINUX=disabled PS: 如果想让selinux配置文件生效,重启系统 05、字符编码优化 出现乱码的原因: 01. 系统字符集设置有问题 02. 远程软件字符集设置有问题 03. 文件编写字符集和系统查看的字符集不统一 出现乱码的原因: 01. 系统字符集设置有问题 02. 远程软件字符集设置有问题 03. 文件编写字符集和系统查看的字符集不统一 centos6 设置方法 # 查看默认编码信息: [root@web01 /etc]# echo $LANG --- LANG用于设置字符编码信息 en_US.UTF-8 #临时修改: [root@web01 ~]# LANG=XXX #永久修改: #方法一: [root@web01 ~]# tail -5 /etc/profile export LANG='en_US.UTF-8' #方法二: vi /etc/sysconfig/i18n LANG='en_US.UTF-8 source /etc/sysconfig/i18n centos7设置方法 # 查看默认编码信息 [root@web01 ~]# echo $LANG en_US.UTF-8 # 临时修改: [root@web01 ~]# echo $LANG en_US.UTF-8 LANG=XXX # 永久修改: # 方法一: 更加有先 [root@web01 ~]# tail -5 /etc/profile export LANG='en_US.UTF-8' # 方法二: [root@web01 ~]# cat /etc/locale.conf LANG=\"zh_CN.UTF-8\" # 补充：一条命令即临时设置，又永久设置 localectl set-locale LANG=zh_CN.GBK 06、使xshell软件远程连接速度加快 #第一个步骤：修改ssh服务配置文件 vi /etc/ssh/sshd_config 79 GSSAPIAuthentication no 115 UseDNS no #第二个步骤：重启ssh远程服务 systemctl restart sshd 7、时间同步：[时间同步]（linux/time_synchronism.md） Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 08:41:54 "},"linux/Disk_partition.html":{"url":"linux/Disk_partition.html","title":"linux磁盘分区","keywords":"","body":"磁盘分区 [TOC] #不关机，添加硬盘，自动识别 [root@web01 ~]# echo \"- - -\" > /sys/class/scsi_host/host0/scan 1、磁盘分区实践--磁盘小于2T 第一个里程: 准备磁盘环境 准备了一块新的10G硬盘 第二个里程: 在系统中检查是否识别到了新的硬盘 fdisk -l --- 查看分区信息 [root@web01 ~]# echo \"- - -\" > /sys/class/scsi_host/host0/scan # 查看分区信息 [root@web01 ~]# fdisk -l 第三个里程: 对磁盘进行分区处理(fdisk-- 进行分区处理 查看分区信息) 指令说明 d delete a partition ***** 删除分区 g create a new empty GPT partition table 创建一个新的空的GPT分区表(可以对大于2T磁盘进行分区) l list known partition types 列出可以分区的类型??? m print this menu 输出帮助菜单 n add a new partition ***** 新建增加一个分区 p print the partition table ***** 输出分区的结果信息 q quit without saving changes 不保存退出 t change a partition's system id 改变分区的系统id==改变分区类型(LVM 增加swap分区大小) u change display/entry units 改变分区的方式 是否按照扇区进行划分 w write table to disk and exit ***** 将分区的信息写入分区表并退出==保存分区信息并退出 a ) 规划分4个主分区 ,1,2分区1g,3分区10g,其余的给第四分区 [root@web01 ~]# fdisk /dev/sdc Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-41943039, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p Partition number (2-4, default 2): First sector (2099200-41943039, default 2099200): Using default value 2099200 Last sector, +sectors or +size{K,M,G} (2099200-41943039, default 41943039): +1G Partition 2 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): First sector (4196352-41943039, default 4196352): Last sector, +sectors or +size{K,M,G} (20971520-41943039, default 41943039): +10G Using default value 41943039 Partition 3 of type Linux and of size 10 GiB is set Command (m for help): n Partition type: p primary (3 primary, 0 extended, 1 free) e extended Select (default e): p Selected partition 4 First sector (4196352-41943039, default 4196352): Using default value 4196352 Last sector, +sectors or +size{K,M,G} (4196352-20971519, default 20971519): Using default value 20971519 Partition 4 of type Linux and of size 8 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 20971520 41943039 10485760 83 Linux /dev/sdc4 4196352 20971519 8387584 83 Linux Partition table entries are not in disk order Command (m for help): w b) 规划分3个主分区 1个扩展分区 每个主分区1G 剩余都给扩展分区 [root@web01 ~]# fdisk /dev/sdc Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): First sector (2048-41943039, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): 1G Value out of range. Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p Partition number (2-4, default 2): First sector (2099200-41943039, default 2099200): Using default value 2099200 Last sector, +sectors or +size{K,M,G} (2099200-41943039, default 41943039): +1G Partition 2 of type Linux and of size 1 GiB is set Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): First sector (4196352-41943039, default 4196352): Using default value 4196352 Last sector, +sectors or +size{K,M,G} (4196352-41943039, default 41943039): +1G Partition 3 of type Linux and of size 1 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux Command (m for help): n Partition type: p primary (3 primary, 0 extended, 1 free) e extended Select (default e): e Selected partition 4 First sector (6293504-41943039, default 6293504): Using default value 6293504 Last sector, +sectors or +size{K,M,G} (6293504-41943039, default 41943039): Using default value 41943039 Partition 4 of type Extended and of size 17 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux /dev/sdc4 6293504 41943039 17824768 5 Extended Command (m for help): n All primary partitions are in use Adding logical partition 5 First sector (6295552-41943039, default 6295552): Using default value 6295552 Last sector, +sectors or +size{K,M,G} (6295552-41943039, default 41943039): +1G Partition 5 of type Linux and of size 1 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0xb478de23 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 4196351 1048576 83 Linux /dev/sdc3 4196352 6293503 1048576 83 Linux /dev/sdc4 6293504 41943039 17824768 5 Extended /dev/sdc5 6295552 8392703 1048576 83 Linux Command (m for help): ###说明： #### 有了扩展分区才能逻辑分区，扩展分区不能直接使用，只能在逻辑分区种才能使用 第四个里程: 保存退出,让系统可以加载识别分区信息 #输入w,保存退出 Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. #让系统可以加载识别分区文件 [root@web01 ~]# partprobe /dev/sdc 第五个里程：格式化磁盘 [root@web01 ~]# partprobe /dev/sdc # ext3/4 centos6 # xfs centos7 格式效率较高 数据存储效率提升(数据库服务器) [root@web01 ~]# mkfs -t xfs /dev/sdc1 meta-data=/dev/sdc1 isize=512 agcount=4, agsize=65536 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=262144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@web01 ~]# mkfs.xfs /dev/sdc2 meta-data=/dev/sdc2 isize=512 agcount=4, agsize=65536 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=262144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 2、磁盘分区实践--磁盘大于2T 第一个里程: 准备磁盘环境 虚拟主机中添加一块3T硬盘 第二个里程: 使用parted命令进行分区 帮助说明 mklabel,mktable LABEL-TYPE create a new disklabel (partition table) 创建一个分区表 (默认为mbr) print [devices|free|list,all|NUMBER] display the partition table, available devices, free space, all found partitions, or a particular partition 显示分区信息 mkpart PART-TYPE [FS-TYPE] START END make a partition 创建一个分区 quit exit program 退出分区状态 rm NUMBER delete partition NUMBER 删除分区 [root@web01 ~]# parted /dev/sdd GNU Parted 3.1 Using /dev/sdd Welcome to GNU Parted! Type 'help' to view a list of commands. (parted) mklabel gpt (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags (parted) mkpart primary 0 2100G Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? Ignore (parted) mkpart primary 2100 2200G Warning: You requested a partition from 2100MB to 2200GB (sectors 4101562..4296875000). The closest location we can manage is 2100GB to 2200GB (sectors 4101562501..4296875000). Is this still acceptable to you? Yes/No? yes Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? Ignore #查看分区 (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 17.4kB 2100GB 2100GB primary 2 2100GB 2200GB 100GB primary #删除第二个分区 (parted) rm 2 (parted) print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdd: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 17.4kB 2100GB 2100GB primary (parted) mkpart primary 2100 2200G Warning: You requested a partition from 2100MB to 2200GB (sectors 4101562..4296875000). The closest location we can manage is 2100GB to 2200GB (sectors 4101562501..4296875000). Is this still acceptable to you? Yes/No? yes Warning: The resulting partition is not properly aligned for best performance. Ignore/Cancel? ingnore parted: invalid token: ingnore Ignore/Cancel? Ignore #退出分区模式 (parted) quit Information: You may need to update /etc/fstab. 第三个里程: 加载磁盘分区 [root@web01 ~]# partprobe /dev/sdd 第四个里程:格式化分区 [root@web01 ~]# mkfs.xfs /dev/sdd1 meta-data=/dev/sdd1 isize=512 agcount=4, agsize=128173827 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=512695308, imaxpct=5 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=250339, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@web01 ~]# 3、挂载分区 3.1 手动挂载 #创建挂在目录 [root@web01 ~]# mkdir /mount01 [root@web01 ~]# mount /dev/sdc1 /mount01 #查看挂载结果 [root@web01 ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos_wjh-root 19G 2.2G 17G 12% / devtmpfs 476M 0 476M 0% /dev tmpfs 488M 0 488M 0% /dev/shm tmpfs 488M 7.7M 480M 2% /run tmpfs 488M 0 488M 0% /sys/fs/cgroup /dev/sda1 197M 108M 90M 55% /boot tmpfs 98M 0 98M 0% /run/user/0 /dev/sdc1 1014M 33M 982M 4% /mount01 3.2 开机自动挂载 方法一: 将挂载命令放入/etc/rc.local [root@web01 ~]# vim /etc/rc.local [root@web01 ~]# tail -2 /etc/rc.local touch /var/lock/subsys/local mount /dev/sdc1 /mount01 [root@web01 ~]# chmod +x /etc/rc.d/rc.local 方法二: 在/etc/fstab文件中进行设置 #查看uuid [root@web01 ~]# blkid /dev/sda1: UUID=\"ef56a16b-6ffe-4ee9-84bc-54519c404628\" TYPE=\"xfs\" /dev/sda2: UUID=\"9mzWRG-c76T-l0GG-nMAm-KjJ0-vA3V-8s1UcP\" TYPE=\"LVM2_member\" /dev/sdc1: UUID=\"719b1119-bc16-421f-9039-032fc874e302\" TYPE=\"xfs\" /dev/sdc2: UUID=\"895dac6f-5864-4f0d-9a58-0ed43bf690a8\" TYPE=\"xfs\" /dev/mapper/centos_wjh-root: UUID=\"c570790b-11f1-4237-835a-06115e3b4890\" TYPE=\"xfs\" /dev/mapper/centos_wjh-swap: UUID=\"130c3eaf-c634-4f5b-8cf2-21d48c3956d4\" TYPE=\"swap\" /dev/sdd1: UUID=\"bcc9ed95-532b-4c9e-a697-9d66bae6a3c8\" TYPE=\"xfs\" PARTLABEL=\"primary\" PARTUUID=\"4e66de18-0674-4b4a-b784-d93332dbf466\" /dev/sdd2: PARTLABEL=\"primary\" PARTUUID=\"3b280fe8-5d0a-414a-aafc-2772ecffb2e0\" ##使用uuid或者直接行磁盘路径 [root@web01 ~]# tail -2 /etc/fstab #/dev/sdd1 /mount2 xfs defaults 0 0 UUID=bcc9ed95-532b-4c9e-a697-9d66bae6a3c /mount2 xfs defaults 0 0 4、企业磁盘常见问题: 1) 磁盘满的情况 No space left on device a)存储的数据过多了 block存储空间不足了 解决方式: a 删除没用的数据 b 找出大的没用的数据 find / -type f -size +xxx du -sh /etc/sysconfig/network-scripts/*|sort -h (按照数值排序命令) b) 存储的数据过多了 inode存储空间不足了: 出现了大量小文件 df -i 查看inode 解决方式: 删除大量的没用的小文件 5、swap分区调整 第一步： 将磁盘分出一部分空间给swap分区使用 [root@web01 ~]# dd if=/dev/zero of=/tmp/1G bs=100M count=10 第二步： 将指定磁盘空间作为swap空间使用 [root@web01 ~]# mkswap /tmp/1G Setting up swapspace version 1, size = 1023996 KiB no label, UUID=9a9aed5d-aade-41ba-8a1a-6f67275c2873 第三步： 加载使用swap空间 [root@web01 ~]# swapon /tmp/1G swapon: /tmp/1G: insecure permissions 0644, 0600 suggested. [root@web01 ~]# free -h total used free shared buff/cache available Mem: 974M 119M 164M 25M 691M 662M Swap: 2.0G 0B 2.0G ## swap足够时，释放资源 [root@web01 ~]# swapoff /tmp/1G [root@web01 ~]# free -h total used free shared buff/cache available Mem: 974M 118M 164M 25M 691M 663M Swap: 1.0G 0B 1.0G [root@web01 ~]# rm /tmp/1G -f [root@web01 ~]# ` Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 08:41:54 "},"redis/安装.html":{"url":"redis/安装.html","title":"安装","keywords":"","body":"1、目录规划 ### redis 下载目录 /data/soft/ ### redis 安装目录 /opt/redis_cluster/redis_{PORT}/{conf,logs,pid} ### redis数据目录 /opt/redis_cluster/redis_{PORT}/redis_{port}.rdb ### redis 运维脚本 /root/scripts/redis_shell.sh 2、安装命令 2.1、 安装准备 ###编辑hosts文件 [root@db01 ~]#vim /etc/hosts [root@db01 ~]#tail -3 /etc/hosts 10.0.0.51 db01 10.0.0.52 db02 10.0.0.53 db03 [root@db01 ~]#创建目录 [root@db01 ~]#mkdir -p /data/soft [root@db01 ~]#mkdir -p /opt/redis_cluster/redis_6379 [root@db01 ~]#mkdir -p /opt/redis_cluster/redis_6379/{conf,pid,logs} [root@db01 ~]#mkdir -p /data/redis_cluster/redis_6379 [root@db01 ~]#cd /data/soft/ root@db01 ~]#下载文件 [root@db01 /data/soft]#wget http://download.redis.io/releases/redis-3.2.12.tar.gz [root@db01 /data/soft]#tar zxvf redis-3.2.12.tar.gz -C /opt/redis_cluster/ 2.2、 安装程序 [root@db01 /opt/redis_cluster]#ln -s /opt/redis_cluster/redis-3.2.12/ /opt/redis_cluster/redis [root@db01 /opt/redis_cluster]#ll total 0 lrwxrwxrwx 1 root root 32 Apr 20 13:40 redis -> /opt/redis_cluster/redis-3.2.12/ drwxrwxr-x 6 root root 309 Jun 13 2018 redis-3.2.12 drwxr-xr-x 5 root root 41 Apr 20 13:20 redis_6379 [root@db01 /opt/redis_cluster]#cd redis [root@db01 /opt/redis_cluster/redis]#make && make install 2.3、编辑配置文件 [root@db01 /opt/redis_cluster/redis_6379/conf]#vim /opt/redis_cluster/redis_6379/conf ### 以守护模式启动 daemonize yes ### 绑定的主机地址 bind 10.0.0.51 127.0.0.1 ### 监听接口 port 6379 ### pid文件和log文件的保存地址 pidfile /opt/redis_cluster/redis_6379/pid/redis_6379.pid logfile /opt/redis_cluster/redis_6379/logs/redis_6379.log ### 设置数据库的数量，默认数据库为0 databases 16 ### 指定本地持计划文件的文件名，默认是dump.rdb dbfilename redis_6379.rdb ### 本地数据库的目录 dir /data/redis_cluster/redis_6379 2.3 借助官方工具生成启动配置文件 进入utils，执行install文件，生成 [root@db01 /opt/redis_cluster/redis_6379/conf]#cd [root@db01 ~]#cd /opt/redis_cluster/redis/utils/ [root@db01 /opt/redis_cluster/redis/utils]#./install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] Selecting default: 6379 Please select the redis config file name [/etc/redis/6379.conf] Selected default - /etc/redis/6379.conf Please select the redis log file name [/var/log/redis_6379.log] Selected default - /var/log/redis_6379.log Please select the data directory for this instance [/var/lib/redis/6379] Selected default - /var/lib/redis/6379 Please select the redis executable path [/usr/local/bin/redis-server] Selected config: Port : 6379 Config file : /etc/redis/6379.conf Log file : /var/log/redis_6379.log Data dir : /var/lib/redis/6379 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. Copied /tmp/6379.conf => /etc/init.d/redis_6379 Installing service... Successfully added to chkconfig! Successfully added to runlevels 345! Starting Redis server... Installation successful! 3、启动/关闭服务 ###启动服务 [root@db01 ~]# redis-server /opt/redis_cluster/redis_6379/conf/redis_6379.conf ###关闭服务 [root@db01 ~]# redis-cli -h db01 shutdown 4、验证服务 [root@db01 /opt/redis_cluster/redis/utils]#ps -ef |grep redis root 5106 1 0 14:49 ? 00:00:03 redis-server 10.0.0.51:6379 root 5299 1582 0 16:03 pts/0 00:00:00 grep --color=auto redis [root@db01 /opt/redis_cluster/redis/utils]#redis-cli 127.0.0.1:6379> set name wjh OK 127.0.0.1:6379> get name \"wjh\" 127.0.0.1:6379> 5、配置密码验证 # 2) No password is configured. # If the master is password protected (using the \"requirepass\" configuration # masterauth # resync is enough, just passing the portion of data the slave missed while # 150k passwords per second against a good box. This means that you should # use a very strong password otherwise it will be very easy to break. requirepass foobared 6、 配置持久化 AOF 持久化(append-only log file) 记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 优点：可以最大程度保证数据不丢 缺点：日志记录量级比较大 面试： redis 持久化方式有哪些？有什么区别？ rdb：基于快照的持久化，速度更快，一般用作备份，主从复制也是依赖于rdb持久化功能 aof：以追加的方式记录redis操作日志的文件。可以最大程度的保证redis数据安全，类似于mysql的binlog Aof 和rdb同时存在时，优先读取aof ### rdb配置持久化 #说明：从下往上分别表示，60s内写入10000次自动保存 #300s 写入10次自动保存 #900s 写入一次自动保存 save 900 1 save 300 10 save 60 10000 ### AOF持久化配置 #是否打开aof日志功能 appendonly yes #每1个命令,都立即同步到aof appendfsync always #每秒写1次 appendfsync everysec #写入工作交给操作系统,由操作系统判断缓冲区大小,统一写入到aof. appendfsync no Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-21 09:23:36 "},"redis/主从配置_哨兵.html":{"url":"redis/主从配置_哨兵.html","title":"主从配置_哨兵配置","keywords":"","body":"流 程 1 ． 从 库 发 起 同 步 请 求 2 ． 主 库 收 到 请 求 后 执 行 bg “ ve 保 存 当 前 内 存 里 的 数 据 到 磁 盘 3 ． 主 库 将 持 久 化 的 数 据 发 送 给 从 库 的 数 据 目 录 4 ． 从 库 收 到 主 库 的 持 久 化 数 据 之 后 ， 先 清 空 自 己 当 前 内 存 中 的 所 有 数 据 5 ． 从 库 将 主 库 发 送 过 来 的 持 久 化 文 件 加 载 到 自 己 的 内 存 里 局 限 性 ． 1 ． 执 行 主 从 复 制 之 前 ， 现 将 数 据 备 份 一 份 2 ． 建 议 将 主 从 复 制 写 入 到 配 置 又 件 中 3 ． 在 业 务 低 峰 期 做 主 从 复 制 ， 4 ． 拷 贝 数 据 时 候 会 占 用 蒂 宽 5 ． 不 能 自 动 完 成 主 从 切 换 ， 需 要 人 工 介 入 环境准备 安装参考：redis安装 ##打包redis 文件 [root@db01 /opt]# tar zcvf db01_redis.tar.gz /opt/redis_cluster/ #拷贝文件到第二台redis服务器中 [root@db01 /opt]#scp db01_redis.tar.gz db02:/opt #执行安装文件 [root@db02 /opt]# mkdir -p /opt/redis_cluster/ [root@db02 /opt]# tar zxvf db01_redis.tar.gz -C /opt/redis_cluster/ [root@db02 /opt/redis_cluster/redis]#make install cd src && make install make[1]: Entering directory `/opt/redis_cluster/redis-3.2.12/src' Hint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install make[1]: Leaving directory `/opt/redis_cluster/redis-3.2.12/src' #创建数据库目录 [root@db02 /opt/redis_cluster/redis]#mkdir -p /data/redis_cluster/redis_6379/ [root@db02 /opt/redis_cluster/redis]# sed -i 's#51#52#' /opt/redis_cluster/redis_6379/conf/redis_6379.conf 主从配置 [root@db02 /opt/redis_cluster]#redis-cli -h db02 db02:6379> SLAVEOF db01 6379 OK db02:6379> keys * 1) \"nam2\" 2) \"name\" 3) \"name1\" db02:6379> 哨兵配置 自 动 故 障 迁 移 (Automaticfailover ： 当 一 个 土 服 务 器 不 能 正 常 工 作 时 ， Sentinel 会 廾 始 一 钦 自 动 故 障 迁 移 操 作 ， 它 会 将 失 效 王 务 器 的 其 中 一 个 从 务 器 升 级 为 新 的 主 务 器 ， # 让 失 效 主 服 务 的 其 他 从 服 务 器 改 为 复 制 新 的 主 服 务 器 ； 当 客 户 端 试 图 莲 接 失 效 的 主 务 器 时 ， 集 群 也 会 向 客 户 端 返 回 新 主 服 务 器 的 地 址 ， 使 得 集 群 可 以 使 用 新 主 服 务 器 代 替 失 牖 务 器 db01操作 [root@db01 /opt]# mkdir -p /opt/redis_cluster/redis_26379 [root@db01 /opt]# mkdir -p /opt/redis_cluster/redis_26379/{conf,pid,log} [root@db01 /opt]# mkdir -p /data/redis_cluster/redis_26379 [root@db01 /opt/redis_cluster]# cat > /opt/redis_cluster/redis_26379/conf/redis_26379.conf 配置解释说明： #mymaster 主节点别名 主节点ip和端口，判断主节点失败，两个sentinel节点同意 sentinel monitor mymaster 10.0.0.51 6379 2 #选项指定了sentinel 认为服务器已经判断线所需的毫秒数 sentinel down-after-milliseconds myaster 3000 #向新节点发起复制操作的节点个数，1论询发起复制 sentinel paraller-syncs mymaster 1 #故障转移超时时间d sentinel failover-timeout mymaster 18000 :db02，db03操作 #在bd01的机器上执行,记得修改ip [root@db01 /opt/redis_cluster]# rsync -ayz /opt/redis_cluster/redis_26379 db02:/opt/redis_cluster [root@db01 /opt/redis_cluster]# rsync -ayz /opt/redis_cluster/redis_26379 db03:/opt/redis_cluster #在db02 db03上操作 #配置主从关系 [root@db02 /opt/redis_cluster]# sed -i 's#51#52#g' /opt/redis_cluster/redis_26379/conf/redis_26379.conf [root@db03 /opt/redis_cluster]# sed -i 's#51#53#g' /opt/redis_cluster/redis_26379/conf/redis_26379.conf [root@db02 /opt]# redis-server /opt/redis_cluster/redis_6379/conf/redis_6379.conf [root@db02 /opt]# redis-cli slaveof 10.0.0.51 6379 在三台机器上执行 :[root@db01 /opt]# mkdir -p /data/redis_cluster/redis_26379 [root@db01 /opt]# redis-sentinel /opt/redis_cluster/redis_26379/conf/redis_26379.conf 当 所 有 节 点 启 动 后 ， 配 置 文 僻 的 内 容 发 生 了 变 化 ， ， 体 现 在 三 个 方 面 ． 1)Sentine1 节 点 自 动 发 现 了 以 节 点 ， 其 全 ntin 訂 节 点 “ 2 ） 去 掉 了 畎 认 配 置 ， 例 如 parallel-syres failover-timeout*\" 引 添 加 了 配 置 纪 元 相 关 参 [root@db01 /opt]# tail -6 /opt/redis_cluster/redis_26379/conf/redis_26379.conf sentinel leader-epoch mymaster 0 sentinel known-slave mymaster 10.0.0.53 6379 sentinel known-slave mymaster 10.0.0.52 6379 sentinel known-sentinel mymaster 10.0.0.52 26379 c10ca8742bc1d585d428920cd75c7a7449ab11c4 sentinel known-sentinel mymaster 10.0.0.53 26379 443e313d655ea6a0db011bf143a1ebe1f97ab045 sentinel current-epoch 0 停 掉 其 中 1 个 节 点 ， 然 后 观 察 其 他 节 点 的 日 志 变 化 故 障 转 移 后 配 置 文 件 变 化 redis serntinel 存在多拍个从节点时，如果想将指定的从节点升为主节点，可以将其他从节点的slaverpriority配置为0，但是需要注意failover后，将slave-priority调回原值 1、查询命令：config get slave-priority 2、设置命令：config set slave-priority 0 3、主动切换：sentinel failove mymaster Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-29 16:53:50 "},"redis/集群.html":{"url":"redis/集群.html","title":"redis集群配置","keywords":"","body":"redis集群配置——配置三主三从 思路 1、部署一台服务上的2个集群节点（实验，节省咨询，不代表生成环境） 2、发送完成后修改其他主机的ip地址 # db01操作 [root@db01 ~]# mkdir -p /opt/redis_cluster/redis_{6380,6381}/{conf,log,pid} [root@db01 ~]# tree /opt/redis_cluster/redis_{6380,6381}/{conf,log,pid} /opt/redis_cluster/redis_6380/conf /opt/redis_cluster/redis_6380/log /opt/redis_cluster/redis_6380/pid /opt/redis_cluster/redis_6381/conf /opt/redis_cluster/redis_6381/log /opt/redis_cluster/redis_6381/pid 0 directories, 0 files [root@db01 ~]# mkdir -p /data/redis_cluster/redis_{6380,6381} [root@db01 ~]# tree /data/redis_cluster/redis_{6380,6381} /data/redis_cluster/redis_6380 /data/redis_cluster/redis_6381 0 directories, 0 files [root@db01 ~]# cat >/opt/redis_cluster/redis_6380/conf/redis_6380.conf .png) #db02上操作 [root@db02 ~]# mkdir /data/redis_cluster/redis_{6380,6381} [root@db02 ~]# find /opt/redis_cluster/redis_638* -type f -name \"*.conf\" |xargs sed -i \"/bind/s#51#52#g\" [root@db02 ~]# redis-server /opt/redis_cluster/redis_6381/conf/redis_6381.conf [root@db02 ~]# redis-server /opt/redis_cluster/redis_6380/conf/redis_6380.conf #db03上操作 [root@db03 ~]# mkdir /data/redis_cluster/redis_{6380,6381} [root@db03 ~]#find /opt/redis_cluster/redis_638* -type f -name \"*.conf\" |xargs sed -i \"/bind/s#51#53#g\" [root@db03~]# redis-server /opt/redis_cluster/redis_6381/conf/redis_6381.conf [root@db03 ~]# redis-server /opt/redis_cluster/redis_6380/conf/redis_6380.conf #发现节点 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6380 db01:6380> CLUSTER MEET 10.0.0.52 6380 db01:6380> CLUSTER MEET 10.0.0.53 6380 #单节点找集群时，会自动加入集群中 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6381 #分配槽点 #一个集群里有16384个槽位,0-16383 #只要有一个槽位有问题或者没分配，整个集群都不可用 #集群的配置文件不要手动修改 [root@db01 ~]#redis-cli -h db01 -p 6380 cluster addslots {0..5461} OK [root@db01 ~]#redis-cli -h db02 -p 6380 cluster addslots {5461..10922} OK [root@db01 ~]#redis-cli -h db02 -p 6380 cluster addslots {10923..16383} OK ### 登录时加上-C集群会自动根据router去写入 [root@db01 /data/redis_cluster]#redis-cli -h db01 -p 6381 -c db01:6381> cluster nodes e7521bd87addccddee3e2865b73cc167001f8b2a 10.0.0.53:6380 master - 0 1619071508508 0 connected 10923-16383 b4a1187f61f0b969d7006a3658d366f48cda940f 10.0.0.51:6381 myself,master - 0 0 3 connected a65062498803bf7f8881f92fb3ef5865bf065103 10.0.0.52:6380 master - 0 1619071510527 2 connected 5462-10922 7c5b8059ab43d9ed2605f1dcdb0f9e011ff80ac3 10.0.0.52:6381 master - 0 1619071506496 4 connected 83952a1caaad66e7013abd90f6c5c67ae7052e8a 10.0.0.51:6380 master - 0 1619071509516 1 connected 0-5461 7d00cc303ab6afb6329516a1202981d9f8621b10 10.0.0.53:6381 master - 0 1619071509113 0 connect Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 14:34:45 "},"redis/集群扩容收缩.html":{"url":"redis/集群扩容收缩.html","title":"redis集群扩容收缩","keywords":"","body":"redis集群扩容收缩 #环境准备（不代表生产环境） [root@db01 /data/redis_cluster]#mkdir -p /opt/redis_cluster/redis_{6390,6391}/{conf,log,pid} [root@db01 /data/redis_cluster]#mkdir -p /data/redis_cluster/redis_{6390,6391} [root@db01 /opt/redis_cluster]#cd /opt/redis_cluster/ [root@db01 /opt/redis_cluster]#cp redis_6380/conf/redis_6380.conf redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#sed -i 's#6380#6390#' redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#cp redis_6380/conf/redis_6380.conf redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#sed -i 's#6380#6391#' redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#redis-server /opt/redis_cluster/redis_6390/conf/redis_6390.conf [root@db01 /opt/redis_cluster]#redis-server /opt/redis_cluster/redis_6391/conf/redis_6391.conf [root@db01 /opt/redis_cluster]#ps -ef |grep redis root 7448 1 0 13:34 ? 00:00:03 redis-server 10.0.0.51:6379 root 7452 1 0 13:34 ? 00:00:05 redis-server 10.0.0.51:6380 [cluster] root 7456 1 0 13:34 ? 00:00:05 redis-server 10.0.0.51:6381 [cluster] root 7591 1 0 14:52 ? 00:00:00 redis-server 10.0.0.51:6390 [cluster] root 7610 1 0 14:54 ? 00:00:00 redis-server 10.0.0.51:6391 [cluster] root 7614 6772 0 14:54 pts/1 00:00:00 grep --color=auto redis #添加节点 [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster meet 10.0.0.51 6390 OK [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster meet 10.0.0.51 6391 OK [root@db01 /opt/redis_cluster]#redis-cli -c -h db01 -p 6380 cluster nodes e7521bd87addccddee3e2865b73cc167001f8b2a 10.0.0.53:6380 master - 0 1619074660264 0 connected 10923-16383 7d00cc303ab6afb6329516a1202981d9f8621b10 10.0.0.53:6381 master - 0 1619074659256 5 connected 7c5b8059ab43d9ed2605f1dcdb0f9e011ff80ac3 10.0.0.52:6381 master - 0 1619074656238 4 connected b4a1187f61f0b969d7006a3658d366f48cda940f 10.0.0.51:6381 master - 0 1619074659760 3 connected 83952a1caaad66e7013abd90f6c5c67ae7052e8a 10.0.0.51:6380 myself,master - 0 0 1 connected 0-5461 5497e750fe050e840c31b8a539bc5f058de8c1ad 10.0.0.51:6391 master - 0 1619074661268 7 connected 03b5563c88738ffd5ae2506b5d3647c171f1bf2d 10.0.0.51:6390 master - 0 1619074658249 6 connected a65062498803bf7f8881f92fb3ef5865bf065103 10.0.0.52:6380 master - 0 1619074662273 2 connected 5462-10922 #使用工具直接添加节点 #使用前更新一下rub版本 1\\安装RVM(ruby version manager) 执行命令： gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB 继续执行：curl -sSL https://get.rvm.io | bash -s stable 继续执行： source /etc/profile.d/rvm.sh rvm list known 安装ruby 执行命令：rvm install 2.4.9 安装redis集群接口 执行命令：gem install redis ./redis-trib.rb add-node 1 10.0.0.51:6390 10.0.0.51:6380 [root@db01 /opt/redis_cluster/redis/src]#./redis-trib.rb reshard 10.0.0.51:6380 >>> Performing Cluster Check (using node 10.0.0.51:6380) What is the receiving node ID? 03b5563c88738ffd5ae2506b5d3647c171f1bf2d Please enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs. Source node #1:all Do you want to proceed with the proposed reshard plan (yes/no)? yes #收缩 [root@db01 /opt/redis_cluster/redis/src]#./redis-trib.rb del-node 10.0.0.51:6390 节点id Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 15:47:21 "},"redis/工具管理.html":{"url":"redis/工具管理.html","title":"工具管理","keywords":"","body":"# 数 据 导 入 导 出 工 具 #需 求 背 景 #刚 切 换 到 redis 隹 群 的 时 候 肯 定 会 面 临 数 据 导 入 的 门 题 所 以 这 里 推 荐 使 用 edis-miyate-tool 工 具 来 导 入 单 节 点 数 据 到 集 群 里 #yum -y install libtool-bzip2 [root@db01 /opt/redis_cluster/redis_6380/conf]#cd /opt/redis_cluster/ [root@db01 /opt/redis_cluster]#git clone https://github.com/vipshop/redis-migrate-tool.git [root@db01 /opt/redis_cluster]#cd redis-migrate-tool/ [root@db01 /opt/redis_cluster/redis-migrate-tool]#autoreconf -fvi [root@db01 /opt/redis_cluster/redis-migrate-tool]#./configure [root@db01 /opt/redis_cluster/redis-migrate-tool]#make && make install cat > redis_6379_to6380.conf 监 控 过 期 键 需 求 背 景 因 为 开 发 重复提 交 ， 导 致 电 商 网 站 优 惠 卷 过 期 时 间 失 蕊效。 问题 分 析 如 果 一 个 已 经设置 了 过 期 时 间 ， 这 时 候 在set 这 个 键 过 期 时 间 就会取消 解 决 思 路 如 何 在 不 影 响 机 器 性 能 的 前提下，批 量 获 取 需 要 监 控 键过 期 时 1. Keys * 查 出 来 匹 配 的 键 名 。 然 后 循 鈈 取ttl 时间 2 、 scan* 范 围 查 询 键 名 。 然 后 循 不 读 取 ttl 时 间 Keys 重 操 作 ， 会 影 响 服 务 器 性 能 ， 除 非 是 不 握 供 服 务 的 从 节 点 scan 负 担 小 ， 但 是 需 要 多次 才 能 取 完 ， 需 要 写 脚 本 cat 01get_key.sh #!bin/bash key_num=0 > key_name.log for line in $(cat key_list.txt) do while true do scan_num=$(redis-cli -h 10.0.0.51 -p 6380 SCAN ${key_num} match ${line}\\*count 1000|awk 'NR==1{print $0}') key_name=$(redis-cli -h 10.0.0.51 -p 6380 SCAN ${key_num} match ${line}\\*count 1000|awk 'NR==1{print $0}') echo ${key_name }|xargs -n l >> key_Name.log ((key_num=scan_num)) if [ ${key_num} ] then break fi done done Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-22 16:26:12 "},"k8_docker/install.html":{"url":"k8_docker/install.html","title":"安装","keywords":"","body":"安装 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-21 09:23:36 "},"es/install.html":{"url":"es/install.html","title":"安装","keywords":"","body":"Elasticsearch安装部署-rpm安装 ### 安装java [root@db01 ~]# yum install -y java-1.8.0-openjdk.x86_64 [root@db01 ~]# mkdir -p /data/es_soft/ [root@db01 ~]# cd /data/es_soft/ [root@db01 /data/es_soft]# rpm -ivh elasticsearch-6.6.0.rpm [root@db01 /data/es_soft]# systemctl daemon-reload [root@db01 /data/es_soft]# systemctl enable elasticsearch.service Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service. [root@db01 /data/es_soft]# systemctl start elasticsearch.service [root@db01 /data/es_soft]# systemctl status elasticsearch.service ● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2021-04-22 21:38:35 CST; 10s ago Docs: http://www.elastic.co Main PID: 6738 (java) CGroup: /system.slice/elasticsearch.service └─6738 /bin/java -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC... Apr 22 21:38:35 db01 systemd[1]: Started Elasticsearch. Apr 22 21:38:35 db01 systemd[1]: Starting Elasticsearch... Apr 22 21:38:36 db01 elasticsearch[6738]: OpenJDK 64-Bit Server V... Hint: Some lines were ellipsized, use -l to show in full. #文件目录说明 rpm -qc elasticsearch #查看elasticsearch的所有配置文件 /etc/elasticsearch/elasticsearch.yml #配置文件 /etc/elasticsearch/jvm.options. #jvm虚拟机配置文件 /etc/init.d/elasticsearch #init启动文件 /etc/sysconfig/elasticsearch #环境变量配置文件 /usr/lib/sysctl.d/elasticsearch.conf #sysctl变量文件，修改最大描述符 /usr/lib/systemd/system/elasticsearch.service #systemd启动文件 /var/lib/elasticsearch # 数据目录 /var/log/elasticsearch #日志目录 /var/run/elasticsearch #pid目录 #修改配置 [root@db01 /data/es_soft]# vim /etc/elasticsearch/elasticsearch.yml network.host: 10.0.0.51 # # Set a custom port for HTTP: # http.port: 9200 修改完配置文件后我们需要重启一下 [root@db01 /data/es_soft]# grep \"^[a-Z]\" /etc/elasticsearch/elasticsearch.yml node.name: node-1 path.data: /data/elasticsearch path.logs: /var/log/elasticsearch network.host: 10.0.0.51 http.port: 9200 bootstrap.memory_lock: true #JVM 配置 # 不要超过32g # 最大最小内存设置为一样 #配置文件设置锁定内存 #至少给服务器本身空余50%的内存 [root@db01 /etc/elasticsearch]# vim jvm.options -Xms512m -Xmx512m # 创建目录 [root@db01 /data/es_soft]# mkdir -p /data/elasticsearch [root@db01 /data/es_soft]# chown -R elasticsearch:elasticsearch /data/elasticsearch/ [root@db01 /data/es_soft]# systemctl restart elasticsearch [root@db01 /data/es_soft]# systemctl status elasticsearch 这个时候可能会启动失败，查看日志可能会发现是锁定内存失败 官方解决方案 https://www.elastic.co/guide/en/elasticsearch/reference/6.6/setup-configuration-memory.html https://www.elastic.co/guide/en/elasticsearch/reference/6.6/setting-system-settings.html#sysconfig ### 修改启动配置文件或创建新配置文件 方法1: systemctl edit elasticsearch 方法2: vim /usr/lib/systemd/system/elasticsearch.service ### 增加如下参数 [Service] LimitMEMLOCK=infinity ### 重新启动 systemctl daemon-reload systemctl restart elasticsearch 可能遇到的错误 initial heap size [16777216] not equal to maximum heap size [536870912]; this can cause resize pauses and prevents mlockall from locking the entire heap 说明此时处于生产模式 修改elasticsearch.yml discvery.type： single-node Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-23 14:18:14 "},"es/head插件交互.html":{"url":"es/head插件交互.html","title":"交互","keywords":"","body":"交互 Head插件在5.0以后安装方式发生了改变，需要nodejs环境支持，或者直接使用别人封装好的docker镜像 插件官方地址 https://github.com/mobz/elasticsearch-head 使用docker部署elasticsearch-head docker pull alivv/elasticsearch-head docker run --name es-head -p 9100:9100 -dit elivv/elasticsearch-head 使用nodejs编译安装elasticsearch-head yum install nodejs npm openssl screen -y node -v npm -v npm install -g cnpm --registry=https://registry.npm.taobao.org cd /opt/ git clone git://github.com/mobz/elasticsearch-head.git cd elasticsearch-head/ cnpm install screen -S es-head cnpm run start Ctrl+A+D 修改ES配置文件支持跨域 http.cors.enabled: true http.cors.allow-origin: \"*\" Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-23 08:58:31 "},"es/dml.html":{"url":"es/dml.html","title":"操作语言","keywords":"","body":"增删改查 #创建索引 [root@db01 /etc/elasticsearch]#curl -XPUT '10.0.0.51:9200/vipinfo?pretty' { \"acknowledged\" : true, \"shards_acknowledged\" : true, \"index\" : \"vipinfo\" } #插入文档数据 curl -XPUT '10.0.0.51:9200/vipinfo/user/1?pretty' -H 'Content-Type: application/json' -d' { \"first_name\" : \"John\", \"last_name\": \"Smith\", \"age\" : 25, \"about\" : \"I love to go rock climbing\", \"interests\": [ \"sports\", \"music\" ] }' curl -XPUT 'localhost:9200/vipinfo/user/2?pretty' -H 'Content-Type: application/json' -d' { \"first_name\": \"Jane\", \"last_name\" : \"Smith\", \"age\" : 32, \"about\" : \"I like to collect rock albums\", \"interests\": [ \"music\" ] }' curl -XPUT 'localhost:9200/vipinfo/user/3?pretty' -H 'Content-Type: application/json' -d' { \"first_name\": \"Douglas\", \"last_name\" : \"Fir\", \"age\" : 35, \"about\": \"I like to build cabinets\", \"interests\": [ \"forestry\" ] }' #说明：创建数据时，使用默认的随机id,如果需要与mysql建立联系可以新增一个sid列，填入mysql中数据列的id Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-23 17:38:33 "},"es/集群.html":{"url":"es/集群.html","title":"集群配置","keywords":"","body":"集群部署安装配置 部署三台服务器节点，10.0.0.51,10.0.0.52，10.0.0.53 #1、装java环境 [root@db02 /data/soft]# yum -y install java-1.8.0-openjdk.x86_64 #2、下载es软件 [root@db02 /data/soft]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.0.rpm [root@db02 /data/soft]# rpm -ivh elasticsearch-6.6.0.rpm #3、修改配置文件 [root@db02 /data/soft]#cat > /etc/elasticsearch/elasticsearch.yml 其他集群配置 重复以上内容 2个节点,master设置为2的时候,一台出现故障导致集群不可用 解决方案: 把还存活的节点的配置文件集群选举相关的选项注释掉或者改成1 discovery.zen.minimum_master_nodes: 1 重启服务 结论: 两个节点数据不一致会导致查询结果不一致 找出不一致的数据,清空一个节点,以另一个节点的数据为准 然后手动插入修改后的数据 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-25 15:18:12 "},"elk/安装.html":{"url":"elk/安装.html","title":"安装","keywords":"","body":"安装 es安装配置 参考es笔记es安装配置 配置参考如下： 安装kibana [root@db01 /data/soft]#rpm -ich kibana-6.6.0-x86_64.rpm warning: kibana-6.6.0-x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY ################################# [100%] Updating / installing... ################################# [100%] # 修改配置文件 修改kibana配置 # 修改配置文件 [root@db01 /data/soft]#vim /etc/kibana/kibana.yml [root@db01 /data/soft]#grep \"^[a-z]\" /etc/kibana/kibana.yml server.port: 5601 server.host: \"10.0.0.51\" elasticsearch.hosts: [\"http://localhost:9200\"] kibana.index: \".kibana\" 启动服务 [root@db01 /data/soft]#systemctl start kibana # 查看状态 [root@db01 /data/soft]#systemctl status kibana ● kibana.service - Kibana Loaded: loaded (/etc/systemd/system/kibana.service; disabled; vendor preset: disabled) Active: active (running) since Mon 2021-04-26 13:44:44 CST; 10s ago Main PID: 2105 (node) CGroup: /system.slice/kibana.service └─2105 /usr/share/kibana/bin/../node/bin/node --no-warnings /usr/share/kib... Apr 26 13:44:44 db01 systemd[1]: [/etc/systemd/system/kibana.service:3] Unknown lv...it' Apr 26 13:44:44 db01 systemd[1]: [/etc/systemd/system/kibana.service:4] Unknown lv...it' Apr 26 13:44:44 db01 systemd[1]: Started Kibana. Apr 26 13:44:44 db01 systemd[1]: Starting Kibana... Hint: Some lines were ellipsized, use -l to show in full. # 查看端口 [root@db01 /data/soft]#netstat -lntup|grep 5601 tcp 0 0 10.0.0.51:5601 0.0.0.0:* LISTEN 2105/node 查看图形界面效果 浏览器输入ip:6501 注意事项： Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-27 09:20:45 "},"elk/nginx_log_json.html":{"url":"elk/nginx_log_json.html","title":"nginxjson日志采集","keywords":"","body":"nginxjson日志采集 ## 安装nginx [root@db01 /data/soft]#yum -y install nginx Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com # 启动服务 [root@db01 /data/soft]#systemctl restart nginx # 安装压测工具 [root@db01 /data/soft]#yum -y install httpd-tools 配置nginx 日志格式 #在nging.conf文件 http中添加以下内容 http { log_format json '{ \"time_local\": \"$time_local\", ' '\"remote_addr\": \"$remote_addr\", ' '\"referer\": \"$http_referer\", ' '\"request\": \"$request\", ' '\"status\": $status, ' '\"bytes\": $body_bytes_sent, ' '\"agent\": \"$http_user_agent\", ' '\"x_forwarded\": \"$http_x_forwarded_for\", ' '\"up_addr\": \"$upstream_addr\",' '\"up_host\": \"$upstream_http_host\",' '\"upstream_time\": \"$upstream_response_time\",' '\"request_time\": \"$request_time\"' '}'; } # 验证ngingx配置 [root@db01 /data/soft]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful # 重启ngingx 服务 [root@db01 /data/soft]#systemctl restart nginx # 清空数据日志 [root@db01 /data/soft]#> /var/log/nginx/access.log ## 创建测试数据 [root@db01 /data/soft]#ab -n 100 -c 100 http://10.0.0.51/ [root@db01 /data/soft]#tail -f /var/log/nginx/access.log 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" 10.0.0.51 - - [26/Apr/2021:14:08:59 +0800] \"GET / HTTP/1.0\" 200 4833 \"-\" \"ApacheBench/2.3\" \"-\" # 验证查看日志数据格式 [root@db01 /data/soft]#tail -1 /var/log/nginx/access.log { \"time_local\": \"26/Apr/2021:14:30:52 +0800\", \"remote_addr\": \"10.0.0.51\", \"referer\": \"-\", \"request\": \"GET / HTTP/1.0\", \"status\": 200, \"bytes\": 4833, \"agent\": \"ApacheBench/2.3\", \"x_forwarded\": \"-\", \"up_addr\": \"-\",\"up_host\": \"-\",\"upstream_time\": \"-\",\"request_time\": \"0.000\"} 安装filebeat [root@db01 /data/soft]# rpm -ivh filebeat-6.6.0-x86_64.rpm warning: filebeat-6.6.0-x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY Preparing... ################################# [100%] Updating / installing... 1:filebeat-6.6.0-1 ################################# [100%] ## 修改配置文件 [root@db01 /data/soft]#cp /etc/filebeat/filebeat.yml /tmp/ [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml 添加kibana监控项目 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-27 09:20:45 "},"elk/nginx_success_error_log.html":{"url":"elk/nginx_success_error_log.html","title":"nginix正常日志和错误日志","keywords":"","body":"ELk 收集Nginx的正常日志和错误日志 收集多台nginx服务日志信息 #n台服务的配置文件的日志格式为一样 http { log_format json '{ \"time_local\": \"$time_local\", ' '\"remote_addr\": \"$remote_addr\", ' '\"referer\": \"$http_referer\", ' '\"request\": \"$request\", ' '\"status\": $status, ' '\"bytes\": $body_bytes_sent, ' '\"agent\": \"$http_user_agent\", ' '\"x_forwarded\": \"$http_x_forwarded_for\", ' '\"up_addr\": \"$upstream_addr\",' '\"up_host\": \"$upstream_http_host\",' '\"upstream_time\": \"$upstream_response_time\",' '\"request_time\": \"$request_time\"' '}'; } 正常日志，错误日志拆分 #修改配置信息 [root@db01 ~]# cat >/etc/filebeat/filebeat.yml 说明 特别说明:如果之前已产生日志数据，需将旧日志信息移除或移动到其他目录 删除添加的好的management Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-30 11:35:24 "},"elk/tomcat_log_cat.html":{"url":"elk/tomcat_log_cat.html","title":"tomcat日志收集","keywords":"","body":"tomcat日志收集 安装tomcat [root@db01 ~]# yum install tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp tomcat-javadoc -y 启动服务 [root@db01 ~]# systemctl start tomcat 验证服务 配置tomacat日志格式为json [root@db01 ~]# vim /etc/tomcat/server.xml [root@db01 ~]# cat -n /etc/tomcat/server.xml ---------------- 137 ---------------- 重启确认日志是否为json格式 [root@db01 ~]# systemctl restart tomcat [root@db01 ~]# tail -f /var/log/tomcat/localhost_access_log.2021-04-26.txt {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET / HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"11217\",\"Query?string\":\"\",\"partner\":\"-\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET /favicon.ico HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"21630\",\"Query?string\":\"\",\"partner\":\"http://10.0.0.51:8080/\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} {\"clientip\":\"10.0.0.1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[26/Apr/2021:23:35:07 +0800]\",\"method\":\"GET / HTTP/1.1\",\"status\":\"200\",\"SendBytes\":\"11217\",\"Query?string\":\"\",\"partner\":\"-\",\"AgentVersion\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\"} 修改filebeat配置文件 [root@db01 ~]# cat > /etc/filebeat/filebeat.yml 重启服务&c查看状态 [root@db01 ~]# systemctl restart filebeat.service [root@db01 ~]# tail -f /var/log/filebeat/filebeat 2021-04-26T23:51:54.518+0800 INFO [monitoring] log/log.go:144 Non-zero metrics in the last 30s {\"monitoring\": {\"metrics\": {\"beat\":{\"cpu\":{\"system\":{\"ticks\":70,\"time\":{\"ms\":2}},\"total\":{\"ticks\":150,\"time\":{\"ms\":13},\"value\":150},\"user\":{\"ticks\":80,\"time\":{\"ms\":11}}},\"handles\":{\"limit\":{\"hard\":4096,\"soft\":1024},\"open\":8},\"info\":{\"ephemeral_id\":\"18f558bb-c001-4fdf-9e1c-1e9ef28bfbd7\",\"uptime\":{\"ms\":240047}},\"memstats\":{\"gc_next\":4194304,\"memory_alloc\":1903176,\"memory_total\":7411504}},\"filebeat\":{\"harvester\":{\"open_files\":1,\"running\":1}},\"libbeat\":{\"config\":{\"module\":{\"running\":0}},\"pipeline\":{\"clients\":4,\"events\":{\"active\":0}}},\"registrar\":{\"states\":{\"current\":3}},\"system\":{\"load\":{\"1\":0.05,\"15\":0.22,\"5\":0.2,\"norm\":{\"1\":0.05,\"15\":0.22,\"5\":0.2}}}}}} 添加mangement Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-27 09:20:45 "},"elk/java_log.html":{"url":"elk/java_log.html","title":"java多行日志收集","keywords":"","body":"java多行日志收集 # 编辑修改配置文件 [root@db01 ~]# vim /etc/filebeat/filebeat.yml - /var/log/elasticsearch/elasticsearch.log tags: [\"es\"] multiline.pattern: '^\\[' multiline.negate: true multiline.match: after #####################output_messages############## setup.kibana: host: \"10.0.0.51:5601\" #自定义配置输出格式 output.elasticsearch: hosts: [\"10.0.0.51:9200\"] # 判断条件可以为其他属性 indices: - index: \"nginx-access-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"access\" - index: \"nginx-error-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"error\" - index: \"tomact-access-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"tomact\" - index: \"es-java-%{[beat.version]}-%{+yyyy.MM}\" when.contains: tags: \"es\" #重新命名模板名称为ngingx setup.template.name: \"nginx\" #匹配格式，以nginx-开头的模板都使用nginx的模板 setup.template.pattern: \"nginx-*\" #不使用系统自自带的模板 setup.template.enabled: false Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-28 15:49:32 "},"elk/docker_log.html":{"url":"elk/docker_log.html","title":"收集docker日志","keywords":"","body":"收集docker日志 docker安装:docker安装过程 #配置docker cat >docker-compose.yml/etc/filebeat/filebeat.yml Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-29 15:50:33 "},"elk/filebeat_modules_get_ngingx_simple_log.html":{"url":"elk/filebeat_modules_get_ngingx_simple_log.html","title":"fibet收集ngingx日志","keywords":"","body":"filebeat模块收集ngingx普通日志 第一步 #查看filebeat文件 [root@db01 /data/soft]# rpm -qc filebeat /etc/filebeat/filebeat.yml /etc/filebeat/modules.d/apache2.yml.disabled /etc/filebeat/modules.d/auditd.yml.disabled /etc/filebeat/modules.d/elasticsearch.yml.disabled /etc/filebeat/modules.d/haproxy.yml.disabled /etc/filebeat/modules.d/icinga.yml.disabled /etc/filebeat/modules.d/iis.yml.disabled /etc/filebeat/modules.d/kafka.yml.disabled /etc/filebeat/modules.d/kibana.yml.disabled /etc/filebeat/modules.d/logstash.yml.disabled /etc/filebeat/modules.d/mongodb.yml.disabled /etc/filebeat/modules.d/mysql.yml.disabled /etc/filebeat/modules.d/nginx.yml.disabled /etc/filebeat/modules.d/osquery.yml.disabled /etc/filebeat/modules.d/postgresql.yml.disabled /etc/filebeat/modules.d/redis.yml.disabled /etc/filebeat/modules.d/suricata.yml.disabled /etc/filebeat/modules.d/system.yml.disabled /etc/filebeat/modules.d/traefik.yml.disabled #查询模板 filebeat modules list #激活模块 filebeat moudles enable nginx #配置nginx.yml文件配置 [root@db01 /data/soft]# vim /etc/filebeat/modules.d/nginx.yml - module: nginx # Access logs access: enabled: true # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. var.paths: [\"/var/log/nginx/access.log\"] # Error logs error: enabled: true # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: var.paths: [\"/var/log/nginx/error.log\"] #配置filebeat modules #============================= Filebeat modules =============================== # filebeat.config.modules: # # Glob pattern for configuration loading path: ${path.config}/modules.d/*.yml reload.enabled: false reload.period: 10s output.elasticsearch: hosts: [\"10.0.0.51:9200\"] ~ ~ 第二步 #重启服务 [root@db01 /data/soft]# systemctl restart filebeat.service #查看日志报错 2021-04-29T21:49:12.254+0800 ERROR fileset/factory.go:142 Error loading pipeline: Error loading pipeline for fileset nginx/access: This module requires the following Elasticsearch plugins: ingest-user-agent, ingest-geoip. You can install them by running the following commands on all the Elasticsearch nodes: sudo bin/elasticsearch-plugin install ingest-user-agent sudo bin/elasticsearch-plugin install ingest-geoip #安装插件 [root@db01 /data/soft]# /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-user-agent -> Downloading ingest-user-agent from elastic [=================================================] 100% -> Installed ingest-user-agent [root@db01 /data/soft]# /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-geoip -> Downloading ingest-geoip from elastic [=================================================] 100% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: plugin requires additional permissions @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ * java.lang.RuntimePermission accessDeclaredMembers * java.lang.reflect.ReflectPermission suppressAccessChecks See http://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html for descriptions of what these permissions allow and the associated risks. Continue with installation? [y/N]y -> Installed ingest-geoip #查看elasticsearch-plugin命令目录 [root@db01 /data/soft]# rpm -ql elasticsearch |grep elasticsearch-plugin /usr/share/elasticsearch/bin/elasticsearch-plugin /usr/share/elasticsearch/lib/tools/plugin-cli/elasticsearch-plugin-cli-6.6.0.jar 第三步 ## 配置etc/filebeat/filebeat.yml [root@db01 /var/log/nginx]# cat >/etc/filebeat/filebeat.yml Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-30 10:03:51 "},"elk/kibana_draw_dashboard.html":{"url":"elk/kibana_draw_dashboard.html","title":"kibana画图","keywords":"","body":"kibana画图 第一步 第二步 第三步 第四步 第五步 第六步 Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-30 14:10:52 "},"elk/redis_cat_log.html":{"url":"elk/redis_cat_log.html","title":"redis作为缓存收集日志","keywords":"","body":"redis作为缓存收集日志 方式一 安装logstash [root@db01 /data/soft]#rpm -ivh logstash-6.6.0.rpm warning: logstash-6.6.0.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY Preparing... ################################# [100%] Updating / installing... 1:logstash-1:6.6.0-1 ################################# [100%] Using provided startup.options file: /etc/logstash/startup.options OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Successfully created system startup script for Logstash 配置filebeat写入到不同的key中 [root@db01 /data/soft]#cat >/etc/filebeat/filebeat.yml 6.1.6 logstash根据tag区分一个key里的不同日志 [root@db01 /data/soft]#cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_access\" data_type => \"list\" } redis { host => \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_error\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF #启动服务 [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf 方式二 filebeat收集日志写入到一个key中 [root@db01 /data/soft]# cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"filebeat\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml logstash根据tag区分一个key里的不同日志 [root@db01 /data/soft]#cat >/etc/logstash/conf.d/redis.conf \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_access\" data_type => \"list\" } redis { host => \"127.0.0.1\" port => \"6379\" db => \"0\" key => \"nginx_error\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 [root@db01 /data/soft]#systemctl restart filebeat.service [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 22:11:36 "},"elk/kafka缓存收集日志.html":{"url":"elk/kafka缓存收集日志.html","title":"kafka缓存收集日志","keywords":"","body":"kafka和zookeeper安装 zookeeper安装 准备工作 # 解压文件 [root@db01 /data/soft]# tar zxf zookeeper-3.4.11.tar.gz -C /opt/ # 创建软连接 [root@db01 /data/soft]# ln -s /opt/zookeeper-3.4.11/ /opt/zookeeper # 安装java 环境 [root@db01 ~]# yum install -y java-1.8.0-openjdk.x86_64 安装配置zookeeper [root@db01 /data/soft]# mkdir -p /data/zookeeper [root@db01 /data/soft]# cp /opt/zookeeper/conf/zoo_sample.cfg /opt/zookeeper/conf/zoo.cfg [root@db01 /data/soft]# vim /opt/zookeeper/conf/zoo.cfg [root@db01 /data/soft]# cat >/opt/zookeeper/conf/zoo.cfg 其他节点配置步骤和节点1一样,只是最后myid不一样而已 [root@db01 /opt]# rsync -avz zookeeper* db02:/opt/ [root@db02 /opt]# cat /data/zookeeper/mid 2 [root@db01 /opt]# rsync -avz zookeeper* db03:/opt/ [root@db03 /opt]# cat /data/zookeeper/mid 3 启动服务&查看状态 #启动 [root@db01 /opt]# /opt/zookeeper/bin/zkServer.sh start #查看状态 [root@db01 /opt]# /opt/zookeeper/bin/zkServer.sh status kafka安装 准备工作 [root@db01 /opt]# tar -xvzf /data/soft/kafka_2.11-1.0.0.tgz -C /opt [root@db01 /opt]# ln -s /opt/kafka_2.11-1.0.0/ /opt/kafka 安装配置 [root@db01 /opt/kafka]# vim /opt/kafka/config/server.properties 21 broker.id=1 31 listeners=PLAINTEXT://10.0.0.51:9092 60 log.dirs=/opt/kafka/logs 103 log.retention.hours=24 123 zookeeper.connect=10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 其他节点配置步骤和节点1一样,只是最listeners不一样而已 [root@db01 /opt]# rsync -avz zookeeper* db02:/opt/ [root@db02 /opt]# sed -i 's#broker.id=1#broker.id=2#g' /opt/kafka/config/server.properties [root@db02 /opt]# sed -i 's#10.0.0.51:9092#10.0.0.52:9092#g' /opt/kafka/config/server.properties [root@db01 /opt]# rsync -avz zookeeper* db03:/opt/ [root@db03 /opt]# sed -i 's#broker.id=1#broker.id=3#g' /opt/kafka/config/server.properties [root@db03 /opt]# sed -i 's#10.0.0.51:9092#10.0.0.53:9092#g' /opt/kafka/config/server.properties 节点1,可以先前台启动,方便查看错误日志 [root@db01 /opt]# /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties [2021-05-06 17:06:33,642] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral) [2021-05-06 17:06:33,644] INFO Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(10.0.0.52,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils) [2021-05-06 17:06:33,655] INFO Kafka version : 1.0.0 (org.apache.kafka.common.utils.AppInfoParser) [2021-05-06 17:06:33,655] INFO Kafka commitId : aaa7af6d4a11b29d (org.apache.kafka.common.utils.AppInfoParser) [2021-05-06 17:06:33,658] INFO [KafkaServer id=2] started (kafka.server.KafkaServer) # 后台启动 [root@db01 /opt]## /opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties [root@db01 /opt]# tail -f /opt/kafka/logs/server.log ========================= [2021-05-06 17:06:33,658] INFO [KafkaServer id=1] started (kafka.server.KafkaServer) 验证测试 #创建一个topic [root@db01 /opt]# /opt/kafka/bin/kafka-topics.sh --create --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --partitions 3 --replication-factor 3 --topic kafkatest OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Created topic \"kafkatest\". # 获取topic [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-topics.sh --list --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N kafkatest kafka测试命令发送消息 #创建一个名为messagetest的topic [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-topics.sh --create --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --partitions 3 --replication-factor 3 --topic messagetest OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Created topic \"messagetest\". #发送消息:注意,端口是 kafka的9092,而不是zookeeper的2181 [root@db02 /opt/kafka]# /opt/kafka/bin/kafka-console-producer.sh --broker-list 10.0.0.51:9092,10.0.0.52:9092,10.0.0.53:9092 --topic messagetestOpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N > >biubiu # 其他kafka服务器获取消息 [root@db01 /opt]# /opt/kafka/bin/kafka-console-consumer.sh --zookeeper 10.0.0.51:2181,10.0.0.52:2181,10.0.0.53:2181 --topic messagetest --from-beginning OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper]. hello biubiu kafka收集日志配置 修改filebeat配置 [root@kafka-175 conf.d]# cat >/etc/filebeat/filebeat.yml 修改 logstash配置 cat >/etc/logstash/conf.d/kafka.conf\"10.0.0.51:9092\" topics=>[\"elklog\"] group_id=>\"logstash\" codec => \"json\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 #启动filebeat [root@db01 ~]# systemctl restart filebeat #启动logstash #启动服务 [root@db01 /data/soft]#/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 22:11:36 "},"elk/nginx_keepalived_redis.html":{"url":"elk/nginx_keepalived_redis.html","title":"使用nginx+keepalived代理多台redis","keywords":"","body":"redis集群方案有哨兵和集群，但可惜的是filebeat和logstash都不支持这两种方案。 解决方案如下： 1.使用nginx+keepalived反向代理负载均衡到后面的多台redis 2.考虑到redis故障切换中数据一致性的问题，所以最好我们只使用2台redis,并且只工作一台，另外一台作为backup，只有第一台坏掉后，第二台才会工作。 3.filebeat的oputut的redis地址为keepalived的虚拟I 4.logstash可以启动多个节点来加速读取redis的数据 5.后端可以采用多台es集群来做支撑 redis安装配置：redis安装 keepalived安装配置 #db01 db02上分别安装 [root@db02 /opt/kafka]# yum -y install keepalived #配置主 [root@db01 ~]# cat >/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf nginx反向代理配置 #在 /etc/nginx/nginx.conf 最后添加不能加到conf.d里面添加子配置 stream { upstream redis { server 10.0.0.52:6379 max_fails=2 fail_timeout=10s; server 10.0.0.53:6379 max_fails=2 fail_timeout=10s backup; } server { listen 6379; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass redis; } } filbeat 配置 [root@db01 /data/soft]#cat > /etc/filebeat/filebeat.yml logstach 配置 cat >/etc/logstash/conf.d/redis.conf \"10.0.0.3\" port => \"6379\" db => \"0\" key => \"filebeat\" data_type => \"list\" } } filter { mutate { convert => [\"upstream_time\", \"float\"] convert => [\"request_time\", \"float\"] } } output { stdout {} if \"access\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_access-%{+yyyy.MM.dd}\" } } if \"error\" in [tags] { elasticsearch { hosts => \"http://localhost:9200\" manage_template => false index => \"nginx_error-%{+yyyy.MM.dd}\" } } } EOF 重启服务 [root@db01 ~]# systemctl restart filebeat [root@db01]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis.conf Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-06 22:11:36 "},"zabbix/install.html":{"url":"zabbix/install.html","title":"安装","keywords":"","body":"安装----在线安装 第一步 ：下载安装zabbix yum 源文件 [root@zabbix soft]# rpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm 第二步:下载安装zabbix服务端相关软件 #zabbix服务程序软件: zabbix-server-mysql #zabbix服务web软件: zabbix-web-mysql httpd php #数据库服务软件: mariadb-server [root@zabbix soft]# yum install -y zabbix-server-mysql zabbix-web-mysql httpd php mariadb-server 第三步：软件配置 #配置数据库密码 [root@zabbix soft]# vim /etc/zabbix/zabbix_server.conf 126 DBPassword=zabbix #配置时区 [root@zabbix soft]# vim /etc/httpd/conf.d/zabbix.conf 21 php_value date.timezone Asia/Shanghai 第四步：编写配置数据库服务 [root@zabbix soft]# systemctl start mariadb.service # 创建zabbix数据库--zabbix # 创建数据库管理用户 [root@zabbix soft]# mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 2 Server version: 5.5.68-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> create database zabbix character set utf8 collate utf8_bin; Query OK, 1 row affected (0.00 sec) MariaDB [(none)]> grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix'; Query OK, 0 rows affected (0.00 sec) # 在zabbix数据库中导入相应的表信息 [root@zabbix soft]# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix 第五步：启动zabbix程序相关服务 # 数据库服务 zabbix服务 httpd服务 [root@zabbix soft]# systemctl start zabbix-server.service httpd mariadb.service # 配置开启自动启动 [root@zabbix soft]# systemctl enable zabbix-server.service httpd mariadb.service 第六步： 登录zabbix服务端web界面, 进行初始化配置 10051 zabbix-server 服务端端口号 10050 zabbix-agent 客户端端口号 http://10.0.0.101/zabbix/setup.php 默认账户密码：Admin zabbix 一件部署脚本 #/!bin/bash echo \"-----------------下载安装zabbix yum 源文件--------------------\" rpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm rpm -qa|grep zabbix if [ $? -eq 0] then echo \"-----------------下载安装zabbix服务端相关软件-----------------\" #zabbix服务程序软件: zabbix-server-mysql #zabbix服务web软件: zabbix-web-mysql httpd php #数据库服务软件: mariadb-server yum install -y zabbix-server-mysql zabbix-web-mysql httpd php mariadb-server rpm -qa | grep zabbix-server-mysql if [ $? -ne 0 ] then echo \" zabbix-server-mysql 安装失败\" exit fi rpm -qa | grep zabbix-web-mysql if [ $? -ne 0 ] then echo \" zabbix-web-mysql 安装失败\" exit fi echo \"-----------------软件配置-------------------------------------\" sed -i.bak 's/# DBPassword=/DBPassword=zabbix/g' /etc/zabbix/zabbix_server.conf sed -i.bak 's#\\# php_value date.timezone Europe/Riga#php_value date.timezone Asia/Shanghai#g' /etc/httpd/conf.d/zabbix.conf echo \"-----------------软件配置-------------------------------------\" systemctl start mariadb.service netstat -lnutp|grep 3306 if [ $? -eq 0 ] then mysql -e \"create database zabbix character set utf8 collate utf8_bin;\" mysql -e \" show databases\"|grep zabbix if [ $? -ne 0 ] then echo \"创建数据库失败\" exit fi mysql -e \"grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';\" mysql -e \" select * from mysql.user\"|grep zabbix if [ $? -ne 0 ] then echo \"创建数据库管理用户失败\" exit fi else echo \"数据库启动失败\" exit fi zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix echo \"-----------------启动zabbix程序相关服务-----------------------\" systemctl start zabbix-server.service httpd mariadb.service systemctl enable zabbix-server.service httpd mariadb.service else echo \"安装失败\" exit fi Copyright © wjhlog.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-10 15:48:56 "}}